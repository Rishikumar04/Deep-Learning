{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfication Task Practise Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                  as pd\n",
    "import numpy                   as np\n",
    "import keras\n",
    "from   keras.layers            import Dense, Dropout, BatchNormalization, Activation\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   keras.models            import Sequential\n",
    "from   keras.callbacks         import EarlyStopping\n",
    "from   sklearn.metrics         import confusion_matrix, classification_report, accuracy_score, log_loss, hinge_loss\n",
    "from sklearn.preprocessing     import StandardScaler\n",
    "from imblearn.over_sampling    import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var13_medio_ult1</th>\n",
       "      <th>saldo_medio_var17_ult3</th>\n",
       "      <th>saldo_medio_var29_hace2</th>\n",
       "      <th>saldo_medio_var29_hace3</th>\n",
       "      <th>saldo_medio_var29_ult1</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142882</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.73</td>\n",
       "      <td>17.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.73</td>\n",
       "      <td>17.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59375.97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116073</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117951.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40727</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1051.86</td>\n",
       "      <td>1145.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1051.86</td>\n",
       "      <td>1145.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81164.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96753</td>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1353.03</td>\n",
       "      <td>1998.81</td>\n",
       "      <td>990.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362.28</td>\n",
       "      <td>362.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137912.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105319</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40407.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0  142882     2     55                30.0                    17.73   \n",
       "1  116073     2     26                 0.0                     0.00   \n",
       "2   40727     2     31               180.0                  1051.86   \n",
       "3   96753    89     55                 0.0                  1353.03   \n",
       "4  105319     2     24                 0.0                     0.00   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_ult1  \\\n",
       "0                    17.73                     0.00                0.0   \n",
       "1                     0.00                     0.00                0.0   \n",
       "2                  1145.91                     0.00                0.0   \n",
       "3                  1998.81                   990.75                0.0   \n",
       "4                     0.00                     0.00                0.0   \n",
       "\n",
       "   imp_op_var41_comer_ult1  imp_op_var41_comer_ult3  ...  \\\n",
       "0                    17.73                    17.73  ...   \n",
       "1                     0.00                     0.00  ...   \n",
       "2                  1051.86                  1145.91  ...   \n",
       "3                   362.28                   362.28  ...   \n",
       "4                     0.00                     0.00  ...   \n",
       "\n",
       "   saldo_medio_var13_medio_ult1  saldo_medio_var17_ult3  \\\n",
       "0                             0                     0.0   \n",
       "1                             0                     0.0   \n",
       "2                             0                     0.0   \n",
       "3                             0                     0.0   \n",
       "4                             0                     0.0   \n",
       "\n",
       "   saldo_medio_var29_hace2  saldo_medio_var29_hace3  saldo_medio_var29_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_hace3  saldo_medio_var33_ult3  saldo_medio_var44_hace3  \\\n",
       "0                      0.0                     0.0                      0.0   \n",
       "1                      0.0                     0.0                      0.0   \n",
       "2                      0.0                     0.0                      0.0   \n",
       "3                      0.0                     0.0                      0.0   \n",
       "4                      0.0                     0.0                      0.0   \n",
       "\n",
       "       var38  TARGET_Classification  \n",
       "0   59375.97                      1  \n",
       "1  117951.42                      0  \n",
       "2   81164.61                      0  \n",
       "3  137912.85                      0  \n",
       "4   40407.66                      0  \n",
       "\n",
       "[5 rows x 215 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_classification.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17997\n",
       "1     1808\n",
       "Name: TARGET_Classification, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET_Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.isna().sum()>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult3</th>\n",
       "      <th>imp_op_var41_efect_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var13_medio_ult1</th>\n",
       "      <th>saldo_medio_var17_ult3</th>\n",
       "      <th>saldo_medio_var29_hace2</th>\n",
       "      <th>saldo_medio_var29_hace3</th>\n",
       "      <th>saldo_medio_var29_ult1</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.73</td>\n",
       "      <td>17.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.73</td>\n",
       "      <td>17.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59375.97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117951.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1051.86</td>\n",
       "      <td>1145.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1051.86</td>\n",
       "      <td>1145.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81164.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1353.03</td>\n",
       "      <td>1998.81</td>\n",
       "      <td>990.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362.28</td>\n",
       "      <td>362.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137912.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40407.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0     2     55                30.0                    17.73   \n",
       "1     2     26                 0.0                     0.00   \n",
       "2     2     31               180.0                  1051.86   \n",
       "3    89     55                 0.0                  1353.03   \n",
       "4     2     24                 0.0                     0.00   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_ult1  \\\n",
       "0                    17.73                     0.00                0.0   \n",
       "1                     0.00                     0.00                0.0   \n",
       "2                  1145.91                     0.00                0.0   \n",
       "3                  1998.81                   990.75                0.0   \n",
       "4                     0.00                     0.00                0.0   \n",
       "\n",
       "   imp_op_var41_comer_ult1  imp_op_var41_comer_ult3  imp_op_var41_efect_ult1  \\\n",
       "0                    17.73                    17.73                      0.0   \n",
       "1                     0.00                     0.00                      0.0   \n",
       "2                  1051.86                  1145.91                      0.0   \n",
       "3                   362.28                   362.28                      0.0   \n",
       "4                     0.00                     0.00                      0.0   \n",
       "\n",
       "   ...  saldo_medio_var13_medio_ult1  saldo_medio_var17_ult3  \\\n",
       "0  ...                             0                     0.0   \n",
       "1  ...                             0                     0.0   \n",
       "2  ...                             0                     0.0   \n",
       "3  ...                             0                     0.0   \n",
       "4  ...                             0                     0.0   \n",
       "\n",
       "   saldo_medio_var29_hace2  saldo_medio_var29_hace3  saldo_medio_var29_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_hace3  saldo_medio_var33_ult3  saldo_medio_var44_hace3  \\\n",
       "0                      0.0                     0.0                      0.0   \n",
       "1                      0.0                     0.0                      0.0   \n",
       "2                      0.0                     0.0                      0.0   \n",
       "3                      0.0                     0.0                      0.0   \n",
       "4                      0.0                     0.0                      0.0   \n",
       "\n",
       "       var38  TARGET_Classification  \n",
       "0   59375.97                      1  \n",
       "1  117951.42                      0  \n",
       "2   81164.61                      0  \n",
       "3  137912.85                      0  \n",
       "4   40407.66                      0  \n",
       "\n",
       "[5 rows x 214 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-1].values\n",
    "y = df['TARGET_Classification'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard_Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "\n",
    "X_test_sc = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true,y_pred):\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "    print('Log Loss:\\n', log_loss(y_true, y_pred))\n",
    "    print('Hinge Loss:\\n', hinge_loss(y_true, y_pred))\n",
    "    print('\\n\\nAccuracy Score:\\n', accuracy_score(y_true, y_pred))\n",
    "    print('\\n\\nClassification Report: \\n', classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model_algo(activation, nodes, opti, dropout = False):\n",
    "    model = Sequential()\n",
    "    for i in range(len(nodes)): #Add input layer and hidden layer\n",
    "        if i == 0:\n",
    "            model.add(Dense(nodes[i], input_dim = 212, kernel_initializer = 'he_normal'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(activation))\n",
    "            if dropout:\n",
    "                model.add(Dropout(0.3))\n",
    "        else:\n",
    "            model.add(Dense(nodes[i]))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(activation))\n",
    "            if dropout:\n",
    "                model.add(Dropout(0.3))\n",
    "            \n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    print(model)\n",
    "    #Compile\n",
    "    model.compile(optimizer = opti, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fac4b99c2e0>\n"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "model = deep_model_algo(activation='relu', nodes = [300, 250, 200, 100, 20], opti = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 6s 38ms/step - loss: 1.3452 - accuracy: 0.7488 - val_loss: 0.3379 - val_accuracy: 0.9072\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.7794 - accuracy: 0.8850 - val_loss: 0.3336 - val_accuracy: 0.9072\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6115 - accuracy: 0.8881 - val_loss: 0.3460 - val_accuracy: 0.9072\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6055 - accuracy: 0.8766 - val_loss: 0.3389 - val_accuracy: 0.9072\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.6300 - accuracy: 0.8780 - val_loss: 0.3287 - val_accuracy: 0.9072\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5177 - accuracy: 0.8960 - val_loss: 0.3279 - val_accuracy: 0.9072\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.5252 - accuracy: 0.8928 - val_loss: 0.3276 - val_accuracy: 0.9072\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.5052 - accuracy: 0.8960 - val_loss: 0.3276 - val_accuracy: 0.9072\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.4740 - accuracy: 0.8999 - val_loss: 0.3407 - val_accuracy: 0.9072\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.4784 - accuracy: 0.8953 - val_loss: 0.3384 - val_accuracy: 0.9072\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.5753 - accuracy: 0.8892 - val_loss: 0.3276 - val_accuracy: 0.9072\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.5036 - accuracy: 0.8975 - val_loss: 0.3277 - val_accuracy: 0.9072\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.4664 - accuracy: 0.8984 - val_loss: 0.3202 - val_accuracy: 0.9077\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.4486 - accuracy: 0.8997 - val_loss: 0.3058 - val_accuracy: 0.9086\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.4439 - accuracy: 0.8967 - val_loss: 0.3060 - val_accuracy: 0.9086\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3610 - accuracy: 0.9041 - val_loss: 0.3073 - val_accuracy: 0.9086\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3343 - accuracy: 0.9111 - val_loss: 0.3220 - val_accuracy: 0.9086\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3415 - accuracy: 0.9077 - val_loss: 0.3074 - val_accuracy: 0.9086\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3408 - accuracy: 0.9075 - val_loss: 0.3065 - val_accuracy: 0.9086\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3224 - accuracy: 0.9102 - val_loss: 0.3073 - val_accuracy: 0.9086\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3280 - accuracy: 0.9123 - val_loss: 0.3060 - val_accuracy: 0.9086\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3247 - accuracy: 0.9106 - val_loss: 0.3087 - val_accuracy: 0.9086\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3385 - accuracy: 0.9068 - val_loss: 0.3138 - val_accuracy: 0.9086\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3290 - accuracy: 0.9099 - val_loss: 0.3143 - val_accuracy: 0.9086\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3562 - accuracy: 0.9053 - val_loss: 0.3137 - val_accuracy: 0.9086\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3492 - accuracy: 0.9043 - val_loss: 0.3186 - val_accuracy: 0.9086\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3186 - accuracy: 0.9114 - val_loss: 0.3060 - val_accuracy: 0.9086\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3309 - accuracy: 0.9093 - val_loss: 0.3685 - val_accuracy: 0.9086\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3257 - accuracy: 0.9077 - val_loss: 0.3195 - val_accuracy: 0.9086\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3419 - accuracy: 0.9038 - val_loss: 0.3117 - val_accuracy: 0.9086\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3217 - accuracy: 0.9084 - val_loss: 0.3123 - val_accuracy: 0.9086\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3223 - accuracy: 0.9083 - val_loss: 0.3148 - val_accuracy: 0.9086\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3228 - accuracy: 0.9084 - val_loss: 0.3115 - val_accuracy: 0.9086\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3118 - accuracy: 0.9099 - val_loss: 0.3117 - val_accuracy: 0.9086\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3152 - accuracy: 0.9074 - val_loss: 0.3076 - val_accuracy: 0.9086\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3328 - accuracy: 0.9039 - val_loss: 0.3068 - val_accuracy: 0.9086\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.3105 - accuracy: 0.9087 - val_loss: 0.3058 - val_accuracy: 0.9086\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3099 - accuracy: 0.9076 - val_loss: 0.3123 - val_accuracy: 0.9086\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3728 - accuracy: 0.8994 - val_loss: 0.3108 - val_accuracy: 0.9086\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.3135 - accuracy: 0.9107 - val_loss: 0.3118 - val_accuracy: 0.9086\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3306 - accuracy: 0.9070 - val_loss: 0.3118 - val_accuracy: 0.9086\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3151 - accuracy: 0.9095 - val_loss: 0.3092 - val_accuracy: 0.9086\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3068 - accuracy: 0.9096 - val_loss: 0.3087 - val_accuracy: 0.9086\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3708 - accuracy: 0.9014 - val_loss: 0.3142 - val_accuracy: 0.9082\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3203 - accuracy: 0.9060 - val_loss: 0.3088 - val_accuracy: 0.9086\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3400 - accuracy: 0.9039 - val_loss: 0.3088 - val_accuracy: 0.9086\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3052 - accuracy: 0.9082 - val_loss: 0.3181 - val_accuracy: 0.9086\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3177 - accuracy: 0.9068 - val_loss: 0.3164 - val_accuracy: 0.9086\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3098 - accuracy: 0.9079 - val_loss: 0.3163 - val_accuracy: 0.9086\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3058 - accuracy: 0.9106 - val_loss: 0.3081 - val_accuracy: 0.9086\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3102 - accuracy: 0.9077 - val_loss: 0.3073 - val_accuracy: 0.9086\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3147 - accuracy: 0.9092 - val_loss: 0.3068 - val_accuracy: 0.9086\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3011 - accuracy: 0.9127 - val_loss: 0.3094 - val_accuracy: 0.9086\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.2993 - accuracy: 0.9109 - val_loss: 0.3113 - val_accuracy: 0.9086\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3088 - accuracy: 0.9077 - val_loss: 0.3148 - val_accuracy: 0.9086\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3130 - accuracy: 0.9078 - val_loss: 0.3157 - val_accuracy: 0.9086\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3113 - accuracy: 0.9069 - val_loss: 0.3187 - val_accuracy: 0.9086\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 15ms/step - loss: 0.2822 - accuracy: 0.9176 - val_loss: 0.3136 - val_accuracy: 0.9086\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3187 - accuracy: 0.9033 - val_loss: 0.3178 - val_accuracy: 0.9086\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3068 - accuracy: 0.9041 - val_loss: 0.3187 - val_accuracy: 0.9086\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2903 - accuracy: 0.9146 - val_loss: 0.3186 - val_accuracy: 0.9086\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3275 - accuracy: 0.9073 - val_loss: 0.3193 - val_accuracy: 0.9086\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3189 - accuracy: 0.9040 - val_loss: 0.3116 - val_accuracy: 0.9086\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3198 - accuracy: 0.9064 - val_loss: 0.3086 - val_accuracy: 0.9086\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3037 - accuracy: 0.9102 - val_loss: 0.3062 - val_accuracy: 0.9086\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3204 - accuracy: 0.9067 - val_loss: 0.3074 - val_accuracy: 0.9086\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3153 - accuracy: 0.9048 - val_loss: 0.3065 - val_accuracy: 0.9086\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3160 - accuracy: 0.9082 - val_loss: 0.3062 - val_accuracy: 0.9086\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3725 - accuracy: 0.9037 - val_loss: 0.3064 - val_accuracy: 0.9086\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3104 - accuracy: 0.9065 - val_loss: 0.3084 - val_accuracy: 0.9086\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2972 - accuracy: 0.9095 - val_loss: 0.3122 - val_accuracy: 0.9086\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3153 - accuracy: 0.9051 - val_loss: 0.3161 - val_accuracy: 0.9086\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.3138 - accuracy: 0.9032 - val_loss: 0.3241 - val_accuracy: 0.9086\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3005 - accuracy: 0.9082 - val_loss: 0.3272 - val_accuracy: 0.9086\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.2976 - accuracy: 0.9094 - val_loss: 0.3211 - val_accuracy: 0.9086\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2951 - accuracy: 0.9086 - val_loss: 0.3216 - val_accuracy: 0.9086\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2940 - accuracy: 0.9141 - val_loss: 0.3131 - val_accuracy: 0.9086\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2964 - accuracy: 0.9100 - val_loss: 0.3207 - val_accuracy: 0.9086\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3204 - accuracy: 0.9006 - val_loss: 0.3237 - val_accuracy: 0.9086\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2972 - accuracy: 0.9067 - val_loss: 0.3218 - val_accuracy: 0.9086\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2981 - accuracy: 0.9097 - val_loss: 0.3149 - val_accuracy: 0.9086\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.2802 - accuracy: 0.9085 - val_loss: 0.3185 - val_accuracy: 0.9086\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3093 - accuracy: 0.9047 - val_loss: 0.3274 - val_accuracy: 0.9086\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.2871 - accuracy: 0.9093 - val_loss: 0.3246 - val_accuracy: 0.9086\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2902 - accuracy: 0.9069 - val_loss: 0.3260 - val_accuracy: 0.9086\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2969 - accuracy: 0.9070 - val_loss: 0.3240 - val_accuracy: 0.9086\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.2993 - accuracy: 0.9057 - val_loss: 0.3361 - val_accuracy: 0.9086\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2859 - accuracy: 0.9109 - val_loss: 0.3291 - val_accuracy: 0.9086\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.2948 - accuracy: 0.9101 - val_loss: 0.3202 - val_accuracy: 0.9086\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3006 - accuracy: 0.9049 - val_loss: 0.3243 - val_accuracy: 0.9086\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.2826 - accuracy: 0.9113 - val_loss: 0.3085 - val_accuracy: 0.9086\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2989 - accuracy: 0.9078 - val_loss: 0.3090 - val_accuracy: 0.9086\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3056 - accuracy: 0.9111 - val_loss: 0.3246 - val_accuracy: 0.9086\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.2980 - accuracy: 0.9102 - val_loss: 0.3446 - val_accuracy: 0.9086\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.2914 - accuracy: 0.9128 - val_loss: 0.3406 - val_accuracy: 0.9086\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3078 - accuracy: 0.9041 - val_loss: 0.3430 - val_accuracy: 0.9086\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3010 - accuracy: 0.9036 - val_loss: 0.3188 - val_accuracy: 0.9086\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2931 - accuracy: 0.9090 - val_loss: 0.3353 - val_accuracy: 0.9086\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.2919 - accuracy: 0.9077 - val_loss: 0.3325 - val_accuracy: 0.9086\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.2845 - accuracy: 0.9108 - val_loss: 0.3256 - val_accuracy: 0.9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac4b8b2a00>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 256, epochs = 100, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict_classes(X_train)\n",
    "test_pred = model.predict_classes (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[12597     0]\n",
      " [ 1266     0]]\n",
      "Log Loss:\n",
      " 3.154157896267542\n",
      "Hinge Loss:\n",
      " 1.0\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9086777753732959\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     12597\n",
      "           1       0.00      0.00      0.00      1266\n",
      "\n",
      "    accuracy                           0.91     13863\n",
      "   macro avg       0.45      0.50      0.48     13863\n",
      "weighted avg       0.83      0.91      0.87     13863\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5400    0]\n",
      " [ 542    0]]\n",
      "Log Loss:\n",
      " 3.150457220808077\n",
      "Hinge Loss:\n",
      " 1.0\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9087849209020532\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      5400\n",
      "           1       0.00      0.00      0.00       542\n",
      "\n",
      "    accuracy                           0.91      5942\n",
      "   macro avg       0.45      0.50      0.48      5942\n",
      "weighted avg       0.83      0.91      0.87      5942\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train, train_pred)\n",
    "metrics(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fac33408f70>\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "model = deep_model_algo(activation='relu', nodes = [300, 250, 200, 100, 20], opti = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 6s 30ms/step - loss: 1.3704 - accuracy: 0.8715 - val_loss: 0.3432 - val_accuracy: 0.9066\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.6544 - accuracy: 0.8923 - val_loss: 0.3468 - val_accuracy: 0.9066\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.4550 - accuracy: 0.9031 - val_loss: 0.3153 - val_accuracy: 0.9088\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.4084 - accuracy: 0.8834 - val_loss: 0.3298 - val_accuracy: 0.9088\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3739 - accuracy: 0.8970 - val_loss: 0.3144 - val_accuracy: 0.9088\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3463 - accuracy: 0.9070 - val_loss: 0.3149 - val_accuracy: 0.9084\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3308 - accuracy: 0.9117 - val_loss: 0.3149 - val_accuracy: 0.9084\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3333 - accuracy: 0.9122 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3748 - accuracy: 0.9034 - val_loss: 0.3291 - val_accuracy: 0.9076\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3307 - accuracy: 0.9063 - val_loss: 0.3276 - val_accuracy: 0.9076\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3452 - accuracy: 0.9078 - val_loss: 0.3161 - val_accuracy: 0.9088\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3340 - accuracy: 0.9094 - val_loss: 0.3103 - val_accuracy: 0.9088\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3311 - accuracy: 0.9069 - val_loss: 0.3104 - val_accuracy: 0.9088\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3278 - accuracy: 0.9089 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3319 - accuracy: 0.9057 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.3281 - accuracy: 0.9069 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3118 - accuracy: 0.9123 - val_loss: 0.3055 - val_accuracy: 0.9084\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.3350 - accuracy: 0.9081 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.3257 - accuracy: 0.9068 - val_loss: 0.3064 - val_accuracy: 0.9088\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.3337 - accuracy: 0.9073 - val_loss: 0.3182 - val_accuracy: 0.9088\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.3213 - accuracy: 0.9097 - val_loss: 0.3117 - val_accuracy: 0.9088\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.3412 - accuracy: 0.9074 - val_loss: 0.3103 - val_accuracy: 0.9088\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.3217 - accuracy: 0.9073 - val_loss: 0.3111 - val_accuracy: 0.9088\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3245 - accuracy: 0.9069 - val_loss: 0.3158 - val_accuracy: 0.9088\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3267 - accuracy: 0.9058 - val_loss: 0.3182 - val_accuracy: 0.9088\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.5786 - accuracy: 0.8900 - val_loss: 0.3635 - val_accuracy: 0.9066\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3384 - accuracy: 0.9068 - val_loss: 0.3514 - val_accuracy: 0.9066\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3063 - accuracy: 0.9116 - val_loss: 0.3506 - val_accuracy: 0.9066\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3218 - accuracy: 0.9081 - val_loss: 0.3315 - val_accuracy: 0.9074\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3140 - accuracy: 0.9126 - val_loss: 0.3143 - val_accuracy: 0.9088\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3202 - accuracy: 0.9094 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3222 - accuracy: 0.9040 - val_loss: 0.3189 - val_accuracy: 0.9088\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2988 - accuracy: 0.9107 - val_loss: 0.3174 - val_accuracy: 0.9088\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3080 - accuracy: 0.9092 - val_loss: 0.3120 - val_accuracy: 0.9083\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3156 - accuracy: 0.9051 - val_loss: 0.3111 - val_accuracy: 0.9088\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3037 - accuracy: 0.9095 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3136 - accuracy: 0.9072 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3093 - accuracy: 0.9083 - val_loss: 0.3146 - val_accuracy: 0.9088\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3118 - accuracy: 0.9056 - val_loss: 0.3171 - val_accuracy: 0.9088\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3052 - accuracy: 0.9089 - val_loss: 0.3219 - val_accuracy: 0.9088\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3029 - accuracy: 0.9104 - val_loss: 0.3297 - val_accuracy: 0.9088\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3071 - accuracy: 0.9107 - val_loss: 0.3108 - val_accuracy: 0.9088\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3085 - accuracy: 0.9076 - val_loss: 0.3132 - val_accuracy: 0.9088\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3032 - accuracy: 0.9098 - val_loss: 0.3132 - val_accuracy: 0.9088\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2923 - accuracy: 0.9111 - val_loss: 0.3238 - val_accuracy: 0.9088\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.3189 - accuracy: 0.9043 - val_loss: 0.3304 - val_accuracy: 0.9088\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.3192 - accuracy: 0.9055 - val_loss: 0.3357 - val_accuracy: 0.9088\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3089 - accuracy: 0.9067 - val_loss: 0.3450 - val_accuracy: 0.9088\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3019 - accuracy: 0.9075 - val_loss: 0.3275 - val_accuracy: 0.9084\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2947 - accuracy: 0.9106 - val_loss: 0.3209 - val_accuracy: 0.9088\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3431 - accuracy: 0.9064 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3141 - accuracy: 0.9090 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3151 - accuracy: 0.9111 - val_loss: 0.3161 - val_accuracy: 0.9083\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3163 - accuracy: 0.9064 - val_loss: 0.3141 - val_accuracy: 0.9088\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3146 - accuracy: 0.9083 - val_loss: 0.3127 - val_accuracy: 0.9088\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3032 - accuracy: 0.9087 - val_loss: 0.3311 - val_accuracy: 0.9066\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3020 - accuracy: 0.9083 - val_loss: 0.3322 - val_accuracy: 0.9073\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2984 - accuracy: 0.9124 - val_loss: 0.3205 - val_accuracy: 0.9081\n",
      "Epoch 59/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2951 - accuracy: 0.9108 - val_loss: 0.3232 - val_accuracy: 0.9088\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3020 - accuracy: 0.9093 - val_loss: 0.3252 - val_accuracy: 0.9088\n",
      "Epoch 61/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3128 - accuracy: 0.9106 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3120 - accuracy: 0.9058 - val_loss: 0.3117 - val_accuracy: 0.9088\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3064 - accuracy: 0.9087 - val_loss: 0.3157 - val_accuracy: 0.9088\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2998 - accuracy: 0.9111 - val_loss: 0.3183 - val_accuracy: 0.9088\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2921 - accuracy: 0.9106 - val_loss: 0.3208 - val_accuracy: 0.9088\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3058 - accuracy: 0.9077 - val_loss: 0.3369 - val_accuracy: 0.9088\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2952 - accuracy: 0.9110 - val_loss: 0.3460 - val_accuracy: 0.9088\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3083 - accuracy: 0.9072 - val_loss: 0.3370 - val_accuracy: 0.9088\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2910 - accuracy: 0.9107 - val_loss: 0.3546 - val_accuracy: 0.9066\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3307 - accuracy: 0.9053 - val_loss: 0.3153 - val_accuracy: 0.9084\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3090 - accuracy: 0.9093 - val_loss: 0.3151 - val_accuracy: 0.9084\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3140 - accuracy: 0.9105 - val_loss: 0.3148 - val_accuracy: 0.9084\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3150 - accuracy: 0.9087 - val_loss: 0.3244 - val_accuracy: 0.9079\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3106 - accuracy: 0.9065 - val_loss: 0.3250 - val_accuracy: 0.9079\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3013 - accuracy: 0.9101 - val_loss: 0.3225 - val_accuracy: 0.9083\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3053 - accuracy: 0.9074 - val_loss: 0.3270 - val_accuracy: 0.9079\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3062 - accuracy: 0.9079 - val_loss: 0.3435 - val_accuracy: 0.9079\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2961 - accuracy: 0.9105 - val_loss: 0.3409 - val_accuracy: 0.9079\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3010 - accuracy: 0.9075 - val_loss: 0.3430 - val_accuracy: 0.9079\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3039 - accuracy: 0.9077 - val_loss: 0.3463 - val_accuracy: 0.9083\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2961 - accuracy: 0.9094 - val_loss: 0.3728 - val_accuracy: 0.9083\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3058 - accuracy: 0.9052 - val_loss: 0.3605 - val_accuracy: 0.9083\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2954 - accuracy: 0.9080 - val_loss: 0.3599 - val_accuracy: 0.9083\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3008 - accuracy: 0.9092 - val_loss: 0.3512 - val_accuracy: 0.9083\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2984 - accuracy: 0.9066 - val_loss: 0.3414 - val_accuracy: 0.9083\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2989 - accuracy: 0.9055 - val_loss: 0.3350 - val_accuracy: 0.9083\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2996 - accuracy: 0.9074 - val_loss: 0.3492 - val_accuracy: 0.9083\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2866 - accuracy: 0.9077 - val_loss: 0.3315 - val_accuracy: 0.9083\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2919 - accuracy: 0.9068 - val_loss: 0.3307 - val_accuracy: 0.9083\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3054 - accuracy: 0.9092 - val_loss: 0.3252 - val_accuracy: 0.9079\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3030 - accuracy: 0.9097 - val_loss: 0.3191 - val_accuracy: 0.9083\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2987 - accuracy: 0.9126 - val_loss: 0.3184 - val_accuracy: 0.9083\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3057 - accuracy: 0.9079 - val_loss: 0.3243 - val_accuracy: 0.9083\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3087 - accuracy: 0.9050 - val_loss: 0.3323 - val_accuracy: 0.9083\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2972 - accuracy: 0.9083 - val_loss: 0.3533 - val_accuracy: 0.9083\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3030 - accuracy: 0.9057 - val_loss: 0.3669 - val_accuracy: 0.9083\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3059 - accuracy: 0.9123 - val_loss: 0.3178 - val_accuracy: 0.9083\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3023 - accuracy: 0.9108 - val_loss: 0.3173 - val_accuracy: 0.9083\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3124 - accuracy: 0.9052 - val_loss: 0.3174 - val_accuracy: 0.9083\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2882 - accuracy: 0.9149 - val_loss: 0.3172 - val_accuracy: 0.9083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac333f7520>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 256, epochs = 100, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.098414</td>\n",
       "      <td>0.868715</td>\n",
       "      <td>0.343181</td>\n",
       "      <td>0.906597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.623822</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.346849</td>\n",
       "      <td>0.906597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404374</td>\n",
       "      <td>0.905215</td>\n",
       "      <td>0.315293</td>\n",
       "      <td>0.908785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.435694</td>\n",
       "      <td>0.871024</td>\n",
       "      <td>0.329832</td>\n",
       "      <td>0.908785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.365599</td>\n",
       "      <td>0.900527</td>\n",
       "      <td>0.314369</td>\n",
       "      <td>0.908785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.098414  0.868715  0.343181      0.906597\n",
       "1  0.623822  0.895044  0.346849      0.906597\n",
       "2  0.404374  0.905215  0.315293      0.908785\n",
       "3  0.435694  0.871024  0.329832      0.908785\n",
       "4  0.365599  0.900527  0.314369      0.908785"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict_classes(X_train)\n",
    "test_pred = model.predict_classes (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[12593     4]\n",
      " [ 1265     1]]\n",
      "Log Loss:\n",
      " 3.1616324347927134\n",
      "Hinge Loss:\n",
      " 1.0002164033758927\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9084613719974032\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     12597\n",
      "           1       0.20      0.00      0.00      1266\n",
      "\n",
      "    accuracy                           0.91     13863\n",
      "   macro avg       0.55      0.50      0.48     13863\n",
      "weighted avg       0.84      0.91      0.87     13863\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5397    3]\n",
      " [ 542    0]]\n",
      "Log Loss:\n",
      " 3.1678955796059602\n",
      "Hinge Loss:\n",
      " 1.0005048805116123\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.908280040390441\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      5400\n",
      "           1       0.00      0.00      0.00       542\n",
      "\n",
      "    accuracy                           0.91      5942\n",
      "   macro avg       0.45      0.50      0.48      5942\n",
      "weighted avg       0.83      0.91      0.87      5942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train, train_pred)\n",
    "metrics(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.3608 - accuracy: 0.9042 - val_loss: 0.3084 - val_accuracy: 0.9088\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.2823 - accuracy: 0.9072 - val_loss: 0.3054 - val_accuracy: 0.9088\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2731 - accuracy: 0.9089 - val_loss: 0.3059 - val_accuracy: 0.9088\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2709 - accuracy: 0.9081 - val_loss: 0.3067 - val_accuracy: 0.9088\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2830 - accuracy: 0.9090 - val_loss: 0.3154 - val_accuracy: 0.9088\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2623 - accuracy: 0.9090 - val_loss: 0.3091 - val_accuracy: 0.9088\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2551 - accuracy: 0.9087 - val_loss: 0.3060 - val_accuracy: 0.9088\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 1s 25ms/step - loss: 0.2894 - accuracy: 0.9090 - val_loss: 0.3442 - val_accuracy: 0.9088\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2730 - accuracy: 0.9089 - val_loss: 0.3172 - val_accuracy: 0.9088\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2953 - accuracy: 0.8937 - val_loss: 0.3074 - val_accuracy: 0.9088\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2678 - accuracy: 0.9089 - val_loss: 0.3063 - val_accuracy: 0.9088\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2694 - accuracy: 0.9082 - val_loss: 0.4548 - val_accuracy: 0.9088\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2612 - accuracy: 0.9060 - val_loss: 0.3077 - val_accuracy: 0.9088\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2545 - accuracy: 0.9090 - val_loss: 0.3058 - val_accuracy: 0.9088\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2549 - accuracy: 0.9088 - val_loss: 0.3092 - val_accuracy: 0.9088\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3681 - accuracy: 0.8947 - val_loss: 0.3222 - val_accuracy: 0.9088\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2657 - accuracy: 0.9086 - val_loss: 0.3348 - val_accuracy: 0.9088\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2571 - accuracy: 0.9087 - val_loss: 0.3433 - val_accuracy: 0.9088\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2530 - accuracy: 0.9087 - val_loss: 0.3396 - val_accuracy: 0.9088\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2464 - accuracy: 0.9085 - val_loss: 0.3430 - val_accuracy: 0.9088\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2509 - accuracy: 0.9085 - val_loss: 0.3308 - val_accuracy: 0.9088\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2516 - accuracy: 0.9090 - val_loss: 0.3355 - val_accuracy: 0.9088\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2508 - accuracy: 0.9087 - val_loss: 0.3375 - val_accuracy: 0.9088\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2509 - accuracy: 0.9087 - val_loss: 0.3513 - val_accuracy: 0.9088\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2506 - accuracy: 0.9083 - val_loss: 0.3504 - val_accuracy: 0.9088\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2466 - accuracy: 0.9091 - val_loss: 0.3878 - val_accuracy: 0.9088\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2628 - accuracy: 0.9090 - val_loss: 0.3129 - val_accuracy: 0.9088\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2538 - accuracy: 0.9089 - val_loss: 0.3151 - val_accuracy: 0.9088\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.2459 - accuracy: 0.9091 - val_loss: 0.3434 - val_accuracy: 0.9088\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.3049 - accuracy: 0.9087 - val_loss: 0.3069 - val_accuracy: 0.9088\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2802 - accuracy: 0.9089 - val_loss: 0.3151 - val_accuracy: 0.9088\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2523 - accuracy: 0.9090 - val_loss: 0.3066 - val_accuracy: 0.9088\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2501 - accuracy: 0.9090 - val_loss: 0.3132 - val_accuracy: 0.9088\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2477 - accuracy: 0.9098 - val_loss: 0.3110 - val_accuracy: 0.9088\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 1s 24ms/step - loss: 0.2450 - accuracy: 0.9092 - val_loss: 0.3251 - val_accuracy: 0.9088\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.2400 - accuracy: 0.9095 - val_loss: 0.3548 - val_accuracy: 0.9088\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.2491 - accuracy: 0.9097 - val_loss: 0.3497 - val_accuracy: 0.9088\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.2442 - accuracy: 0.9090 - val_loss: 0.3201 - val_accuracy: 0.9088\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.2505 - accuracy: 0.9100 - val_loss: 0.3168 - val_accuracy: 0.9088\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 1s 23ms/step - loss: 0.2414 - accuracy: 0.9094 - val_loss: 0.3574 - val_accuracy: 0.9088\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 1s 23ms/step - loss: 0.2610 - accuracy: 0.9102 - val_loss: 0.3659 - val_accuracy: 0.9088\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 1s 24ms/step - loss: 0.3037 - accuracy: 0.9083 - val_loss: 0.3151 - val_accuracy: 0.9088\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.4766 - accuracy: 0.8860 - val_loss: 0.3085 - val_accuracy: 0.9088\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.3189 - accuracy: 0.9025 - val_loss: 0.3221 - val_accuracy: 0.9088\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2570 - accuracy: 0.9079 - val_loss: 0.3160 - val_accuracy: 0.9088\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2523 - accuracy: 0.9098 - val_loss: 0.2921 - val_accuracy: 0.9088\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2429 - accuracy: 0.9093 - val_loss: 0.3090 - val_accuracy: 0.9088\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.2397 - accuracy: 0.9084 - val_loss: 0.3298 - val_accuracy: 0.9088\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.2411 - accuracy: 0.9093 - val_loss: 0.3002 - val_accuracy: 0.9081\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.2462 - accuracy: 0.9100 - val_loss: 0.3332 - val_accuracy: 0.9063\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.2385 - accuracy: 0.9084 - val_loss: 0.3367 - val_accuracy: 0.8997\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2345 - accuracy: 0.9085 - val_loss: 0.3392 - val_accuracy: 0.8948\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.2357 - accuracy: 0.9099 - val_loss: 0.3571 - val_accuracy: 0.8775\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.2381 - accuracy: 0.9111 - val_loss: 0.3563 - val_accuracy: 0.8534\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.2360 - accuracy: 0.9093 - val_loss: 0.3380 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2375 - accuracy: 0.9113 - val_loss: 0.3355 - val_accuracy: 0.8689\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2541 - accuracy: 0.9087 - val_loss: 0.4333 - val_accuracy: 0.9084\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2755 - accuracy: 0.9099 - val_loss: 0.3021 - val_accuracy: 0.9088\n",
      "Epoch 59/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2739 - accuracy: 0.9094 - val_loss: 0.2913 - val_accuracy: 0.9088\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2621 - accuracy: 0.9088 - val_loss: 0.2883 - val_accuracy: 0.9088\n",
      "Epoch 61/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.2503 - accuracy: 0.9089 - val_loss: 0.2902 - val_accuracy: 0.9088\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.2876 - accuracy: 0.9031 - val_loss: 0.9111 - val_accuracy: 0.8573\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.6494 - accuracy: 0.8608 - val_loss: 0.7796 - val_accuracy: 0.8613\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.5708 - accuracy: 0.8767 - val_loss: 0.5193 - val_accuracy: 0.8834\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.4959 - accuracy: 0.8865 - val_loss: 0.4019 - val_accuracy: 0.8931\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.4186 - accuracy: 0.8937 - val_loss: 0.3442 - val_accuracy: 0.9036\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.4051 - accuracy: 0.8977 - val_loss: 0.3490 - val_accuracy: 0.9034\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3771 - accuracy: 0.8989 - val_loss: 0.3400 - val_accuracy: 0.9031\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.4034 - accuracy: 0.8927 - val_loss: 0.4131 - val_accuracy: 0.8881\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.3581 - accuracy: 0.9002 - val_loss: 0.3563 - val_accuracy: 0.9026\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.3434 - accuracy: 0.9017 - val_loss: 0.3389 - val_accuracy: 0.9026\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.3318 - accuracy: 0.9019 - val_loss: 0.3334 - val_accuracy: 0.9034\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.3568 - accuracy: 0.9000 - val_loss: 0.2980 - val_accuracy: 0.9054\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.3274 - accuracy: 0.9023 - val_loss: 0.2978 - val_accuracy: 0.9051\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.3264 - accuracy: 0.9023 - val_loss: 0.3041 - val_accuracy: 0.9056\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.3090 - accuracy: 0.9033 - val_loss: 0.3088 - val_accuracy: 0.9049\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.3006 - accuracy: 0.9041 - val_loss: 0.3194 - val_accuracy: 0.9053\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.3213 - accuracy: 0.9015 - val_loss: 0.3261 - val_accuracy: 0.9042\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.2984 - accuracy: 0.9044 - val_loss: 0.3153 - val_accuracy: 0.9044\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.2585 - accuracy: 0.9072 - val_loss: 0.2805 - val_accuracy: 0.9071\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.2424 - accuracy: 0.9087 - val_loss: 0.2742 - val_accuracy: 0.9076\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2405 - accuracy: 0.9086 - val_loss: 0.2699 - val_accuracy: 0.9074\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2407 - accuracy: 0.9090 - val_loss: 0.2729 - val_accuracy: 0.9078\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 1s 23ms/step - loss: 0.2424 - accuracy: 0.9088 - val_loss: 0.3569 - val_accuracy: 0.9081\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.3520 - accuracy: 0.9085 - val_loss: 0.3597 - val_accuracy: 0.9088\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.3147 - accuracy: 0.9087 - val_loss: 0.3220 - val_accuracy: 0.9088\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.3031 - accuracy: 0.9089 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2866 - accuracy: 0.9086 - val_loss: 0.2990 - val_accuracy: 0.9088\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.2707 - accuracy: 0.9085 - val_loss: 0.2870 - val_accuracy: 0.9078\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.2630 - accuracy: 0.9087 - val_loss: 0.2793 - val_accuracy: 0.9081\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2536 - accuracy: 0.9097 - val_loss: 0.2792 - val_accuracy: 0.9071\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.2566 - accuracy: 0.9066 - val_loss: 0.2866 - val_accuracy: 0.9053\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2519 - accuracy: 0.9082 - val_loss: 0.2819 - val_accuracy: 0.9054\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2454 - accuracy: 0.9090 - val_loss: 0.2599 - val_accuracy: 0.9079\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2432 - accuracy: 0.9093 - val_loss: 0.2572 - val_accuracy: 0.9088\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2415 - accuracy: 0.9097 - val_loss: 0.2685 - val_accuracy: 0.9088\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.2391 - accuracy: 0.9092 - val_loss: 0.2623 - val_accuracy: 0.9090\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2373 - accuracy: 0.9093 - val_loss: 0.2721 - val_accuracy: 0.9081\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.2445 - accuracy: 0.9095 - val_loss: 0.2756 - val_accuracy: 0.9088\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.2372 - accuracy: 0.9100 - val_loss: 0.2724 - val_accuracy: 0.9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac385da070>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standard scaler\n",
    "model.fit(X_train_sc, y_train, batch_size = 256, epochs = 100, validation_data = (X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.360823</td>\n",
       "      <td>0.904205</td>\n",
       "      <td>0.308446</td>\n",
       "      <td>0.908785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.282265</td>\n",
       "      <td>0.907235</td>\n",
       "      <td>0.305414</td>\n",
       "      <td>0.908785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273148</td>\n",
       "      <td>0.908894</td>\n",
       "      <td>0.305906</td>\n",
       "      <td>0.908785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270873</td>\n",
       "      <td>0.908101</td>\n",
       "      <td>0.306668</td>\n",
       "      <td>0.908785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.283018</td>\n",
       "      <td>0.909038</td>\n",
       "      <td>0.315374</td>\n",
       "      <td>0.908785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.360823  0.904205  0.308446      0.908785\n",
       "1  0.282265  0.907235  0.305414      0.908785\n",
       "2  0.273148  0.908894  0.305906      0.908785\n",
       "3  0.270873  0.908101  0.306668      0.908785\n",
       "4  0.283018  0.909038  0.315374      0.908785"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict_classes(X_train_sc)\n",
    "test_pred = model.predict_classes (X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred1 = (model.predict(X_train_sc)>0.3)\n",
    "test_pred1 = (model.predict(X_test_sc)>0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[11840   757]\n",
      " [  735   531]]\n",
      "Log Loss:\n",
      " 3.7172660806796083\n",
      "Hinge Loss:\n",
      " 1.0163023876505808\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.8923753877227152\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     12597\n",
      "           1       0.41      0.42      0.42      1266\n",
      "\n",
      "    accuracy                           0.89     13863\n",
      "   macro avg       0.68      0.68      0.68     13863\n",
      "weighted avg       0.89      0.89      0.89     13863\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5041  359]\n",
      " [ 321  221]]\n",
      "Log Loss:\n",
      " 3.95265146482947\n",
      "Hinge Loss:\n",
      " 1.0232245035341636\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.8855604173678896\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      5400\n",
      "           1       0.38      0.41      0.39       542\n",
      "\n",
      "    accuracy                           0.89      5942\n",
      "   macro avg       0.66      0.67      0.67      5942\n",
      "weighted avg       0.89      0.89      0.89      5942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train, train_pred1.astype(int))\n",
    "\n",
    "metrics(y_test, test_pred1.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE()\n",
    "\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13863,), (25194,))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_train_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.8550 - accuracy: 0.5418 - val_loss: 0.6530 - val_accuracy: 0.9081\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.6722 - accuracy: 0.6081 - val_loss: 0.6235 - val_accuracy: 0.9088\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.6338 - accuracy: 0.6292 - val_loss: 0.5286 - val_accuracy: 0.9083\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.6219 - accuracy: 0.6348 - val_loss: 0.4693 - val_accuracy: 0.9081\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.6212 - accuracy: 0.6359 - val_loss: 0.4913 - val_accuracy: 0.9083\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 2s 20ms/step - loss: 0.6146 - accuracy: 0.6376 - val_loss: 0.4388 - val_accuracy: 0.9083\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 2s 23ms/step - loss: 0.6667 - accuracy: 0.6360 - val_loss: 0.4830 - val_accuracy: 0.9066\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.7291 - accuracy: 0.6275 - val_loss: 0.4783 - val_accuracy: 0.9068\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.6804 - accuracy: 0.6338 - val_loss: 0.5803 - val_accuracy: 0.9083\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.6039 - accuracy: 0.6548 - val_loss: 0.5033 - val_accuracy: 0.9083\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.6019 - accuracy: 0.6472 - val_loss: 0.4982 - val_accuracy: 0.9083\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5925 - accuracy: 0.6630 - val_loss: 0.4293 - val_accuracy: 0.9083\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5904 - accuracy: 0.6615 - val_loss: 0.4461 - val_accuracy: 0.9083\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.5961 - accuracy: 0.6567 - val_loss: 0.4237 - val_accuracy: 0.9083\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5888 - accuracy: 0.6658 - val_loss: 0.4323 - val_accuracy: 0.9083\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.5921 - accuracy: 0.6615 - val_loss: 0.4900 - val_accuracy: 0.9083\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.5858 - accuracy: 0.6650 - val_loss: 0.5159 - val_accuracy: 0.9071\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 2s 17ms/step - loss: 0.5745 - accuracy: 0.6762 - val_loss: 0.4408 - val_accuracy: 0.9079\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5769 - accuracy: 0.6743 - val_loss: 0.3752 - val_accuracy: 0.9083\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.5776 - accuracy: 0.6765 - val_loss: 0.3803 - val_accuracy: 0.9083\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.5742 - accuracy: 0.6741 - val_loss: 0.3953 - val_accuracy: 0.9083\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5745 - accuracy: 0.6752 - val_loss: 0.4006 - val_accuracy: 0.9071\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.5702 - accuracy: 0.6794 - val_loss: 0.3881 - val_accuracy: 0.9074\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.5674 - accuracy: 0.6783 - val_loss: 0.3411 - val_accuracy: 0.9083\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.5772 - accuracy: 0.6713 - val_loss: 0.3862 - val_accuracy: 0.9074\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5828 - accuracy: 0.6610 - val_loss: 0.3855 - val_accuracy: 0.9069\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.6405 - accuracy: 0.6751 - val_loss: 0.4720 - val_accuracy: 0.9069\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.7123 - accuracy: 0.6606 - val_loss: 0.4357 - val_accuracy: 0.9069\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 2s 17ms/step - loss: 0.7068 - accuracy: 0.6744 - val_loss: 0.3772 - val_accuracy: 0.9069\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.6868 - accuracy: 0.6747 - val_loss: 0.3394 - val_accuracy: 0.9069\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.6777 - accuracy: 0.6746 - val_loss: 0.3570 - val_accuracy: 0.9069\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5952 - accuracy: 0.6994 - val_loss: 0.3888 - val_accuracy: 0.9069\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 0.6240 - accuracy: 0.6674 - val_loss: 0.3965 - val_accuracy: 0.9071\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 0.5911 - accuracy: 0.6825 - val_loss: 0.4159 - val_accuracy: 0.9071\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 2s 17ms/step - loss: 0.5862 - accuracy: 0.6788 - val_loss: 0.4546 - val_accuracy: 0.9071\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5782 - accuracy: 0.6817 - val_loss: 0.4519 - val_accuracy: 0.9071\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 2s 18ms/step - loss: 0.5638 - accuracy: 0.6802 - val_loss: 0.4063 - val_accuracy: 0.9071\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 2s 17ms/step - loss: 0.5691 - accuracy: 0.6761 - val_loss: 0.4678 - val_accuracy: 0.9071\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 2s 17ms/step - loss: 0.5696 - accuracy: 0.6731 - val_loss: 0.4167 - val_accuracy: 0.9071\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 2s 21ms/step - loss: 0.5587 - accuracy: 0.6818 - val_loss: 0.4162 - val_accuracy: 0.9071\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 2s 20ms/step - loss: 0.5828 - accuracy: 0.6626 - val_loss: 0.6661 - val_accuracy: 0.9071\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 2s 18ms/step - loss: 0.6408 - accuracy: 0.6127 - val_loss: 0.4783 - val_accuracy: 0.9071\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 2s 17ms/step - loss: 0.5955 - accuracy: 0.6644 - val_loss: 0.3818 - val_accuracy: 0.9071\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 3s 26ms/step - loss: 0.5629 - accuracy: 0.6857 - val_loss: 0.3469 - val_accuracy: 0.9071\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 3s 27ms/step - loss: 0.5588 - accuracy: 0.6833 - val_loss: 0.3775 - val_accuracy: 0.9071\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 2s 25ms/step - loss: 0.5593 - accuracy: 0.6820 - val_loss: 0.3625 - val_accuracy: 0.9071\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 3s 27ms/step - loss: 0.5537 - accuracy: 0.6807 - val_loss: 0.3443 - val_accuracy: 0.9071\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 2s 25ms/step - loss: 0.5542 - accuracy: 0.6935 - val_loss: 0.3901 - val_accuracy: 0.9071\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 3s 28ms/step - loss: 0.5510 - accuracy: 0.6890 - val_loss: 0.4429 - val_accuracy: 0.9071\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 3s 26ms/step - loss: 0.5569 - accuracy: 0.6877 - val_loss: 0.3991 - val_accuracy: 0.9071\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 3s 29ms/step - loss: 0.5493 - accuracy: 0.6904 - val_loss: 0.4002 - val_accuracy: 0.9071\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 2s 25ms/step - loss: 0.5451 - accuracy: 0.6896 - val_loss: 0.4093 - val_accuracy: 0.9071\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 2s 24ms/step - loss: 0.5516 - accuracy: 0.6841 - val_loss: 0.4153 - val_accuracy: 0.9071\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 3s 27ms/step - loss: 0.5436 - accuracy: 0.6938 - val_loss: 0.4531 - val_accuracy: 0.9071\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 2s 21ms/step - loss: 0.5733 - accuracy: 0.6654 - val_loss: 0.7381 - val_accuracy: 0.0929\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 2s 20ms/step - loss: 0.6504 - accuracy: 0.6132 - val_loss: 0.5477 - val_accuracy: 0.9071\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 2s 19ms/step - loss: 0.6347 - accuracy: 0.6378 - val_loss: 0.4528 - val_accuracy: 0.9071\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 1s 15ms/step - loss: 0.6318 - accuracy: 0.6303 - val_loss: 0.4597 - val_accuracy: 0.9071\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.6382 - accuracy: 0.6166 - val_loss: 0.4269 - val_accuracy: 0.9071\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 2s 18ms/step - loss: 0.5872 - accuracy: 0.6839 - val_loss: 0.4019 - val_accuracy: 0.9071\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 0.5764 - accuracy: 0.6821 - val_loss: 0.3583 - val_accuracy: 0.9083\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5716 - accuracy: 0.6884 - val_loss: 0.3281 - val_accuracy: 0.9088\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 0.5694 - accuracy: 0.6895 - val_loss: 0.3345 - val_accuracy: 0.9088\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.5832 - accuracy: 0.6891 - val_loss: 0.3738 - val_accuracy: 0.9088\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 0.5707 - accuracy: 0.6797 - val_loss: 0.3851 - val_accuracy: 0.9069\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5601 - accuracy: 0.6891 - val_loss: 0.3995 - val_accuracy: 0.9071\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 0.5580 - accuracy: 0.7003 - val_loss: 0.3217 - val_accuracy: 0.9083\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5463 - accuracy: 0.7060 - val_loss: 0.3276 - val_accuracy: 0.9083\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5467 - accuracy: 0.7049 - val_loss: 0.3575 - val_accuracy: 0.9083\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5587 - accuracy: 0.7033 - val_loss: 0.3418 - val_accuracy: 0.9088\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5448 - accuracy: 0.7003 - val_loss: 0.3503 - val_accuracy: 0.9088\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5750 - accuracy: 0.6873 - val_loss: 0.4239 - val_accuracy: 0.9088\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5458 - accuracy: 0.7047 - val_loss: 0.3424 - val_accuracy: 0.9083\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5481 - accuracy: 0.6957 - val_loss: 0.3377 - val_accuracy: 0.9081\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5475 - accuracy: 0.6996 - val_loss: 0.3319 - val_accuracy: 0.9083\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 0.5289 - accuracy: 0.7185 - val_loss: 0.3328 - val_accuracy: 0.9079\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5285 - accuracy: 0.7161 - val_loss: 0.3613 - val_accuracy: 0.9071\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 0.5345 - accuracy: 0.7118 - val_loss: 0.3701 - val_accuracy: 0.9069\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.5246 - accuracy: 0.7238 - val_loss: 0.3628 - val_accuracy: 0.9069\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 2s 20ms/step - loss: 0.5321 - accuracy: 0.7160 - val_loss: 0.3716 - val_accuracy: 0.9071\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 2s 17ms/step - loss: 0.5250 - accuracy: 0.7194 - val_loss: 0.3757 - val_accuracy: 0.9071\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 2s 16ms/step - loss: 0.6855 - accuracy: 0.5370 - val_loss: 0.7134 - val_accuracy: 0.9071\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.6678 - accuracy: 0.5725 - val_loss: 0.6892 - val_accuracy: 0.9083\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 0.6514 - accuracy: 0.5948 - val_loss: 0.6212 - val_accuracy: 0.9083\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.6184 - accuracy: 0.6477 - val_loss: 0.4883 - val_accuracy: 0.9083\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.6154 - accuracy: 0.6600 - val_loss: 0.4464 - val_accuracy: 0.9083\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5985 - accuracy: 0.6731 - val_loss: 0.4421 - val_accuracy: 0.9083\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.6354 - accuracy: 0.6310 - val_loss: 0.5549 - val_accuracy: 0.9083\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5954 - accuracy: 0.6734 - val_loss: 0.4264 - val_accuracy: 0.9083\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 0.5663 - accuracy: 0.6967 - val_loss: 0.4878 - val_accuracy: 0.9083\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5622 - accuracy: 0.7063 - val_loss: 0.4237 - val_accuracy: 0.9083\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5659 - accuracy: 0.7002 - val_loss: 0.4580 - val_accuracy: 0.9083\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5583 - accuracy: 0.7006 - val_loss: 0.4007 - val_accuracy: 0.9083\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5549 - accuracy: 0.7025 - val_loss: 0.4285 - val_accuracy: 0.9071\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5534 - accuracy: 0.7070 - val_loss: 0.4273 - val_accuracy: 0.9071\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5796 - accuracy: 0.6839 - val_loss: 0.4254 - val_accuracy: 0.9071\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.5761 - accuracy: 0.6808 - val_loss: 0.3795 - val_accuracy: 0.9071\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 0.6240 - accuracy: 0.6353 - val_loss: 0.5816 - val_accuracy: 0.9083\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.6189 - accuracy: 0.6417 - val_loss: 0.4790 - val_accuracy: 0.9083\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.6054 - accuracy: 0.6689 - val_loss: 0.4327 - val_accuracy: 0.9083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac3881e160>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sm, y_train_sm, batch_size = 256, epochs = 100, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss.head()\n",
    "loss[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict_classes(X_train_sm)\n",
    "test_pred = model.predict_classes (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[12593     4]\n",
      " [12584    13]]\n",
      "Log Loss:\n",
      " 17.257050109451665\n",
      "Hinge Loss:\n",
      " 0.9996427720885925\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.5003572279114075\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     12597\n",
      "           1       0.76      0.00      0.00     12597\n",
      "\n",
      "    accuracy                           0.50     25194\n",
      "   macro avg       0.63      0.50      0.33     25194\n",
      "weighted avg       0.63      0.50      0.33     25194\n",
      "\n",
      "----------\n",
      "Confusion Matrix:\n",
      " [[5397    3]\n",
      " [ 542    0]]\n",
      "Log Loss:\n",
      " 3.1678955796059602\n",
      "Hinge Loss:\n",
      " 1.0005048805116123\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.908280040390441\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      5400\n",
      "           1       0.00      0.00      0.00       542\n",
      "\n",
      "    accuracy                           0.91      5942\n",
      "   macro avg       0.45      0.50      0.48      5942\n",
      "weighted avg       0.83      0.91      0.87      5942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train_sm, train_pred)\n",
    "print('-'*10)\n",
    "metrics(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 8.07130858e-02, -4.08378124e+00,  1.40024519e+00, ...,\n",
       "          1.46293056e+00, -2.22410113e-02,  4.13088547e-03],\n",
       "        [ 6.49903417e-02,  4.08176363e-01, -6.43304810e-02, ...,\n",
       "          1.92980200e-01, -2.49974579e-02, -1.24365808e-02],\n",
       "        [ 2.21984744e-01, -1.10519305e-01,  8.39557052e-02, ...,\n",
       "         -8.87129828e-02,  1.77008986e-01,  7.20781535e-02],\n",
       "        ...,\n",
       "        [ 2.46597067e-01, -4.23270129e-02,  1.06757022e-01, ...,\n",
       "         -1.31196260e-01,  2.32982174e-01,  9.80226845e-02],\n",
       "        [ 3.28228265e-01,  1.35040715e-01,  4.54494879e-02, ...,\n",
       "         -1.20638967e-01,  3.83030400e-02, -3.60658253e-03],\n",
       "        [-1.49625922e-02, -5.31921126e-02,  7.34481961e-02, ...,\n",
       "          2.24616323e-02, -1.32424548e-01, -1.40045226e-01]], dtype=float32),\n",
       " array([-5.30715566e-04, -5.96914615e-05, -9.71819281e-06,  5.48711723e-05,\n",
       "         8.71518743e-04, -3.90925823e-04,  2.32416089e-03,  4.05418221e-03,\n",
       "         4.20193013e-04,  4.40607779e-04,  2.36618653e-04,  1.58943323e-04,\n",
       "        -2.34110252e-04, -2.14129366e-04,  7.30978616e-04,  2.83155678e-04,\n",
       "         6.01368549e-04, -3.15938989e-04, -4.49676649e-04, -2.20443209e-04,\n",
       "        -4.50752414e-04, -5.82494366e-04, -9.61741680e-05,  5.07363409e-04,\n",
       "        -2.00058985e-05, -1.19189041e-04, -3.82780936e-03, -9.69678164e-04,\n",
       "         4.10550740e-04, -3.62042774e-05, -1.62290968e-03,  3.76656931e-03,\n",
       "        -6.04506095e-05,  2.27009532e-05, -3.57398647e-04, -3.89861176e-04,\n",
       "        -7.96139066e-04,  5.97257225e-04,  9.90522210e-04, -7.83916621e-04,\n",
       "         3.41371779e-04, -9.45960404e-04,  1.95041869e-03, -5.68154326e-04,\n",
       "        -9.05428824e-05,  2.19061490e-04, -2.37796659e-04, -4.47794970e-04,\n",
       "        -3.83204460e-05, -4.46265942e-04,  3.77404154e-03, -1.05368881e-03,\n",
       "         1.27269295e-05,  6.99805532e-05,  2.37946142e-03,  2.08086125e-03,\n",
       "        -4.50882176e-03,  1.93098662e-04, -1.66408089e-03,  2.53918074e-06,\n",
       "         9.34645999e-04, -1.66192665e-04,  4.81420523e-03,  1.16619084e-03,\n",
       "         1.13762310e-03,  1.20432582e-03,  5.04721364e-04,  9.85702063e-05,\n",
       "         6.86983694e-04, -1.98127324e-04, -1.10327639e-03,  5.12541272e-04,\n",
       "        -1.59700678e-04, -2.44704279e-05,  9.87368985e-04, -2.58857687e-03,\n",
       "         1.49632484e-04, -1.09656167e-03, -9.77164716e-04,  6.43082662e-04,\n",
       "         8.62942834e-04,  6.71023445e-04, -1.00004087e-04,  3.77443299e-04,\n",
       "        -2.80998956e-05,  1.02082314e-03, -4.62385884e-04,  1.29271974e-03,\n",
       "        -8.10766360e-05,  8.24283507e-06, -2.16665603e-06, -1.88891412e-04,\n",
       "         5.63376409e-04,  5.45502699e-05,  8.33967351e-04, -9.70011679e-05,\n",
       "         8.00880487e-04,  1.00200309e-03,  2.95767793e-04,  1.37717841e-04,\n",
       "        -2.13966751e-03,  1.14982031e-04, -6.11901196e-05, -9.66489431e-04,\n",
       "         2.77280924e-04,  9.84281724e-05,  3.22384411e-04,  4.88517748e-04,\n",
       "        -2.54089595e-04,  9.50113288e-04, -2.37165412e-04,  1.29441411e-04,\n",
       "        -9.21040373e-06, -7.98414694e-05,  4.80386152e-05, -1.06203207e-03,\n",
       "         4.92740655e-04,  2.38109526e-04, -4.52802560e-05, -1.22843031e-03,\n",
       "        -1.12966402e-04,  1.66668484e-04,  9.64543942e-05,  2.36279346e-04,\n",
       "        -1.85175595e-04, -1.08986773e-04,  2.82107649e-05, -2.34120057e-06,\n",
       "        -3.00199026e-04,  2.43030809e-05, -4.26461309e-04, -1.63353269e-03,\n",
       "        -1.01282974e-04, -1.21223705e-03, -2.73992680e-03, -2.85832997e-04,\n",
       "        -8.23802722e-04,  2.47472501e-03, -4.14762646e-04, -3.15012643e-04,\n",
       "         6.93793758e-04,  4.02101519e-04,  4.43819545e-06,  3.83126608e-04,\n",
       "         2.96456157e-03,  3.12811229e-04, -6.95073368e-06,  3.04996047e-05,\n",
       "        -3.62253538e-03, -5.07655477e-06, -3.73930699e-04,  8.81475105e-04,\n",
       "         2.79647909e-04,  1.25732797e-03, -1.86049577e-03,  1.90095906e-03,\n",
       "         1.54775786e-04,  6.89080625e-04,  9.52614821e-04, -4.26319806e-04,\n",
       "         2.18575378e-03,  2.48512970e-06, -7.27869745e-04, -1.58203329e-04,\n",
       "         4.78394613e-05,  8.02421651e-04,  7.45586658e-05, -3.90724417e-05,\n",
       "        -1.31212198e-03,  5.01617498e-04,  2.11365218e-03,  5.30491758e-04,\n",
       "         4.14660433e-04,  7.22034456e-05,  4.78856004e-04, -9.33390220e-06,\n",
       "         9.02358152e-04, -1.23797028e-04, -1.98902548e-04, -9.43705818e-05,\n",
       "         3.84800805e-04,  1.56482938e-03,  2.97633233e-04,  7.37556303e-03,\n",
       "        -1.12286813e-04, -2.05522892e-03,  4.13600101e-05, -4.84326563e-04,\n",
       "         2.56976316e-04, -5.46870579e-05,  1.73300199e-04, -9.78402561e-04,\n",
       "        -6.61020749e-04, -9.14164848e-05, -2.88762705e-04,  9.70354246e-04,\n",
       "        -5.14666783e-04,  2.66400166e-04, -7.82725343e-04,  1.67231821e-03,\n",
       "        -2.75734230e-04, -4.87169484e-03,  4.59023024e-04, -2.48373952e-03,\n",
       "        -9.31695220e-04,  7.50383595e-04, -3.93391238e-04,  4.98495647e-04,\n",
       "         1.31162291e-03,  9.03703389e-04, -1.70445000e-03, -2.66023038e-04,\n",
       "        -9.09936280e-05, -7.40288699e-04, -1.28684289e-04,  2.04379042e-03,\n",
       "         1.22501806e-04,  5.81860295e-05,  4.35539463e-04, -1.95982757e-05,\n",
       "        -8.84663663e-04, -1.76574872e-03, -1.25953793e-05, -2.00273891e-04,\n",
       "        -3.55292723e-04, -2.69140553e-04,  1.99008966e-03, -2.33434796e-04,\n",
       "         4.87266993e-03, -5.79211810e-05,  8.69801268e-04,  6.13285811e-04,\n",
       "        -1.11831725e-03, -8.03256175e-04, -2.85964234e-05,  1.90442917e-03,\n",
       "         5.91633259e-04,  2.23683055e-05, -2.89818883e-04, -2.19867743e-05,\n",
       "         9.18804668e-04,  3.73670744e-04,  1.66086436e-04, -1.45365996e-03,\n",
       "        -6.12507341e-04, -3.16168152e-04,  6.63923041e-04, -2.48898650e-05,\n",
       "        -1.68071929e-05,  1.36894814e-04, -6.76377502e-04, -4.88226651e-04,\n",
       "        -4.33577457e-04,  1.02552200e-04,  4.36946953e-04, -3.83641047e-04,\n",
       "        -8.39017914e-04,  2.80868717e-05,  1.80073737e-04, -5.35532832e-04,\n",
       "        -2.32992624e-03,  1.88151898e-04,  1.12665130e-03,  2.74252125e-05,\n",
       "        -2.80185457e-04, -4.79724928e-04,  5.49971774e-05, -6.20511128e-05,\n",
       "         7.79898197e-04,  3.40787927e-04, -2.28929333e-04, -4.93544103e-05,\n",
       "         7.48076476e-04,  3.74094598e-05,  1.65885454e-03,  1.37004436e-05,\n",
       "         6.68635039e-05,  6.40012964e-04, -1.43737823e-04,  1.47925195e-04,\n",
       "         2.68512842e-04, -1.30840726e-06, -2.93428847e-03, -2.02170646e-04,\n",
       "        -1.90822466e-04, -5.43616188e-05,  6.21536019e-05,  7.31677981e-04,\n",
       "        -2.65549112e-04, -3.38466227e-04, -7.53123779e-04,  1.55383867e-04,\n",
       "         8.14644081e-05, -6.66998851e-04,  6.09974493e-04, -1.45682265e-04,\n",
       "         6.00860221e-04,  9.39932070e-05, -1.02520199e-03, -2.17829729e-04],\n",
       "       dtype=float32),\n",
       " array([0.91792583, 0.8898919 , 0.9376755 , 0.99393624, 1.0128669 ,\n",
       "        0.8571367 , 1.0303843 , 0.9735506 , 0.85869825, 0.9024709 ,\n",
       "        0.76258147, 0.9606455 , 1.0674462 , 0.65613633, 0.8780849 ,\n",
       "        0.9467241 , 1.5858107 , 1.0027108 , 1.1014776 , 0.92429876,\n",
       "        0.863349  , 0.96120155, 0.8778498 , 0.88293314, 1.0064017 ,\n",
       "        0.88261455, 0.9843369 , 0.92795527, 1.0829679 , 0.9308803 ,\n",
       "        0.9750025 , 0.9918184 , 0.94085115, 0.84269416, 0.8616329 ,\n",
       "        0.9854625 , 0.8812298 , 1.2010356 , 0.8787142 , 0.9888822 ,\n",
       "        0.9410213 , 0.9564118 , 0.86673737, 0.985582  , 1.1649387 ,\n",
       "        0.8660105 , 1.0789819 , 0.80081266, 0.8888063 , 1.1942219 ,\n",
       "        1.0354384 , 0.998157  , 1.0320623 , 0.9844407 , 0.8649651 ,\n",
       "        0.9079048 , 1.0130277 , 0.93932706, 1.0372715 , 0.8606458 ,\n",
       "        0.8814646 , 0.93828666, 1.010216  , 1.0445492 , 1.0685233 ,\n",
       "        0.8390339 , 0.9163586 , 0.89788556, 0.7818083 , 0.9728853 ,\n",
       "        0.88828576, 1.0532665 , 0.9226883 , 0.8516159 , 0.8408381 ,\n",
       "        1.0496976 , 0.9009232 , 1.176865  , 1.0989532 , 0.92088205,\n",
       "        1.0193456 , 1.0359704 , 1.1220402 , 0.91916174, 1.0222101 ,\n",
       "        0.90133405, 0.9862711 , 0.9016639 , 1.1200668 , 1.0417632 ,\n",
       "        1.0971698 , 0.89987725, 1.146898  , 0.9246307 , 0.87794894,\n",
       "        0.9235197 , 0.82611567, 1.1218501 , 0.7888189 , 1.1385543 ,\n",
       "        0.85535043, 0.77005106, 0.94641775, 1.0020242 , 0.8050252 ,\n",
       "        1.2569187 , 0.9620769 , 1.0817714 , 0.889855  , 1.1035808 ,\n",
       "        0.8374327 , 0.9219872 , 0.9599229 , 1.0574678 , 0.92859894,\n",
       "        0.91464007, 0.8600179 , 0.9619953 , 0.79891163, 1.0317221 ,\n",
       "        1.1817725 , 0.87883   , 0.9266847 , 0.97191274, 0.8728676 ,\n",
       "        1.1169033 , 1.1111884 , 1.0447061 , 1.1031722 , 0.79392046,\n",
       "        0.97365695, 1.0438347 , 0.9494074 , 0.9306274 , 0.9771817 ,\n",
       "        1.03457   , 1.0152335 , 0.91486466, 0.90248257, 0.98543596,\n",
       "        0.9284511 , 1.053341  , 0.94190675, 0.87516415, 0.774789  ,\n",
       "        0.93556774, 0.7685887 , 0.902675  , 0.93162316, 0.90954566,\n",
       "        0.6938599 , 0.9216708 , 0.914773  , 1.066336  , 1.074607  ,\n",
       "        1.0733862 , 0.8618724 , 0.9006824 , 0.9005018 , 0.9364828 ,\n",
       "        0.96514744, 0.8926204 , 1.3062781 , 0.76038265, 0.95643395,\n",
       "        1.2290957 , 1.1025182 , 0.93818724, 0.92915165, 0.9684314 ,\n",
       "        0.97708625, 1.0174484 , 1.0991173 , 1.3856664 , 0.8946249 ,\n",
       "        0.8557161 , 0.9235986 , 0.97084355, 1.0799923 , 1.0116738 ,\n",
       "        0.94259864, 1.2017161 , 1.0798653 , 0.9581951 , 0.87152684,\n",
       "        0.8056137 , 1.1769803 , 0.98932374, 0.7682912 , 1.1432534 ,\n",
       "        0.84255886, 1.0499917 , 1.0313991 , 1.5074307 , 0.9800553 ,\n",
       "        0.9118518 , 1.0126332 , 0.90027434, 1.1523343 , 0.94138145,\n",
       "        1.0709604 , 0.98274785, 1.0632253 , 0.8553329 , 0.95393395,\n",
       "        0.8874587 , 0.89872926, 1.0203674 , 0.92890924, 0.914134  ,\n",
       "        0.9610976 , 1.0367626 , 1.0575501 , 1.2954623 , 0.9278824 ,\n",
       "        0.93632287, 0.9118012 , 0.8069821 , 0.9277098 , 0.8763148 ,\n",
       "        0.95646185, 0.9792774 , 0.80528677, 0.92486167, 0.7772962 ,\n",
       "        1.4189968 , 1.0359329 , 0.9061863 , 0.91879356, 1.2238653 ,\n",
       "        1.0487059 , 0.77605957, 0.9105265 , 1.0384984 , 1.0267385 ,\n",
       "        0.90341914, 1.0370308 , 1.085353  , 0.74375755, 0.85227066,\n",
       "        0.9532032 , 0.9823786 , 0.90175706, 0.80483854, 0.9825092 ,\n",
       "        0.8851562 , 0.9454534 , 0.9262035 , 0.9181641 , 0.879898  ,\n",
       "        1.0960649 , 0.6911089 , 0.8552921 , 0.9728188 , 1.1083097 ,\n",
       "        0.82181793, 1.02774   , 0.895679  , 0.81824124, 1.0446026 ,\n",
       "        1.0465425 , 0.80862933, 0.9302704 , 0.9921354 , 0.871986  ,\n",
       "        0.79000694, 0.87270427, 1.0094172 , 1.0108535 , 0.91708076,\n",
       "        1.2472025 , 0.86999   , 0.9881129 , 0.8773236 , 0.8883182 ,\n",
       "        0.843409  , 0.97640187, 0.9946794 , 0.8956084 , 0.9016553 ,\n",
       "        0.95408314, 0.9619848 , 0.7911747 , 0.9001411 , 0.88376105,\n",
       "        0.9969811 , 1.5293223 , 0.9127699 , 0.97980654, 1.1286755 ,\n",
       "        1.0523282 , 0.9467834 , 1.037631  , 1.4194918 , 1.1833838 ,\n",
       "        1.0439391 , 0.8351209 , 1.1161134 , 0.99992913, 0.93488544],\n",
       "       dtype=float32),\n",
       " array([-5.08939266e-01, -8.15920532e-02, -2.33169928e-01,  9.86444354e-02,\n",
       "         4.18342799e-02, -1.22494422e-01,  2.31686875e-01,  8.82172808e-02,\n",
       "        -3.31662774e-01, -5.05322397e-01,  1.84726529e-02,  1.31217241e-02,\n",
       "         2.98121810e-01, -4.19075519e-01, -1.81753024e-01, -2.27430016e-01,\n",
       "         6.76215589e-01, -5.63421808e-02,  9.85162519e-03,  2.90249497e-01,\n",
       "        -1.36220977e-01, -1.41124606e-01, -5.58194220e-02, -1.13306284e-01,\n",
       "         1.25596404e-01, -1.35147572e-01, -1.83111876e-01, -2.12516040e-01,\n",
       "        -3.55253845e-01, -1.52156830e-01, -1.55207708e-01, -1.32989526e-01,\n",
       "        -4.98650335e-02, -1.21631183e-01,  6.22498654e-02,  1.29973426e-01,\n",
       "        -2.54842043e-02,  4.57763188e-02,  6.47902265e-02, -3.49355251e-01,\n",
       "        -2.17337564e-01, -1.57195404e-01, -5.53189576e-01, -2.70875152e-02,\n",
       "         9.88719836e-02, -6.47241116e-01,  2.91358624e-02, -2.10795969e-01,\n",
       "        -2.24865675e-01,  1.26597986e-01, -7.85543546e-02,  1.80492848e-01,\n",
       "         1.59001052e-01, -2.22741544e-01, -3.47115517e-01,  2.19253134e-02,\n",
       "        -2.97426973e-02, -1.50831699e-01, -2.57818848e-01,  4.80170734e-03,\n",
       "        -2.68293530e-01, -2.23853812e-01, -1.84690684e-01, -9.96107385e-02,\n",
       "         1.01197444e-01, -2.21983716e-02, -2.70360649e-01, -2.59154774e-02,\n",
       "        -1.16786271e-01, -5.87937608e-02, -2.94015914e-01,  3.17041832e-03,\n",
       "        -4.42497671e-01, -1.82460442e-01, -4.08126749e-02, -1.08243994e-01,\n",
       "        -9.11651030e-02, -4.21090312e-02, -6.50922433e-02, -1.90240741e-01,\n",
       "        -1.14798106e-01,  1.49442047e-01,  3.60509157e-01, -2.66247362e-01,\n",
       "        -5.69856763e-02, -1.60377800e-01, -2.69993573e-01, -2.15746388e-01,\n",
       "         1.15879476e-01,  2.15997711e-01,  3.57007012e-02, -6.97582290e-02,\n",
       "         2.56418753e-02, -3.04330319e-01, -7.39920855e-01, -1.83006898e-02,\n",
       "        -8.09812266e-03,  3.13318223e-02, -1.33434609e-01,  2.92221364e-03,\n",
       "        -9.27557424e-02, -3.10500652e-01, -5.88352792e-02, -1.74837828e-01,\n",
       "        -2.39082396e-01, -5.70101142e-02,  1.52700879e-02,  1.26904517e-01,\n",
       "        -1.33012176e-01,  1.30640194e-01, -1.20526619e-01,  3.74694765e-02,\n",
       "        -1.78986669e-01, -4.41666134e-02,  4.02040547e-03, -1.94361180e-01,\n",
       "        -2.18399137e-01, -8.34634542e-01, -9.23200771e-02, -3.83835845e-02,\n",
       "         2.32188374e-01, -7.20769405e-01, -4.15321559e-01,  4.99308258e-02,\n",
       "        -6.11348510e-01,  6.54859692e-02,  1.70731768e-01, -3.06926109e-03,\n",
       "        -7.66241476e-02, -2.82977194e-01, -9.76683348e-02, -2.47813612e-02,\n",
       "         2.69681185e-01, -2.22746268e-01, -2.11072266e-01,  6.33951873e-02,\n",
       "        -1.74528807e-02, -2.13263318e-01, -7.01333443e-03, -2.81659663e-01,\n",
       "         5.45805916e-02, -3.49617839e-01, -3.02180350e-02,  2.10566446e-01,\n",
       "        -2.06831679e-01, -1.79555774e-01, -2.35066459e-01, -2.08185256e-01,\n",
       "        -4.02089983e-01, -1.68220792e-02, -1.96332838e-02, -2.13578686e-01,\n",
       "        -1.09053731e-01, -6.22360501e-04, -1.49545232e-02,  1.76233221e-02,\n",
       "        -3.04134786e-01, -9.84992012e-02, -1.44555911e-01, -4.99480903e-01,\n",
       "        -4.22194630e-01, -3.40999871e-01,  1.64734960e-01, -2.34608024e-01,\n",
       "        -7.44091198e-02, -3.66405733e-02, -5.15772104e-02, -1.24461092e-01,\n",
       "         1.46470554e-02, -7.49897808e-02, -2.18209043e-01,  1.24970786e-01,\n",
       "        -4.66908179e-02,  1.60605505e-01, -1.52216535e-02,  1.54782012e-01,\n",
       "        -5.29751703e-02,  1.14670731e-01,  1.21241264e-01, -8.05997401e-02,\n",
       "         1.11609302e-01, -4.46344726e-02, -7.70755783e-02, -1.46548539e-01,\n",
       "        -3.76641750e-01, -2.63792723e-01,  2.80605614e-01, -7.73272887e-02,\n",
       "        -1.40115052e-01,  8.37678984e-02,  1.40116289e-01, -4.60815094e-02,\n",
       "         3.15053985e-02,  1.48204088e-01, -1.67707294e-01, -3.24226707e-01,\n",
       "         2.74218805e-02, -1.74149647e-01, -4.97175045e-02,  3.85419503e-02,\n",
       "        -1.36274993e-01, -3.04775655e-01,  3.97324823e-02, -2.99342692e-01,\n",
       "        -1.42734349e-01,  6.91965641e-03,  1.51110828e-01, -5.65744489e-02,\n",
       "         9.65713859e-02, -3.05758476e-01, -2.96614677e-01,  4.23790216e-02,\n",
       "         7.53165260e-02,  6.47630021e-02,  1.28239229e-01, -1.65939152e-01,\n",
       "         7.38967359e-02, -5.17542601e-01, -3.44813824e-01,  6.10066652e-02,\n",
       "        -1.58348888e-01, -1.26053602e-03, -2.25825951e-01, -1.41970858e-01,\n",
       "        -4.53665197e-01,  7.14008451e-01,  7.93103054e-02, -6.94602653e-02,\n",
       "        -2.62115091e-01, -2.05670390e-02,  2.41368130e-01, -3.00607771e-01,\n",
       "        -1.90071389e-01, -1.33526728e-01,  2.45898426e-01, -2.14677617e-01,\n",
       "        -4.89692064e-03,  1.77780613e-01, -4.33688134e-01, -4.74880517e-01,\n",
       "        -2.54600272e-02, -8.63317698e-02, -2.00679883e-01, -1.93987712e-01,\n",
       "         4.58046719e-02,  7.66507071e-03, -5.40421009e-01, -2.18459144e-01,\n",
       "        -3.36620450e-01,  5.53974137e-02, -2.53582925e-01, -2.73457348e-01,\n",
       "        -1.75241455e-01,  1.95034936e-01, -1.62401255e-02, -1.85250044e-01,\n",
       "         1.81432217e-01, -4.98237796e-02, -1.45358294e-01,  1.21982336e-01,\n",
       "        -1.91241592e-01, -2.01335087e-01, -6.69787601e-02, -2.81404927e-02,\n",
       "        -3.71523023e-01, -1.09281190e-01, -3.30574751e-01, -2.55690575e-01,\n",
       "        -2.59182323e-02, -9.73075777e-02,  9.98381674e-02,  4.08777446e-02,\n",
       "        -1.91710010e-01, -2.50606406e-02,  2.62471810e-02, -2.92922914e-01,\n",
       "        -4.89504449e-02, -1.29847288e-01, -3.09133917e-01, -3.56450766e-01,\n",
       "        -1.97037101e-01,  1.78951249e-02, -2.90936708e-01,  3.49784759e-03,\n",
       "        -3.30771834e-01,  5.30964918e-02,  2.80472308e-01, -1.54052064e-01,\n",
       "         2.60294713e-02,  1.03668995e-01, -5.04163168e-02, -1.23024218e-01,\n",
       "         2.97111347e-02, -5.22059835e-02,  8.40283707e-02,  1.45860255e-01,\n",
       "        -1.36953771e-01,  3.79978754e-02, -1.60902217e-01, -1.80230096e-01],\n",
       "       dtype=float32),\n",
       " array([ 1.62064112e+06, -1.71407362e+06, -1.32301436e+04, -1.57579875e+05,\n",
       "        -8.58197422e+04, -7.43552250e+05, -1.35956438e+05,  4.77297656e+05,\n",
       "         1.03247019e+06,  2.55237475e+06,  4.72046211e+04, -3.59386469e+05,\n",
       "         1.54306212e+06, -3.43694625e+06, -1.11116575e+06,  1.07082800e+06,\n",
       "        -8.98082875e+05, -5.28309219e+04, -1.46341375e+06,  3.49201355e+02,\n",
       "        -5.06877438e+05,  5.19182062e+05, -8.93856562e+05,  1.14429100e+06,\n",
       "         5.91002227e+04, -1.43885862e+06,  3.89313225e+06, -2.31844450e+06,\n",
       "         1.55059700e+06,  3.12521200e+06, -9.50797625e+05,  1.85186578e+05,\n",
       "         5.15416281e+05, -2.36037520e+04,  1.37612775e+06,  1.65770762e+06,\n",
       "         1.00121731e+06,  9.77309938e+05,  7.23232625e+05,  6.11629625e+05,\n",
       "         1.16227100e+06,  1.20217200e+06,  4.01621281e+05,  1.66672462e+06,\n",
       "         9.81893250e+05,  1.90479700e+06,  4.36995094e+05, -3.97512969e+04,\n",
       "         1.90421500e+06,  1.95554550e+06,  9.87284562e+05,  3.88241484e+04,\n",
       "         1.64145969e+05,  7.81813375e+05,  1.08402600e+06,  1.67477888e+06,\n",
       "         5.63640000e+05,  8.92882000e+05,  1.32798175e+06, -2.95146050e+06,\n",
       "         1.15368138e+06,  3.94924594e+05,  2.66039400e+06,  2.13405675e+06,\n",
       "         2.15125016e+05,  1.57680412e+06,  3.72147656e+05,  2.73703219e+05,\n",
       "         1.79360588e+06,  1.83630162e+06,  1.77480512e+06,  9.85095750e+05,\n",
       "         4.47841016e+04, -7.51596719e+04,  8.90415500e+05, -2.76450220e+03,\n",
       "         1.73928938e+06,  1.11755850e+06,  1.37364150e+06,  7.70364938e+05,\n",
       "         1.39620950e+06,  1.04197288e+06,  7.45050375e+05,  3.80589438e+05,\n",
       "         1.76699212e+06, -7.15720875e+05,  1.15031562e+05,  3.98719225e+06,\n",
       "        -3.94161812e+05,  1.27733200e+06,  1.22250875e+06,  9.93860688e+05,\n",
       "         1.34715088e+06,  2.18511200e+06,  2.25566450e+06, -1.12820975e+06,\n",
       "         1.50233562e+06,  9.04156312e+05, -1.69138612e+06,  8.60244062e+05,\n",
       "         2.21138650e+06, -7.40284312e+05, -2.51292400e+06,  6.47938250e+05,\n",
       "         2.15816925e+06,  2.67321000e+06, -2.49736825e+06,  6.17211938e+05,\n",
       "         3.25311906e+05, -5.20400900e+06, -8.83743062e+05,  3.69772875e+05,\n",
       "         1.64040912e+06, -3.39787719e+05,  6.59116812e+05,  1.54405088e+06,\n",
       "        -4.95092562e+05,  1.10308288e+06,  2.21889975e+06, -7.91836133e+03,\n",
       "        -9.05837734e+04,  1.24986100e+06,  2.18436900e+06,  3.85842800e+06,\n",
       "        -1.00430700e+06,  1.95385906e+05,  7.83897938e+05,  1.40707525e+06,\n",
       "         1.84724200e+06, -1.17755612e+06, -2.52203250e+06, -1.92709050e+06,\n",
       "         6.95737438e+05,  5.88477312e+05, -1.10519344e+05, -3.29359475e+06,\n",
       "        -9.12854844e+04,  7.99366000e+05,  2.52145672e+05, -7.29552656e+04,\n",
       "         1.70530562e+06,  6.88287000e+05,  2.19037500e+06, -5.13612531e+05,\n",
       "         2.04215594e+05,  2.59371100e+06,  2.11726875e+06,  1.97839512e+06,\n",
       "         5.68696188e+05,  1.44519038e+06,  1.94641962e+06, -1.82457578e+05,\n",
       "         8.27128125e+05,  7.67421812e+05,  2.88692500e+05, -1.77471612e+06,\n",
       "        -3.44624050e+06,  1.94474050e+06, -4.41060969e+05,  5.33241750e+05,\n",
       "         6.70940812e+05,  1.73750088e+06, -9.43725938e+05, -1.89663200e+06,\n",
       "        -1.12413312e+05, -6.66448875e+05,  1.18037525e+06, -3.39985500e+05,\n",
       "         4.86015195e+04,  9.78322062e+05,  1.84415262e+06,  7.27413438e+05,\n",
       "        -6.69660750e+05,  4.30552125e+05,  1.70438175e+06,  1.85552138e+06,\n",
       "         1.61101031e+05,  1.17132961e+05,  2.22399025e+06,  1.28662412e+06,\n",
       "         1.20086312e+06,  1.74855038e+06,  1.33414438e+06, -1.48873012e+06,\n",
       "         3.99130844e+05,  1.20145888e+06, -4.50052062e+05,  4.43615156e+05,\n",
       "         1.42556050e+06, -1.24067852e+05,  2.07980162e+06,  1.94854750e+06,\n",
       "        -3.64599102e+04,  3.90079875e+05, -8.22939188e+05,  1.47035338e+06,\n",
       "         7.81773438e+04, -7.30821812e+05,  9.08127938e+05,  2.98961650e+06,\n",
       "        -1.36488400e+06, -9.40331812e+05, -7.53549453e+04,  3.58774188e+05,\n",
       "         1.11015162e+06,  8.10507688e+05,  4.74209625e+05, -5.05021445e+04,\n",
       "        -8.40104812e+05,  1.53430225e+06,  1.35211838e+06, -4.00039500e+05,\n",
       "         3.23921406e+05,  1.60418862e+06, -2.59062575e+06,  5.74277562e+05,\n",
       "        -1.97820650e+06,  1.65436500e+06,  2.51442800e+06, -7.34226062e+05,\n",
       "         1.12108712e+06,  1.05018238e+06,  7.83551625e+05,  9.74231938e+05,\n",
       "         1.46915188e+06, -4.31000406e+05, -2.65205700e+06, -2.47045325e+06,\n",
       "         1.41432075e+06,  1.43973962e+06,  2.65359375e+06,  2.44556500e+06,\n",
       "         1.22230000e+06, -5.84504562e+05,  1.71909738e+06, -1.22898438e+06,\n",
       "         1.75781900e+06,  1.08378650e+06,  2.11802281e+05,  2.03279012e+06,\n",
       "         6.73494438e+05,  1.44412350e+06, -1.18681266e+05,  5.05747938e+05,\n",
       "         1.58901038e+06,  2.23348078e+05,  2.26813850e+06,  1.56074925e+06,\n",
       "         1.27484400e+06,  6.09113875e+05,  1.28983138e+06,  3.32816375e+05,\n",
       "        -1.12192625e+06,  3.23145000e+06,  9.16369875e+05,  2.77976850e+06,\n",
       "         1.53524297e+05,  2.07802050e+06,  2.03097788e+06,  1.26888288e+06,\n",
       "        -1.08485575e+06, -6.59571875e+05,  9.97218312e+05, -9.72110375e+05,\n",
       "         3.10836100e+06,  8.90656812e+05, -2.30380750e+06,  1.18816484e+05,\n",
       "        -1.63739512e+06,  1.68837275e+06,  2.63186025e+06, -6.33000375e+05,\n",
       "        -3.61818938e+05,  1.13777912e+06,  8.77527250e+05,  1.22357180e+05,\n",
       "         1.28410700e+06, -1.36415975e+06, -2.14596200e+06, -2.74519281e+05,\n",
       "         2.05961462e+06, -2.64456275e+06,  1.01896862e+06, -2.40141297e+05,\n",
       "         2.57765371e+04,  4.01560562e+05,  7.62848594e+04,  7.61126688e+05,\n",
       "         1.50608150e+06, -1.50720797e+05, -3.34328438e+05, -5.70324062e+05,\n",
       "         1.29999012e+06,  9.95451062e+05,  1.55653138e+06,  1.57515162e+06,\n",
       "         1.01100012e+06,  4.41264219e+04,  2.06138112e+06,  3.73278344e+05],\n",
       "       dtype=float32),\n",
       " array([8.0009534e+15, 3.8526278e+15, 7.1840393e+15, 4.3704792e+14,\n",
       "        3.4826571e+14, 6.9992029e+14, 4.5758622e+14, 1.1664382e+15,\n",
       "        6.2479201e+15, 8.6564099e+15, 1.2178518e+15, 2.2747583e+15,\n",
       "        2.5396657e+15, 1.2689793e+16, 2.0510851e+15, 7.2452904e+15,\n",
       "        3.7066741e+15, 1.7028957e+15, 2.2385363e+15, 3.3741046e+15,\n",
       "        4.1694633e+15, 8.2966709e+14, 2.1428476e+15, 6.7679944e+15,\n",
       "        6.1224712e+14, 2.4785945e+15, 1.8013922e+16, 6.5241605e+15,\n",
       "        2.8307764e+15, 1.4383903e+16, 1.9128592e+15, 2.1598619e+15,\n",
       "        2.1070622e+15, 2.6924946e+15, 4.2666890e+15, 4.0924722e+15,\n",
       "        5.0647559e+15, 2.2713027e+15, 1.2472271e+15, 1.4777640e+15,\n",
       "        5.6076779e+15, 6.2580868e+15, 1.0243857e+16, 5.5348143e+15,\n",
       "        1.5193847e+15, 3.4718408e+15, 1.2920714e+15, 5.8273907e+15,\n",
       "        6.5744611e+15, 1.0336727e+16, 1.5992547e+15, 4.1581055e+14,\n",
       "        1.4968280e+15, 3.2754604e+15, 2.0408443e+15, 6.4519246e+15,\n",
       "        1.0998964e+15, 1.5115681e+15, 6.4318687e+15, 1.0412130e+16,\n",
       "        1.6721663e+15, 1.4560108e+15, 7.3049904e+15, 9.2060122e+15,\n",
       "        7.4266273e+14, 4.6185528e+15, 1.1774235e+15, 5.5053148e+15,\n",
       "        8.1794914e+15, 5.5684820e+15, 1.9493796e+16, 4.9682743e+15,\n",
       "        7.6269036e+15, 4.9808795e+15, 1.6735892e+15, 9.6497359e+14,\n",
       "        4.7767123e+15, 6.4375241e+15, 2.4591447e+15, 1.4017367e+15,\n",
       "        5.1372635e+15, 2.4764594e+15, 4.4130843e+15, 1.7988641e+15,\n",
       "        1.2982882e+16, 1.9870246e+15, 5.8281471e+15, 1.8699014e+16,\n",
       "        7.5828480e+14, 1.8806963e+15, 4.9644421e+15, 4.2673528e+15,\n",
       "        9.3248024e+15, 5.5584377e+15, 7.6806975e+15, 3.4405998e+15,\n",
       "        2.2207442e+15, 7.6981517e+15, 3.2197383e+15, 1.1556639e+15,\n",
       "        6.2507043e+15, 2.0391940e+15, 2.4824232e+16, 1.6029054e+15,\n",
       "        5.0216688e+15, 8.8555966e+15, 3.5612198e+16, 9.7432924e+14,\n",
       "        4.9639251e+15, 3.1767451e+16, 1.6115351e+15, 1.5085593e+15,\n",
       "        1.1842295e+16, 2.2329156e+15, 4.2278756e+15, 4.7014972e+15,\n",
       "        1.2153236e+16, 6.1730604e+15, 8.1199997e+15, 3.3377079e+15,\n",
       "        2.5189220e+14, 1.6999385e+16, 6.3971251e+15, 1.9972927e+16,\n",
       "        6.2378038e+15, 2.0409557e+15, 3.7936080e+15, 2.6860323e+15,\n",
       "        1.2064032e+16, 2.2740257e+15, 1.8235149e+16, 7.2371622e+15,\n",
       "        1.7794813e+15, 5.1435981e+15, 1.7599317e+15, 1.1258647e+16,\n",
       "        1.3824039e+15, 1.3275837e+15, 1.2253640e+15, 7.4410986e+14,\n",
       "        3.2622617e+15, 1.0535153e+16, 6.8794005e+15, 7.7006019e+14,\n",
       "        9.7404941e+15, 8.3806172e+15, 1.0665224e+16, 7.4281341e+15,\n",
       "        2.0994767e+15, 2.8959716e+15, 1.2866953e+16, 1.4516359e+15,\n",
       "        9.0446139e+14, 6.7460897e+14, 1.4621465e+16, 5.3376624e+15,\n",
       "        1.4051139e+16, 5.6509797e+15, 2.5779067e+15, 4.8513599e+15,\n",
       "        1.0219747e+16, 3.6434535e+15, 1.1148264e+15, 3.7974219e+15,\n",
       "        1.9501762e+15, 3.1664593e+15, 2.5323600e+15, 8.8491858e+15,\n",
       "        6.4821405e+14, 2.6583735e+15, 1.6258027e+16, 2.5632515e+15,\n",
       "        7.3408577e+15, 3.7012891e+14, 7.0761728e+15, 3.5489382e+15,\n",
       "        1.0508151e+15, 4.5601758e+14, 5.1884300e+15, 2.4322977e+15,\n",
       "        3.2021802e+15, 4.2599926e+15, 2.3752683e+15, 3.6109111e+15,\n",
       "        1.0766604e+16, 1.9839169e+15, 6.7654580e+14, 5.8271303e+15,\n",
       "        6.0682439e+15, 4.3936181e+15, 5.2521620e+15, 4.7278415e+15,\n",
       "        1.2984269e+15, 1.6160680e+15, 3.0995458e+15, 2.9861474e+15,\n",
       "        1.0073942e+15, 7.1225193e+15, 2.5089704e+15, 1.0867660e+16,\n",
       "        5.5583904e+15, 1.1828769e+15, 1.3986680e+15, 4.5636492e+15,\n",
       "        6.0758621e+15, 8.0833625e+15, 5.3789969e+14, 1.1457766e+15,\n",
       "        9.4782616e+15, 6.9400508e+15, 7.4925189e+15, 6.6878187e+15,\n",
       "        1.9203251e+15, 5.3903230e+15, 9.7222995e+15, 5.2590291e+15,\n",
       "        3.5860427e+15, 3.6163276e+15, 1.1029800e+16, 8.4723615e+15,\n",
       "        3.0701183e+15, 3.1611230e+15, 3.4848272e+15, 2.3925094e+15,\n",
       "        9.6450921e+15, 6.3520634e+15, 1.5436517e+16, 9.7581754e+15,\n",
       "        4.4276673e+15, 2.6207834e+15, 2.0506270e+16, 6.5103189e+15,\n",
       "        1.7372716e+15, 5.4503752e+15, 8.5057752e+15, 4.0581028e+15,\n",
       "        9.3287592e+15, 2.3734829e+15, 3.5240564e+15, 6.4805854e+15,\n",
       "        6.3863265e+15, 2.6341684e+15, 1.8774511e+15, 6.1521058e+14,\n",
       "        2.5555463e+15, 3.0736966e+15, 4.9151182e+15, 5.1466513e+15,\n",
       "        9.3231274e+15, 1.5061923e+15, 1.8406015e+15, 2.5688589e+15,\n",
       "        5.9171394e+15, 1.4374932e+16, 1.1691004e+15, 1.2739898e+16,\n",
       "        1.9354191e+15, 6.1061765e+15, 6.0864132e+15, 2.6217036e+15,\n",
       "        1.6667073e+15, 5.2358948e+15, 1.9723168e+15, 7.4332569e+15,\n",
       "        1.2873513e+16, 3.3906458e+15, 5.8779140e+15, 2.5444224e+15,\n",
       "        3.7869878e+15, 3.8697607e+15, 1.1517279e+16, 1.0628633e+15,\n",
       "        3.0445031e+15, 1.7350524e+15, 2.3625139e+15, 1.4028271e+16,\n",
       "        3.2096785e+15, 6.3509289e+15, 5.3421657e+15, 8.5109964e+14,\n",
       "        5.0546863e+15, 1.0629596e+16, 1.3828285e+16, 5.9782128e+15,\n",
       "        1.1297223e+15, 2.9533145e+15, 2.6742916e+14, 4.0826928e+15,\n",
       "        3.2434173e+15, 3.0942283e+14, 1.8008372e+15, 4.4030013e+15,\n",
       "        3.6991995e+15, 1.9536437e+15, 6.1073619e+15, 2.7833428e+15,\n",
       "        2.2154813e+15, 1.0852303e+16, 6.7538651e+15, 6.8223709e+15],\n",
       "       dtype=float32),\n",
       " array([[ 0.00742369, -0.0542587 ,  0.01655843, ..., -0.01047817,\n",
       "          0.04513412, -0.04885244],\n",
       "        [ 0.04615092,  0.08188646, -0.03690555, ..., -0.1400763 ,\n",
       "         -0.01621814, -0.13213989],\n",
       "        [ 0.03004478,  0.00561792,  0.07250994, ..., -0.04909692,\n",
       "         -0.09623371,  0.16092646],\n",
       "        ...,\n",
       "        [-0.02735135,  0.18180636, -0.0299236 , ..., -0.24669032,\n",
       "         -0.11128325,  0.02899261],\n",
       "        [ 0.0837859 ,  0.00246659,  0.0247729 , ...,  0.00314779,\n",
       "         -0.03792947, -0.01743688],\n",
       "        [ 0.07572173, -0.00391776, -0.05466291, ...,  0.05424757,\n",
       "         -0.0847701 , -0.01002266]], dtype=float32),\n",
       " array([-3.77436401e-03,  9.02098720e-04,  6.83926698e-03, -6.62424974e-03,\n",
       "        -4.94135777e-03, -2.89477230e-05, -2.01080111e-03, -8.02084804e-03,\n",
       "         5.25633048e-04,  5.75903198e-03,  2.36886030e-04,  6.85864419e-04,\n",
       "         7.28466315e-03,  9.79965180e-03, -7.03338999e-04, -1.01604871e-03,\n",
       "         5.07177971e-02,  1.23393452e-02,  8.31252709e-03, -1.08407775e-03,\n",
       "         2.26222128e-02,  2.24489369e-03,  1.49223823e-02, -2.18458488e-04,\n",
       "        -7.04369042e-03,  8.05140752e-03,  1.69284474e-02,  6.38672849e-03,\n",
       "         2.07866053e-03, -3.71447601e-03, -1.44887308e-03,  4.17225156e-03,\n",
       "        -7.80798786e-04, -9.05323867e-03, -2.41765543e-03, -6.72801118e-03,\n",
       "         5.37470216e-04, -1.12520205e-03, -1.59989728e-03,  2.41028629e-02,\n",
       "         1.56337162e-03, -1.48706697e-03,  9.33629088e-03,  3.18921520e-05,\n",
       "        -6.84842514e-03, -3.54640000e-03,  2.21584528e-03,  3.51148192e-03,\n",
       "        -1.72531884e-02, -4.61362913e-04, -3.26701626e-03, -1.37669025e-02,\n",
       "         6.89336890e-03, -1.43606635e-02, -8.49686679e-04, -5.41223388e-04,\n",
       "         1.26964611e-03,  2.50909366e-02, -6.26470242e-03,  2.05341639e-04,\n",
       "         6.70416374e-03, -7.10803131e-03,  3.98352789e-03,  2.11798423e-03,\n",
       "         2.42864204e-04, -3.44386935e-04, -4.91309492e-03,  2.25436576e-02,\n",
       "        -7.15938024e-03,  4.44441522e-03,  4.47168201e-03, -9.30294115e-03,\n",
       "         1.14699965e-02, -4.05200664e-03,  1.14453561e-03,  1.26351137e-02,\n",
       "        -6.99199131e-03, -4.48539993e-03, -6.07983395e-03, -2.17366908e-02,\n",
       "        -7.59117119e-03,  3.89552452e-02, -7.63963303e-03,  2.55972554e-04,\n",
       "         8.39680084e-04,  3.60427424e-04, -2.36171158e-03, -1.12887006e-02,\n",
       "         2.89919460e-03,  5.42483898e-03, -2.62836693e-03,  1.82498675e-02,\n",
       "         4.09872318e-03,  8.06210842e-03,  3.83252307e-04, -6.05436182e-03,\n",
       "        -6.57899189e-04, -3.60101927e-04, -5.53274294e-03,  3.42458277e-03,\n",
       "         4.29129321e-03,  3.53732891e-03,  6.61062729e-03, -7.27267703e-03,\n",
       "         1.97406113e-03,  1.09924292e-02, -7.00205128e-05,  1.63392036e-03,\n",
       "         8.38933978e-03, -1.18543045e-03, -4.86028322e-04,  2.94453488e-03,\n",
       "         6.24676049e-03,  9.45419888e-04, -1.26013043e-03, -8.38639494e-03,\n",
       "         2.31384691e-02, -1.04775571e-03,  2.02168212e-05, -2.19918787e-03,\n",
       "        -2.48999009e-03, -4.56093950e-03,  8.18513334e-04,  6.30520590e-05,\n",
       "         9.53287643e-04, -1.77594670e-03,  4.89236927e-03, -4.79278201e-03,\n",
       "         2.05317093e-03, -6.78258063e-03,  7.83885736e-03, -5.33373188e-03,\n",
       "        -4.70205024e-03,  8.65570793e-04, -8.32671952e-03,  3.90874483e-02,\n",
       "        -1.79790240e-03, -1.12594226e-02, -3.67304031e-03, -7.56961002e-04,\n",
       "         1.01152482e-02,  3.29857902e-03, -4.44645733e-02, -5.89839322e-03,\n",
       "         3.66763561e-04,  3.75968590e-03,  3.54740350e-03,  3.66752269e-03,\n",
       "         6.39979960e-03, -7.66026461e-03, -1.46905356e-03,  1.26857935e-02,\n",
       "         7.81930052e-04,  3.26694152e-03, -5.41481003e-03,  1.18132634e-03,\n",
       "         5.52965980e-03,  2.64430325e-03,  7.54880905e-03, -9.46561689e-04,\n",
       "         4.93183313e-03,  1.43257457e-05,  3.91969597e-03, -9.66374110e-03,\n",
       "         8.76056217e-03,  3.21253249e-03, -7.95627199e-03,  7.27649638e-03,\n",
       "        -1.17893107e-02,  1.59940831e-02,  2.91264849e-04,  3.19515495e-03,\n",
       "         1.84941199e-03, -7.85333291e-03, -4.31359978e-04,  7.48178782e-03,\n",
       "         6.81694271e-03,  2.25945166e-03, -1.14249000e-02,  4.38320264e-03,\n",
       "        -5.53719234e-03,  4.01150621e-03, -5.20763779e-03, -3.71346530e-03,\n",
       "        -3.21923825e-03,  1.85893918e-03,  1.05027284e-04, -6.30241865e-03,\n",
       "        -3.52927484e-03, -3.70261958e-03,  3.68958077e-04,  7.06110336e-03,\n",
       "         2.38109566e-02,  1.37064690e-02,  3.94159602e-03, -1.09683792e-03,\n",
       "        -1.12430670e-03, -2.42178468e-03, -2.78530386e-03,  1.53430540e-03,\n",
       "         1.00920908e-02,  1.77180150e-03,  3.82541865e-03, -5.06683765e-03,\n",
       "        -1.35107562e-02, -7.79124722e-03, -6.78840373e-03,  6.88537955e-04,\n",
       "         7.04005687e-03,  8.97241477e-03, -8.52349494e-03,  5.17822476e-03,\n",
       "        -4.48493334e-03,  5.03130723e-03,  3.13133374e-03,  3.03090387e-03,\n",
       "         3.69526009e-04,  2.28945687e-02,  2.59529543e-03,  8.25782865e-03,\n",
       "        -7.48761976e-03,  4.44259495e-03,  1.33212013e-02,  8.97342991e-03,\n",
       "         2.38100556e-03,  7.03100697e-04,  1.70010012e-02,  1.73280586e-03,\n",
       "         1.03540877e-02,  1.01055048e-04,  1.65553973e-03,  1.16251502e-03,\n",
       "         2.57169735e-03,  3.10158939e-03,  2.10822807e-04, -6.33472716e-03,\n",
       "        -1.03371195e-03,  6.31543389e-03, -4.20296891e-03, -1.31908769e-03,\n",
       "        -1.58498157e-02,  3.01095191e-04, -7.32032757e-04, -3.08389263e-03,\n",
       "        -5.40615246e-03, -2.62900628e-03, -8.25995812e-05,  1.01646371e-02,\n",
       "        -1.88080725e-04, -3.93686118e-03], dtype=float32),\n",
       " array([0.9005712 , 0.7961668 , 1.059005  , 0.86079377, 0.91278744,\n",
       "        0.8320615 , 0.9867471 , 0.87923276, 0.8739477 , 1.0392383 ,\n",
       "        0.97962683, 0.8580484 , 1.1700132 , 1.0674574 , 0.9312391 ,\n",
       "        0.98327935, 1.2523961 , 1.1051888 , 0.9143284 , 0.8167686 ,\n",
       "        1.1709106 , 1.1848826 , 1.1151385 , 1.0961338 , 0.9364101 ,\n",
       "        1.2794431 , 0.91526455, 0.86472976, 0.98355883, 0.9310484 ,\n",
       "        0.83059   , 0.98814946, 1.0658414 , 1.0950376 , 1.015063  ,\n",
       "        0.7098727 , 1.018201  , 1.051129  , 1.0063745 , 1.2357203 ,\n",
       "        1.05246   , 0.9468033 , 1.0751396 , 0.992322  , 1.0017323 ,\n",
       "        1.1655335 , 0.8383313 , 1.3258202 , 1.0629623 , 1.0330199 ,\n",
       "        0.97548246, 1.2063789 , 1.0801713 , 1.0855881 , 1.1943328 ,\n",
       "        1.0465087 , 0.9551865 , 1.0324472 , 0.96081656, 0.8040571 ,\n",
       "        0.79646146, 1.0755267 , 0.85616416, 1.3988394 , 1.0004174 ,\n",
       "        1.0855459 , 0.7521742 , 1.1761081 , 1.0567539 , 0.849906  ,\n",
       "        0.98060393, 1.0782003 , 1.0514613 , 0.90867174, 1.0068233 ,\n",
       "        1.0323379 , 0.8994363 , 1.0005769 , 1.0383412 , 1.2801087 ,\n",
       "        1.0933174 , 1.0808402 , 0.89568657, 0.8310289 , 0.9214446 ,\n",
       "        1.0684031 , 0.99461687, 0.9225693 , 0.8431244 , 0.9955007 ,\n",
       "        0.9202908 , 1.0272692 , 0.920403  , 1.0990725 , 0.9340902 ,\n",
       "        0.67397285, 0.70461386, 0.97169787, 0.9419232 , 0.8566924 ,\n",
       "        0.8906971 , 1.1137054 , 0.7765045 , 0.8913694 , 1.0322858 ,\n",
       "        1.1038743 , 0.85119796, 1.0336174 , 1.0510316 , 0.8197    ,\n",
       "        1.0022169 , 1.0617526 , 0.95602626, 0.9594903 , 1.0017086 ,\n",
       "        0.92012364, 1.2194966 , 0.85237116, 0.94534063, 1.09573   ,\n",
       "        0.92895246, 1.0737815 , 1.0123614 , 1.0422617 , 1.1664634 ,\n",
       "        1.07335   , 0.9112663 , 1.0723916 , 0.9904058 , 1.0063702 ,\n",
       "        0.8039572 , 0.91149473, 0.8070904 , 0.9713011 , 1.0413516 ,\n",
       "        1.0291275 , 1.1283908 , 1.0274177 , 0.96826375, 0.8527648 ,\n",
       "        0.9670448 , 1.0957949 , 1.280316  , 1.0930068 , 0.8111863 ,\n",
       "        1.14404   , 1.1071507 , 0.91044736, 0.91179335, 0.8130441 ,\n",
       "        0.79823506, 1.0185108 , 0.9183869 , 1.09975   , 0.80264825,\n",
       "        0.96019876, 0.90648127, 0.96592844, 0.9576156 , 0.8433563 ,\n",
       "        0.9378294 , 0.9291282 , 0.8540452 , 1.046479  , 1.1564946 ,\n",
       "        1.02946   , 1.0775243 , 0.9225363 , 1.1606106 , 0.9637975 ,\n",
       "        1.006591  , 0.9809816 , 1.2609156 , 0.9142266 , 1.0381324 ,\n",
       "        1.1276053 , 1.1447046 , 1.1617682 , 0.86538213, 1.1672643 ,\n",
       "        0.9479502 , 1.0724523 , 0.93921536, 0.851114  , 0.9006536 ,\n",
       "        0.9646857 , 1.116699  , 0.99713457, 1.206051  , 0.88440245,\n",
       "        0.8990754 , 1.0245976 , 0.9034031 , 1.0931405 , 0.8966676 ,\n",
       "        0.88944465, 0.93123573, 1.0969287 , 1.0406069 , 1.0384753 ,\n",
       "        1.0935203 , 1.004109  , 0.82782704, 0.8834682 , 1.1127853 ,\n",
       "        1.0371274 , 0.9479154 , 0.9700994 , 0.98693854, 0.99779415,\n",
       "        1.036357  , 0.9810567 , 0.99492407, 0.94461143, 0.95956355,\n",
       "        1.0456071 , 0.91723526, 1.2709033 , 0.8904173 , 1.0948143 ,\n",
       "        1.074281  , 0.8903563 , 0.84041524, 1.1405191 , 0.9670774 ,\n",
       "        0.93041795, 0.9868763 , 0.80280936, 0.9526422 , 0.79499817,\n",
       "        1.0891873 , 0.7449561 , 1.0773866 , 0.99853367, 0.89226854,\n",
       "        0.95283735, 0.9504707 , 1.0697407 , 1.1797181 , 1.026081  ,\n",
       "        1.1005195 , 0.9792275 , 0.8584643 , 1.0455333 , 0.89343506,\n",
       "        0.9994213 , 0.9403445 , 1.0625458 , 1.1575702 , 1.1073586 ],\n",
       "       dtype=float32),\n",
       " array([ 0.01022152, -0.25299907,  0.18234645, -0.06248271, -0.14014794,\n",
       "        -0.2213914 , -0.02244217, -0.08872528, -0.0048446 ,  0.11759206,\n",
       "        -0.19250062, -0.09788147,  0.15829684,  0.12557901,  0.15305881,\n",
       "        -0.03160519,  0.11453135,  0.10658085, -0.14970417, -0.11953256,\n",
       "        -0.02372269, -0.17340742,  0.11341244, -0.05167917, -0.11681034,\n",
       "         0.09635604, -0.01136311,  0.03468314, -0.02872608, -0.29449603,\n",
       "        -0.58228683, -0.15930025, -0.03268939,  0.26496914, -0.18870519,\n",
       "        -0.09440124, -0.21215007, -0.2661873 , -0.17215183,  0.1583126 ,\n",
       "        -0.14198723, -0.14180087, -0.22911716,  0.06130545,  0.16889058,\n",
       "        -0.00274515, -0.18159622,  0.10392772,  0.0025617 ,  0.03645091,\n",
       "        -0.1128072 ,  0.03495425,  0.02731301,  0.15972102,  0.06945878,\n",
       "        -0.03724081, -0.22838159,  0.19906986, -0.14325158, -0.21812804,\n",
       "        -0.24890764,  0.09696771, -0.17355265,  0.15836635, -0.10006955,\n",
       "         0.1075416 , -0.15784697,  0.118741  , -0.08183143, -0.18593657,\n",
       "        -0.0311763 ,  0.18158562,  0.27428663, -0.10157694, -0.07633168,\n",
       "         0.06428299,  0.03182271, -0.23589964, -0.3641112 ,  0.10530566,\n",
       "         0.12134513,  0.1403885 , -0.31649113, -0.16954666, -0.16987815,\n",
       "        -0.14628747,  0.11414064, -0.10938122, -0.14438206, -0.1685776 ,\n",
       "        -0.27306658,  0.13709936, -0.1463845 ,  0.00134378,  0.05229061,\n",
       "        -0.09517886, -0.01199009, -0.4229856 , -0.03495065, -0.08712856,\n",
       "        -0.19968022, -0.08746785, -0.20247738,  0.1348635 ,  0.24240369,\n",
       "        -0.18502134, -0.26018733, -0.10246465, -0.02064861, -0.26821092,\n",
       "        -0.22791383,  0.31478995, -0.1541995 , -0.17779881,  0.02756234,\n",
       "        -0.18418989,  0.12490603, -0.14736071,  0.06563175, -0.09036703,\n",
       "         0.00756173, -0.09135506,  0.13636515, -0.10961159,  0.01273284,\n",
       "         0.02630628, -0.03165167, -0.05242558, -0.2008404 , -0.0930903 ,\n",
       "        -0.10771405,  0.08932855, -0.19492894, -0.01739355,  0.09179493,\n",
       "         0.12266037,  0.062305  ,  0.01712985, -0.23346299,  0.02838632,\n",
       "        -0.0914381 ,  0.03328134,  0.121467  , -0.06279795, -0.1200861 ,\n",
       "        -0.04896934, -0.01537246,  0.10338087, -0.01526191,  0.1316032 ,\n",
       "        -0.25039646,  0.23623835, -0.5326369 , -0.03545845, -0.11160477,\n",
       "         0.1068508 , -0.34930444, -0.2774494 , -0.0082839 , -0.19412552,\n",
       "        -0.18650489, -0.3680932 , -0.15790342,  0.15040168, -0.11192267,\n",
       "        -0.20896864, -0.10331867,  0.15903863,  0.1490039 ,  0.07083514,\n",
       "         0.03732777, -0.71693754,  0.27788493, -0.05212791, -0.09742345,\n",
       "         0.04145135, -0.05033918, -0.31214777, -0.21843648,  0.15348496,\n",
       "         0.10760824,  0.10390611, -0.2090899 , -0.00372195, -0.03030187,\n",
       "        -0.07283945, -0.06204337,  0.04751696,  0.14599817, -0.14893404,\n",
       "        -0.10477372,  0.0214762 , -0.00190305,  0.12665017, -0.23747927,\n",
       "         0.04851996,  0.25734723,  0.28655788, -0.65448   , -0.1478334 ,\n",
       "         0.14338267, -0.12361798, -0.27367032, -0.01811917,  0.12494184,\n",
       "         0.14391415, -0.14005052, -0.3451329 , -0.2529696 , -0.02215826,\n",
       "        -0.032862  , -0.40331474,  0.07900117, -0.155941  , -0.21844064,\n",
       "        -0.18648887, -0.3428238 , -0.00558171, -0.0717511 , -0.00969525,\n",
       "        -0.0809098 , -0.1865515 , -0.10270058, -0.05036318,  0.08532526,\n",
       "         0.14140692, -0.00773127, -0.09782073, -0.15565705, -0.22676499,\n",
       "        -0.01209085, -0.17129771,  0.09737232,  0.09865855, -0.31353846,\n",
       "        -0.01159548, -0.29720753,  0.04511571,  0.05162588, -0.3791846 ,\n",
       "         0.15076214, -0.05729731, -0.337031  , -0.21684423, -0.20701566,\n",
       "        -0.22230124, -0.27532554,  0.01952512,  0.15648206, -0.08375982],\n",
       "       dtype=float32),\n",
       " array([ 0.59326357,  1.3749748 ,  1.6471441 , -0.3831886 ,  1.7139026 ,\n",
       "         1.715238  ,  0.4785866 ,  0.9663447 ,  2.0288134 ,  0.85325617,\n",
       "         1.6191714 , -1.6191493 , -0.4360904 ,  0.78912324,  1.6243498 ,\n",
       "        -2.2269788 , -2.1815712 ,  0.6064166 ,  1.7722666 ,  2.14578   ,\n",
       "         0.88785565, -0.42901304,  1.5877159 , -0.9999294 ,  1.2700218 ,\n",
       "        -1.9347339 ,  1.3255873 , -0.2529726 ,  1.4953945 ,  0.58797365,\n",
       "         1.0186982 ,  1.557817  , -1.4057796 , -0.4520511 ,  1.645198  ,\n",
       "         0.51390517,  0.97437394, -0.75084513,  1.3397039 , -1.322663  ,\n",
       "         0.637633  ,  1.7865553 ,  0.58933914, -0.84532297, -2.0005898 ,\n",
       "         1.6673386 ,  1.9661275 , -0.8382142 ,  0.84218836,  0.7227737 ,\n",
       "         1.3706288 , -2.3969848 ,  1.0403559 ,  0.8936991 , -1.8805139 ,\n",
       "        -0.32969558, -0.47008651,  0.2367178 , -0.4324008 ,  0.47570515,\n",
       "        -1.0716956 , -2.0997195 , -1.4882833 , -3.232165  ,  2.3427    ,\n",
       "        -0.22814554,  0.9289864 ,  0.40982062, -0.3722808 , -1.5859029 ,\n",
       "         0.51797724, -1.1958256 ,  0.74390966,  0.34037793,  0.23429397,\n",
       "        -2.0993319 ,  1.6514906 ,  1.2336329 ,  0.7157624 ,  1.791059  ,\n",
       "         0.9358614 ,  2.7979999 , -0.50981426,  1.7443479 ,  0.8142006 ,\n",
       "         1.343275  ,  0.8662849 ,  0.915141  ,  1.6515892 ,  0.22350778,\n",
       "        -1.5100794 ,  1.1291226 ,  1.6137276 , -0.4870055 ,  1.1072911 ,\n",
       "         0.98217463, -1.5285419 , -1.472095  , -1.0132229 ,  0.38291374,\n",
       "         0.8399532 ,  1.1654476 ,  1.5212445 ,  0.9439597 ,  3.252372  ,\n",
       "         0.60965836,  0.8086892 , -0.4182013 ,  1.2188777 ,  1.9302506 ,\n",
       "        -1.8231192 , -1.6834792 , -1.4684633 ,  1.1560014 ,  0.86153233,\n",
       "        -0.5083168 ,  0.31635404,  1.5366825 , -1.7534131 , -0.8206519 ,\n",
       "        -0.23527464, -1.3845311 , -0.5645534 ,  2.5250988 , -2.9806774 ,\n",
       "        -0.9970286 , -1.6514957 , -0.8033956 ,  1.2600278 ,  1.6748505 ,\n",
       "         0.6004619 ,  0.85228163,  1.5267569 ,  0.2396032 ,  2.4497137 ,\n",
       "        -1.5578418 , -2.2230833 ,  0.9522478 , -1.0629139 ,  2.6855545 ,\n",
       "         0.99848306, -1.0810572 , -2.2806044 , -1.799705  ,  1.5143389 ,\n",
       "         0.96276146,  0.03533818, -1.0918627 ,  0.503828  ,  0.65382814,\n",
       "         0.61251414,  0.9015822 ,  0.85308164,  1.0470173 ,  0.99163944,\n",
       "        -2.5817468 ,  1.2677816 , -1.9680616 ,  0.52760077,  1.1828551 ,\n",
       "         2.5242276 ,  2.5143387 ,  0.6399405 ,  0.25304914, -1.3140858 ,\n",
       "        -0.91282123,  0.22196534, -2.6832213 ,  0.37608466,  1.9417409 ,\n",
       "        -1.2211155 ,  1.7663711 , -0.09336185,  1.7499156 ,  0.6167845 ,\n",
       "         0.84839344,  2.4241905 , -1.8521473 , -1.3841277 , -1.6545659 ,\n",
       "        -0.91129845, -0.65204823,  1.2034032 ,  0.04160602, -1.6142116 ,\n",
       "        -2.311898  ,  0.7909079 , -2.6950634 ,  3.68742   , -1.0988436 ,\n",
       "        -1.1517122 ,  1.264085  , -1.4404387 ,  1.0008849 ,  1.0729291 ,\n",
       "        -1.4025173 ,  0.13036028, -0.5745292 ,  1.5651913 ,  0.6725086 ,\n",
       "         1.2390956 , -0.1478125 , -0.4542671 ,  0.2238121 ,  1.5623126 ,\n",
       "        -0.38467008,  0.75055987,  1.7953333 ,  1.68418   ,  0.25397116,\n",
       "         1.0349997 ,  1.1735706 , -2.0145237 ,  1.6662108 ,  0.5944609 ,\n",
       "        -0.9646854 ,  1.6197801 ,  2.7048507 ,  0.49430448, -2.115914  ,\n",
       "         1.5656713 ,  0.48191446,  1.5149992 , -1.7592373 , -1.2774023 ,\n",
       "         1.6345421 ,  1.9999762 ,  1.3579291 ,  1.3527256 ,  1.479706  ,\n",
       "        -1.1307393 , -1.4998395 , -1.864231  ,  1.4192969 ,  1.2219036 ,\n",
       "         1.3559394 ,  1.1328843 , -1.6060668 , -2.3607366 ,  0.88765454,\n",
       "        -2.550195  ,  1.9188523 ,  2.2281    ,  1.772656  ,  1.6350532 ,\n",
       "         0.7797478 ,  1.9186711 , -3.071937  , -1.1853694 , -0.29474217],\n",
       "       dtype=float32),\n",
       " array([ 23.314983 ,  15.80128  ,  19.380589 ,   6.9065924,  58.125313 ,\n",
       "         81.33881  ,  22.803009 ,  28.610865 ,  23.091263 ,  11.684098 ,\n",
       "         35.799343 ,  50.618732 ,  24.175808 ,  12.659155 ,  37.03899  ,\n",
       "         25.358582 ,  20.5894   ,  16.487648 ,  39.66007  ,  31.993471 ,\n",
       "         11.832181 ,   7.900103 ,  54.69562  ,   9.105798 ,  23.973276 ,\n",
       "         45.145424 ,  30.772575 ,  14.460569 ,  19.101322 ,  32.23711  ,\n",
       "         22.13969  ,  61.796494 ,  12.912124 ,  36.472904 ,  40.270836 ,\n",
       "         13.707072 ,  33.097607 ,  18.934916 ,  19.883562 ,  10.662363 ,\n",
       "         52.19112  ,  58.295578 ,  49.1901   ,  11.020423 , 100.13222  ,\n",
       "         22.706846 ,  58.909977 ,  15.711191 ,  14.523051 ,   6.951413 ,\n",
       "         41.999046 ,  16.586126 ,   8.373329 ,   7.5407743,  14.4000435,\n",
       "         12.261592 ,  14.142403 ,  27.740349 ,  54.424744 ,  32.451218 ,\n",
       "         38.568413 ,  27.60958  ,  21.896008 ,  27.61999  ,  67.961426 ,\n",
       "         29.415983 ,  38.457203 ,  33.062286 ,  18.099096 ,  47.5798   ,\n",
       "         39.50894  ,  10.391262 ,  37.892807 ,  19.543991 ,  21.67343  ,\n",
       "         68.4151   ,  18.425795 ,  15.460925 ,   7.745764 ,   7.3887506,\n",
       "         84.592735 ,  13.099225 ,  15.93567  ,  56.882454 ,  19.197592 ,\n",
       "         33.451435 ,  10.716377 ,  27.408718 ,  32.116306 ,   6.26978  ,\n",
       "         24.980553 ,  16.36401  ,  37.0889   ,   7.8532677,  47.64753  ,\n",
       "         55.33823  ,  15.51013  ,  59.243702 ,  44.41604  ,  24.376032 ,\n",
       "         18.927563 ,  15.253445 ,  63.813805 ,  29.665434 ,  33.47071  ,\n",
       "         16.932102 ,  17.14412  ,  23.163374 ,  14.718691 ,  29.64298  ,\n",
       "         22.804064 ,  12.379053 ,  22.419876 ,  36.138103 ,  37.08273  ,\n",
       "         13.629416 ,  64.38371  ,  40.663185 ,  17.099901 ,  17.353283 ,\n",
       "         20.284151 ,  18.583479 ,  44.419754 , 119.20578  ,  34.006313 ,\n",
       "         47.6181   ,  22.683403 ,  16.516659 ,  18.746424 ,  53.331284 ,\n",
       "         27.491732 ,  25.283611 ,  27.084272 ,  18.818531 ,  30.887108 ,\n",
       "         21.824728 ,  20.778751 ,  11.745283 ,  31.115185 ,  60.90455  ,\n",
       "         28.392042 ,  11.362638 ,   8.219259 ,  10.739163 ,  21.929794 ,\n",
       "         34.86664  ,  28.848793 , 121.59781  ,   9.892275 ,   9.734452 ,\n",
       "          7.598723 ,  23.471943 ,  18.55853  ,   9.573235 ,  36.068985 ,\n",
       "        131.34949  ,  20.349855 ,  63.08225  ,  33.9304   ,  52.20922  ,\n",
       "         34.83482  ,  88.02445  ,  33.1073   ,  17.708853 ,  15.485539 ,\n",
       "          6.6552505,  15.675102 ,  31.846592 ,  23.951233 ,  16.00751  ,\n",
       "         22.524883 ,  37.05087  ,  21.955061 ,  98.6535   ,  33.577595 ,\n",
       "         13.487136 ,  15.9871645,  28.129606 ,  66.69309  ,  13.719254 ,\n",
       "         33.36697  ,  47.86623  ,  20.910501 ,  12.425573 ,  29.319109 ,\n",
       "         79.70774  ,  39.638546 ,  34.138817 ,  42.685333 ,  16.62384  ,\n",
       "         22.09771  ,  28.863773 ,  19.025671 ,  30.483517 ,  30.441751 ,\n",
       "         30.366943 ,  52.38167  ,  35.32305  ,  24.83403  ,  42.39042  ,\n",
       "         16.452368 ,  48.10769  ,  23.95976  ,  33.50882  ,   8.251898 ,\n",
       "         21.45485  ,  22.741457 ,  47.085533 ,  54.65697  ,  42.35891  ,\n",
       "         20.436068 ,  41.64598  ,  31.788101 ,  21.635971 ,  27.988682 ,\n",
       "         13.776447 ,  36.656082 ,  20.41619  ,  17.71234  ,  11.514119 ,\n",
       "         35.87316  ,  21.22187  ,  19.468288 ,  20.282171 ,  32.454796 ,\n",
       "         36.423294 ,  21.852821 ,  38.295235 ,  18.074049 ,  11.888659 ,\n",
       "         46.394905 ,  32.06207  ,  46.141052 ,  25.743244 ,  21.362696 ,\n",
       "         15.023872 ,  31.111387 ,  14.236035 ,  30.736435 ,  10.781811 ,\n",
       "         28.835684 ,  40.408802 ,  47.204388 ,  15.370399 ,  40.019505 ,\n",
       "         25.668102 ,  36.563763 ,  39.18818  ,  20.760263 ,   6.841977 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.06193679, -0.15641627,  0.20054267, ...,  0.01775917,\n",
       "         -0.06954603, -0.01555244],\n",
       "        [ 0.1077492 ,  0.09108032, -0.07337212, ...,  0.07823298,\n",
       "          0.00142836,  0.05801563],\n",
       "        [-0.01541443,  0.06384596,  0.18618093, ...,  0.28303206,\n",
       "         -0.01331284, -0.11036879],\n",
       "        ...,\n",
       "        [-0.05634698, -0.04723944,  0.01397833, ..., -0.01254631,\n",
       "         -0.01555998,  0.1807611 ],\n",
       "        [ 0.08677542,  0.00780856,  0.07614809, ...,  0.01587948,\n",
       "          0.142967  ,  0.03595217],\n",
       "        [-0.05091135, -0.00161566,  0.36106673, ...,  0.08272286,\n",
       "         -0.03726941, -0.13545032]], dtype=float32),\n",
       " array([-4.25845524e-03,  3.00971163e-03, -4.73997497e-05, -5.09753264e-03,\n",
       "        -6.21653441e-03,  1.26060576e-03,  1.50303217e-03, -2.55253573e-04,\n",
       "         5.62315993e-03, -1.57691725e-03,  3.26673733e-03,  7.49793043e-03,\n",
       "         1.13181595e-03,  3.02041159e-03, -4.99727810e-03,  1.79738167e-03,\n",
       "        -6.00162661e-03,  3.22234794e-03, -3.45695019e-03, -1.73566747e-03,\n",
       "        -6.72488473e-03,  1.37852016e-03, -5.61871752e-03,  1.42321957e-03,\n",
       "         2.59916037e-02,  6.44044718e-04, -4.10416815e-03,  3.73452855e-03,\n",
       "         1.76852942e-03,  1.39733765e-03, -2.01288494e-03,  2.19334313e-03,\n",
       "         6.57960866e-03, -3.65504384e-04, -6.97429467e-04, -5.36617590e-03,\n",
       "         8.92734621e-03, -4.17293701e-03, -1.94791856e-03,  1.09472789e-03,\n",
       "         4.57061251e-04, -1.57461781e-03, -4.11350653e-03,  2.86430633e-03,\n",
       "        -3.19068576e-03, -1.21718360e-04, -2.12040134e-02,  3.70630552e-03,\n",
       "        -3.27360928e-02, -5.33002336e-03,  1.76082645e-03,  5.87826641e-03,\n",
       "         2.63539609e-04,  6.15880685e-03,  1.17529288e-03, -1.26161575e-02,\n",
       "         2.13651615e-03, -4.02345741e-03,  1.66871469e-03,  5.13529684e-03,\n",
       "         2.17128382e-03,  5.79708163e-03, -2.28767225e-04,  8.33764672e-03,\n",
       "        -1.44479778e-02,  1.68750691e-03, -9.08248127e-03, -1.29698766e-02,\n",
       "         2.57234229e-03, -1.75722886e-03, -3.64775560e-03, -2.42480170e-03,\n",
       "        -5.06112259e-03, -4.62370785e-03, -1.20547945e-02,  1.77769386e-03,\n",
       "        -3.53661785e-03, -5.49007533e-03,  4.03670082e-03,  9.17567872e-03,\n",
       "        -2.43311748e-03,  2.62467796e-03,  2.96995822e-05,  8.37001577e-03,\n",
       "         3.89133603e-03,  3.41788344e-02,  7.18293071e-04, -7.80548435e-03,\n",
       "        -1.61025778e-03,  3.90855735e-03,  2.72469362e-04,  5.97762701e-04,\n",
       "         8.78488703e-04,  1.71875127e-03,  5.23771532e-03,  3.75685724e-03,\n",
       "        -2.42380914e-03, -1.06172496e-03,  1.51893962e-03, -1.79429655e-04,\n",
       "         2.61955243e-03,  1.91449723e-03, -3.11775645e-03, -5.17740427e-03,\n",
       "         4.06563655e-03,  1.24090735e-03, -3.71604320e-03, -2.07127468e-03,\n",
       "         8.00960173e-04, -2.38117715e-03, -8.84091016e-04,  1.17087667e-03,\n",
       "         2.22989847e-03, -1.81752932e-03, -1.26852735e-03, -8.95630009e-03,\n",
       "         9.19350481e-04, -3.13469917e-02, -5.08875959e-03,  1.17819768e-03,\n",
       "         5.52469725e-03,  2.36494350e-03,  7.32472865e-03, -3.45903216e-03,\n",
       "        -8.52128898e-04, -9.09272954e-03,  8.40226363e-04,  1.07600681e-04,\n",
       "        -8.06900393e-03, -7.43739307e-04,  3.79730552e-03, -2.71472149e-03,\n",
       "        -1.19221897e-03, -2.85386486e-04, -7.35205645e-03, -1.71293959e-03,\n",
       "        -2.83758901e-03, -4.60358383e-03,  8.72906577e-03,  1.95188203e-03,\n",
       "         8.21330395e-05,  3.45600699e-03,  2.45445780e-03, -2.00215727e-03,\n",
       "        -2.97386246e-03,  1.00719626e-03,  6.12055883e-04, -4.36725747e-03,\n",
       "         2.34731436e-02, -1.58016663e-03, -5.71643608e-03,  2.27141893e-03,\n",
       "         1.40181088e-04,  4.09963913e-03, -6.34619454e-03,  1.48319779e-03,\n",
       "        -3.98337562e-03, -2.53694295e-03,  1.93634152e-03, -1.89684238e-03,\n",
       "         7.01014558e-03,  2.13666609e-03, -2.23831623e-03,  1.09302429e-02,\n",
       "        -2.35991683e-02, -4.76227328e-03,  1.47014402e-03,  8.38860462e-04,\n",
       "         2.29910784e-03,  1.02012430e-03,  2.17695313e-04,  1.34193264e-02,\n",
       "        -4.28330124e-04,  8.41817295e-04,  2.17983988e-03, -4.87321941e-03,\n",
       "         5.95645513e-03,  1.39490445e-03,  4.13077744e-03,  3.41158663e-03,\n",
       "         6.18880754e-03,  6.55903760e-03, -6.67215837e-03, -8.82327498e-04,\n",
       "         1.73293275e-03,  4.70487983e-04,  1.11175422e-02, -7.75591517e-03,\n",
       "         2.69689411e-03, -8.64866562e-03, -1.90607109e-03, -1.01569863e-02,\n",
       "         4.68963059e-04, -1.55929746e-02, -7.45551754e-03,  1.31939724e-03,\n",
       "        -1.37437615e-04, -1.98167400e-03,  1.33986515e-03, -3.72530916e-03],\n",
       "       dtype=float32),\n",
       " array([1.0943253 , 1.0635954 , 1.0148445 , 1.07499   , 1.2008026 ,\n",
       "        1.078975  , 0.94102603, 0.89132535, 0.8430205 , 1.0017501 ,\n",
       "        1.2249224 , 0.96522546, 1.0965366 , 1.1304413 , 0.9470425 ,\n",
       "        1.0204926 , 1.0603238 , 0.9187011 , 1.0445342 , 0.8107077 ,\n",
       "        0.8847158 , 0.9808496 , 1.0769261 , 1.2098758 , 1.106535  ,\n",
       "        1.0041145 , 1.1467135 , 1.0806452 , 1.0337039 , 0.79699993,\n",
       "        1.0837195 , 1.0745437 , 0.9676033 , 0.896565  , 1.0915413 ,\n",
       "        1.2102334 , 1.0971785 , 1.1533679 , 0.99748707, 1.0217962 ,\n",
       "        0.9781905 , 0.9356232 , 1.0411652 , 0.9227855 , 1.0617967 ,\n",
       "        1.0124136 , 1.1439743 , 1.0997894 , 1.3366882 , 1.1044216 ,\n",
       "        1.0492958 , 0.98951876, 1.1077906 , 0.99721473, 0.99014974,\n",
       "        1.1230052 , 0.825502  , 1.0655901 , 1.1036452 , 0.95539784,\n",
       "        1.0481414 , 0.89182013, 1.3364176 , 1.0422485 , 1.0358251 ,\n",
       "        1.0392826 , 1.1634004 , 1.136942  , 1.0690548 , 1.1223618 ,\n",
       "        1.0318618 , 0.88477826, 1.1713732 , 1.0076035 , 1.1305274 ,\n",
       "        1.0123246 , 1.0095508 , 0.8194387 , 0.8158732 , 0.7204922 ,\n",
       "        0.9789903 , 1.0307528 , 0.9406576 , 0.93528986, 0.9219978 ,\n",
       "        0.9854727 , 0.9583811 , 1.0252508 , 1.0484045 , 1.0083189 ,\n",
       "        0.93230456, 1.0774074 , 1.0349481 , 0.9920642 , 0.9250323 ,\n",
       "        1.0241225 , 0.986704  , 0.966263  , 0.90302813, 0.94809204,\n",
       "        1.049453  , 1.2005888 , 0.9765116 , 0.9706374 , 1.1438427 ,\n",
       "        0.9959532 , 1.0572712 , 0.9603532 , 0.883973  , 0.96603686,\n",
       "        0.9502654 , 1.1794429 , 1.012178  , 0.9643193 , 0.97489345,\n",
       "        1.1346078 , 1.0462713 , 1.2218527 , 0.942059  , 0.93803316,\n",
       "        0.9082904 , 1.1343952 , 0.96694994, 1.1025988 , 0.98331064,\n",
       "        1.2255923 , 1.0034348 , 1.1853515 , 0.95727754, 1.0560534 ,\n",
       "        1.1191556 , 0.9655    , 1.0546902 , 0.9800721 , 0.96427596,\n",
       "        0.8889665 , 0.9419219 , 1.0051879 , 1.1752527 , 1.2191519 ,\n",
       "        0.77502996, 0.9623221 , 0.9873399 , 0.9043088 , 0.94241965,\n",
       "        0.9133721 , 0.95561063, 0.8313956 , 1.0475663 , 0.9697464 ,\n",
       "        1.1224437 , 1.0598992 , 0.8628715 , 1.0635903 , 0.9062662 ,\n",
       "        1.0612705 , 0.9502261 , 0.97493887, 0.9911624 , 1.1604458 ,\n",
       "        1.0755441 , 0.9661464 , 0.99163115, 1.0962571 , 1.1933081 ,\n",
       "        1.1899184 , 0.87695223, 1.4011654 , 0.9819269 , 0.9770982 ,\n",
       "        0.8653839 , 1.1410756 , 0.92352635, 0.9326983 , 0.98459095,\n",
       "        1.0069686 , 1.069773  , 0.87987906, 0.88475376, 0.96810454,\n",
       "        1.0250396 , 1.099514  , 1.0142369 , 1.0194119 , 0.99212676,\n",
       "        1.0021038 , 1.0065501 , 0.92404425, 0.986583  , 0.8285029 ,\n",
       "        0.9827747 , 1.043665  , 1.028647  , 1.1751903 , 1.2655661 ,\n",
       "        0.8885609 , 1.0548944 , 0.9915479 , 1.1415849 , 0.7201997 ],\n",
       "       dtype=float32),\n",
       " array([-0.04982193, -0.0692787 , -0.07425086, -0.12315457,  0.21256271,\n",
       "        -0.01589911, -0.07937894, -0.16641146, -0.10263516, -0.12951337,\n",
       "        -0.07821725, -0.05495451,  0.00538979,  0.04095197,  0.10817782,\n",
       "         0.08389822, -0.00535989, -0.4116571 , -0.1412217 , -0.05696008,\n",
       "        -0.06983857, -0.03933499,  0.00732782, -0.09328455,  0.018336  ,\n",
       "        -0.2007612 ,  0.07916486,  0.13100253, -0.10252421, -0.15303224,\n",
       "         0.18492845,  0.02623666, -0.07035467,  0.14643586,  0.10836302,\n",
       "         0.3848092 , -0.02906192, -0.15501158, -0.11563209, -0.0405545 ,\n",
       "        -0.07869339, -0.05242564,  0.06924795, -0.06380344, -0.01622558,\n",
       "        -0.02139576,  0.13347067,  0.08936571,  0.15502872,  0.16683464,\n",
       "        -0.05848496, -0.06276982, -0.05822658,  0.07584973, -0.1129567 ,\n",
       "         0.15345582, -0.1285284 , -0.13247225,  0.04454935, -0.20106168,\n",
       "        -0.09848489, -0.08856808,  0.02656347,  0.05917408,  0.17911051,\n",
       "        -0.07322132,  0.11196083,  0.09176419, -0.00719912,  0.1551343 ,\n",
       "         0.10783871,  0.01761961,  0.03003776, -0.02389774, -0.14220281,\n",
       "        -0.16180515,  0.05921371, -0.24575384, -0.04282761, -0.15035939,\n",
       "        -0.189311  ,  0.09195506, -0.11148379, -0.05827859,  0.01313604,\n",
       "         0.08426549, -0.10387941, -0.07718949, -0.11172239,  0.10121773,\n",
       "        -0.06416265, -0.04754464,  0.07270809,  0.32225516,  0.00241751,\n",
       "        -0.09036382,  0.0225764 , -0.12766829, -0.13492928,  0.09558393,\n",
       "        -0.16831854,  0.164031  , -0.17188181, -0.05775982,  0.07996067,\n",
       "        -0.1203649 , -0.14460662, -0.02607626, -0.09995367, -0.2308679 ,\n",
       "        -0.03814596, -0.08214483,  0.03912142, -0.1904071 ,  0.007904  ,\n",
       "        -0.02579498, -0.08206888,  0.26013967, -0.10047441, -0.1012798 ,\n",
       "        -0.02243255,  0.05103377,  0.06941918, -0.03642936, -0.03427048,\n",
       "         0.32422698, -0.1819731 ,  0.17060128, -0.16325782, -0.2826956 ,\n",
       "         0.2705654 ,  0.11478518, -0.00656886, -0.10738269, -0.20183055,\n",
       "        -0.46795133, -0.03066441, -0.0963438 , -0.02061957,  0.1966107 ,\n",
       "        -0.14819032, -0.13721767, -0.15737185,  0.11994738, -0.03370609,\n",
       "        -0.12102759, -0.09412862, -0.02822415, -0.03640019, -0.06213156,\n",
       "        -0.05374542,  0.05931984, -0.17441174,  0.08548832,  0.00226298,\n",
       "        -0.11517166,  0.09739299,  0.02197738, -0.02349862,  0.05417942,\n",
       "         0.16383624,  0.11932488, -0.05753662,  0.06052611,  0.43460292,\n",
       "         0.0927549 ,  0.03521748,  0.05785649, -0.2719742 , -0.10839272,\n",
       "        -0.23932602,  0.19374219, -0.11982169, -0.00421545, -0.0678221 ,\n",
       "        -0.13518889, -0.2293846 , -0.06284899, -0.25727004, -0.05154095,\n",
       "        -0.04872414,  0.06006701, -0.07722609, -0.01386197,  0.14247318,\n",
       "        -0.09009198,  0.1744814 , -0.09977773,  0.15902053, -0.22303608,\n",
       "        -0.14303161,  0.11149593, -0.08657449,  0.21766935,  0.02308753,\n",
       "        -0.00680167, -0.30743614, -0.00702552,  0.04613017, -0.11861699],\n",
       "       dtype=float32),\n",
       " array([ 2.1675904 ,  2.220037  ,  1.5445849 ,  1.4556717 ,  0.9207557 ,\n",
       "        -1.7196279 ,  1.6225762 ,  1.7128012 , -0.4965853 ,  1.9102466 ,\n",
       "        -1.0664873 , -1.6882164 ,  0.25942445, -1.0224618 ,  1.9391131 ,\n",
       "         1.4729677 ,  1.3425322 ,  1.3440192 ,  1.368989  , -0.10845095,\n",
       "         1.203198  ,  0.97344977,  1.2832373 ,  0.4377846 , -0.73570555,\n",
       "         1.5427561 , -1.5031726 ,  1.9049779 ,  1.2576767 ,  1.2051057 ,\n",
       "        -0.7701887 ,  1.4824286 , -1.0509062 , -0.21231239,  1.1774944 ,\n",
       "        -1.4977857 ,  0.6705935 ,  2.4194107 ,  0.96551204,  1.9892744 ,\n",
       "        -0.9674266 ,  1.6990223 ,  1.5208085 , -1.078711  ,  1.2521701 ,\n",
       "         0.04940916, -1.2299974 ,  1.632318  , -0.9785522 ,  2.342366  ,\n",
       "         0.5606053 ,  2.0757306 ,  1.1073153 ,  0.25645238,  2.0946429 ,\n",
       "        -1.46704   ,  0.5651368 ,  1.162033  ,  2.4556422 ,  0.7496431 ,\n",
       "         1.8469139 ,  2.365097  ,  0.49623966,  2.0476732 , -0.7342186 ,\n",
       "         0.32057858,  2.7339191 ,  1.1428795 ,  1.3220558 , -1.1427153 ,\n",
       "        -1.8659841 ,  0.74507546, -0.31611907, -0.5412347 , -0.939306  ,\n",
       "         2.3424327 , -0.28980824,  1.0607933 , -0.18549542,  1.2686538 ,\n",
       "         1.869814  ,  1.8404413 ,  2.198523  , -1.2512358 ,  1.746598  ,\n",
       "        -1.5592618 ,  1.6896424 ,  0.8637304 , -1.8960273 , -1.1446067 ,\n",
       "         0.999823  ,  0.9135256 ,  0.9076876 ,  0.7687582 ,  0.7657797 ,\n",
       "         0.93638074,  1.7575055 ,  2.23693   ,  0.23565316, -0.78150034,\n",
       "         1.273002  ,  0.837321  ,  2.1902008 , -0.02070249, -0.15202263,\n",
       "         1.5677687 , -0.52063453,  0.6003711 , -0.64146936,  1.951401  ,\n",
       "        -0.7426585 ,  0.4289147 , -1.7805388 ,  2.0368268 ,  1.8874565 ,\n",
       "         1.7682924 ,  1.4451097 ,  0.54199207,  0.33025396,  1.2266725 ,\n",
       "        -0.27984053,  1.0813959 ,  0.9851912 , -1.0452242 , -0.39511272,\n",
       "        -1.3146425 ,  1.310772  , -0.408471  ,  1.5518703 ,  2.2573633 ,\n",
       "         2.1541858 , -0.88136196,  0.30711678, -1.2986479 ,  0.9074875 ,\n",
       "         2.210217  , -0.27565756, -1.2453732 ,  0.54189056, -1.2428125 ,\n",
       "         0.80810106,  1.7966595 ,  1.6036911 , -0.55483574,  1.6214905 ,\n",
       "         2.662691  ,  2.172121  ,  1.3148141 ,  2.3414779 , -1.5700049 ,\n",
       "        -1.2193036 , -1.3986771 ,  2.1774094 , -0.30925906,  0.68345064,\n",
       "        -0.1365056 , -0.12649089,  1.0129974 , -0.664949  , -0.09826931,\n",
       "        -0.5814054 , -1.0849065 ,  0.80599695, -0.6663717 , -0.40847024,\n",
       "         0.56560165,  1.4001403 , -0.64175165,  1.758413  ,  1.2659222 ,\n",
       "         2.814516  ,  0.35743296,  0.716174  , -2.268147  ,  1.9052334 ,\n",
       "         0.47046998,  0.65455794,  1.4307287 ,  0.9422667 ,  0.8505306 ,\n",
       "        -0.57635784,  2.0821884 ,  1.2979668 ,  1.2445735 , -1.270812  ,\n",
       "        -0.32541823, -1.912759  ,  1.0853459 ,  0.6138243 ,  0.84168065,\n",
       "         0.6462698 ,  0.90280956,  1.427253  , -0.3229403 ,  1.4171925 ,\n",
       "         1.1689985 , -1.1512429 ,  2.1138947 , -0.484983  ,  1.2444521 ],\n",
       "       dtype=float32),\n",
       " array([105.12152  ,  73.61429  ,  34.27542  ,  54.358547 ,  41.766758 ,\n",
       "         31.990324 ,  17.06266  ,  35.162106 ,   4.0245833,  82.77368  ,\n",
       "         15.801271 ,  65.09533  ,  23.871662 ,  33.40113  ,  61.02458  ,\n",
       "         31.952106 ,  33.756157 ,  12.274706 ,  61.98665  ,  14.759656 ,\n",
       "         49.667664 ,  31.511608 ,  46.777626 ,   6.6390886,  31.037981 ,\n",
       "         48.154274 ,  10.175852 ,  23.102785 ,  42.221893 ,  21.951952 ,\n",
       "         18.071056 ,  46.058167 ,  47.916134 ,  18.95398  ,  27.090714 ,\n",
       "         23.058086 ,  23.524351 ,  47.294235 ,  17.696497 ,  21.25973  ,\n",
       "         33.081795 ,  29.24962  ,  36.68492  ,  52.8011   ,  37.216064 ,\n",
       "         19.686722 ,  21.0433   ,  77.657776 ,  30.733059 ,  51.89389  ,\n",
       "         17.174625 ,  57.48145  ,  30.280552 ,  20.852644 ,  47.991364 ,\n",
       "         21.407724 ,  10.818194 ,  37.760468 ,  59.418045 ,  26.693771 ,\n",
       "         86.67347  ,  79.51962  ,  11.294244 ,  46.088882 ,  26.752651 ,\n",
       "         32.053944 ,  94.079575 ,  18.178478 ,   8.887079 ,  26.981182 ,\n",
       "         50.65771  ,  33.516674 ,   6.836576 ,  11.076873 ,  20.155815 ,\n",
       "         45.472015 ,  36.65843  ,   8.908922 ,  14.198423 ,  30.715849 ,\n",
       "         40.637352 ,  53.971447 ,  61.79314  ,  39.608456 ,  51.79666  ,\n",
       "         42.18662  ,  30.285017 ,  31.77384  ,  47.059906 ,  52.910934 ,\n",
       "         16.518751 ,  31.980406 ,  25.576916 ,  13.384482 ,  48.39248  ,\n",
       "         17.482233 ,  29.254345 ,  46.268093 ,  24.027649 ,  24.74638  ,\n",
       "          2.4417338,  25.917015 ,  49.164566 ,  15.621821 ,   9.468696 ,\n",
       "         45.015564 ,  23.903692 ,  40.520958 ,  23.811613 ,  29.557432 ,\n",
       "         19.858955 ,  11.195405 ,  86.168304 ,  52.72774  ,  49.354153 ,\n",
       "         45.95965  ,   5.992378 ,  10.718805 ,   5.9262967,  23.836702 ,\n",
       "         11.360654 ,  31.180714 ,  40.09408  ,  21.512627 ,   7.5504885,\n",
       "         12.0935135,  34.714584 ,  14.629223 ,  20.913988 ,  43.052876 ,\n",
       "         75.912186 ,  37.390125 ,  22.694592 ,  29.145826 ,  13.552803 ,\n",
       "         18.373755 ,  22.06121  ,  44.906593 ,   9.894892 ,  20.56922  ,\n",
       "          8.756996 ,  17.984169 ,  22.589264 ,  40.123398 ,  33.585384 ,\n",
       "         57.70741  ,  47.010117 ,  47.133934 ,  42.117466 ,  64.96768  ,\n",
       "         17.89892  ,  45.840916 ,  43.80428  ,   9.199294 ,   7.3185883,\n",
       "          8.896438 ,  11.095297 ,  33.669228 ,   5.84548  ,   7.3974376,\n",
       "          9.754899 ,  34.314217 ,  37.189556 ,   8.279111 ,  12.178952 ,\n",
       "         28.830038 ,  51.72377  ,  30.736816 ,  17.106087 ,  31.050753 ,\n",
       "         60.800583 ,  26.183777 ,  21.800093 ,  44.19958  ,  59.253204 ,\n",
       "         13.645527 ,  18.818312 ,  32.482296 ,  16.986132 ,  12.706081 ,\n",
       "          8.621489 ,  67.02415  ,  23.303362 ,  45.157185 ,  28.43302  ,\n",
       "         27.073393 ,  50.498684 ,  23.077002 ,  35.567825 ,  18.766466 ,\n",
       "         19.691916 ,  23.401976 ,  41.23189  ,  25.353756 ,  46.888542 ,\n",
       "         53.963245 ,  26.302567 ,  87.47607  ,  18.321861 ,  15.35746  ],\n",
       "       dtype=float32),\n",
       " array([[-0.14509389,  0.15675066,  0.06965243, ...,  0.08547194,\n",
       "         -0.02109288,  0.1833782 ],\n",
       "        [ 0.06045217, -0.00358576,  0.18706183, ...,  0.09920868,\n",
       "          0.01493937,  0.20821393],\n",
       "        [-0.01137173,  0.06755123, -0.12750593, ..., -0.2143267 ,\n",
       "          0.26848865,  0.0484818 ],\n",
       "        ...,\n",
       "        [ 0.02866559,  0.0955563 , -0.05138403, ..., -0.00408723,\n",
       "         -0.00505973, -0.04961545],\n",
       "        [-0.07174466,  0.15964815,  0.10219967, ...,  0.06638857,\n",
       "          0.04946707, -0.0677831 ],\n",
       "        [ 0.01348195,  0.12921691,  0.05978604, ..., -0.07523592,\n",
       "          0.08868822,  0.1476493 ]], dtype=float32),\n",
       " array([-5.9616897e-04, -9.6738944e-03, -1.2348343e-03, -6.0097845e-03,\n",
       "         1.0608488e-03, -4.1391738e-03,  6.1426930e-05, -5.0846902e-03,\n",
       "        -3.7444588e-03, -2.8057073e-03,  2.1482881e-03, -1.3680632e-03,\n",
       "         1.6567112e-03,  4.2803367e-03, -3.2968944e-04,  1.7880859e-03,\n",
       "         2.2379610e-04, -4.9562077e-03,  1.6997393e-02, -3.5605216e-03,\n",
       "        -5.1778867e-03,  3.6259296e-03, -4.2609195e-03, -3.4800239e-03,\n",
       "         1.2332357e-02,  1.6198652e-03, -5.8643840e-05, -3.0350310e-03,\n",
       "         3.4678951e-03,  9.7176712e-03, -6.8058153e-03, -2.4713948e-03,\n",
       "         9.6862158e-03,  1.0711371e-02, -4.0313511e-04,  2.0907999e-03,\n",
       "         3.8760707e-03,  1.3523470e-03, -1.8224715e-03,  7.9864142e-03,\n",
       "        -3.7303241e-03, -5.6630131e-03, -3.4332853e-02,  2.2230670e-03,\n",
       "        -3.1676339e-03, -2.3921425e-03,  7.3267770e-04, -7.2364579e-03,\n",
       "        -1.2795987e-02,  5.4462552e-03,  8.2041712e-05, -7.3371693e-03,\n",
       "         1.9556456e-03,  9.6465489e-03, -3.3302347e-03, -5.9817815e-03,\n",
       "         1.9748909e-03,  7.4730307e-04,  2.1465393e-04,  8.4620500e-03,\n",
       "        -2.5516881e-03,  1.2634647e-03,  5.7802671e-03, -3.6700782e-03,\n",
       "         2.1743504e-03,  8.4966309e-03,  1.8272368e-03, -3.4555243e-03,\n",
       "         2.4993729e-04,  8.0747698e-03, -7.2119059e-04,  6.6523524e-03,\n",
       "         9.0931403e-03,  1.1509126e-02,  4.6746074e-03,  4.2385934e-03,\n",
       "         4.6985410e-03, -3.6827414e-03,  1.2160814e-03, -1.0070901e-02,\n",
       "         1.0217334e-03,  2.1187600e-03,  2.7542328e-03,  3.4086997e-04,\n",
       "         3.1979468e-03,  7.1696402e-04, -1.7421428e-03,  5.8504441e-03,\n",
       "        -7.2758092e-04, -1.5643938e-03, -1.9597537e-03, -5.7842317e-03,\n",
       "        -1.1559640e-02,  4.7020875e-03,  3.3522916e-03,  2.1368722e-03,\n",
       "         2.2113377e-03,  7.4234316e-03, -5.9817978e-03,  2.2730888e-03],\n",
       "       dtype=float32),\n",
       " array([0.9223091 , 1.0299814 , 1.0806773 , 1.2667245 , 1.1102282 ,\n",
       "        1.0037366 , 1.1585063 , 0.8173275 , 0.9183283 , 1.1370536 ,\n",
       "        1.0501813 , 0.99517685, 0.942139  , 0.98061913, 1.053198  ,\n",
       "        1.0585632 , 0.9233827 , 1.0499527 , 0.90270764, 0.9220059 ,\n",
       "        0.9803818 , 1.1801784 , 0.9828841 , 0.75943464, 0.95413756,\n",
       "        1.2329324 , 0.98301756, 0.8464157 , 1.0812796 , 0.96835595,\n",
       "        0.76899856, 0.71510684, 0.923035  , 1.0556476 , 0.9834334 ,\n",
       "        1.0067647 , 1.1356393 , 0.7143436 , 0.87271297, 1.0505068 ,\n",
       "        1.1007698 , 0.99095833, 1.1833471 , 1.1686451 , 0.9573807 ,\n",
       "        0.9869703 , 1.0754234 , 0.94060755, 1.2718803 , 1.0575811 ,\n",
       "        0.9632771 , 0.88635707, 1.1330616 , 1.3541555 , 0.941451  ,\n",
       "        1.1905061 , 1.0124266 , 0.96820456, 1.1644492 , 0.92360306,\n",
       "        1.0887122 , 1.1127869 , 1.237768  , 0.8252025 , 0.9626023 ,\n",
       "        0.8011002 , 1.2735713 , 0.90949553, 1.2511299 , 0.99385947,\n",
       "        0.95146954, 0.9814883 , 1.0283402 , 1.0241243 , 1.0657697 ,\n",
       "        1.0300769 , 0.8523595 , 1.0511844 , 1.0060711 , 1.0257381 ,\n",
       "        0.93641233, 1.1773604 , 0.8892084 , 0.97472376, 1.1962951 ,\n",
       "        0.9621738 , 1.0265611 , 1.0852519 , 0.848923  , 1.0149624 ,\n",
       "        1.0108877 , 1.0182394 , 1.2285976 , 0.9465575 , 1.2266726 ,\n",
       "        0.7788348 , 1.2672069 , 0.9912451 , 0.9627369 , 1.0130724 ],\n",
       "       dtype=float32),\n",
       " array([-2.38125976e-02, -2.40458861e-01, -1.72508225e-01, -1.04152858e-01,\n",
       "         3.10457706e-01,  1.74682468e-01, -1.10792823e-01, -5.60938194e-02,\n",
       "         2.10333703e-04, -5.26256301e-02,  3.24697606e-02,  2.93555744e-02,\n",
       "        -8.48928615e-02,  1.88044254e-02, -8.23414773e-02, -5.75321652e-02,\n",
       "        -5.76721765e-02, -1.38399839e-01, -3.77201103e-02, -9.81841385e-02,\n",
       "         8.22367966e-02, -2.14576423e-01,  1.66606605e-01, -1.05397910e-01,\n",
       "         6.49498999e-02, -1.07494555e-03,  2.28389665e-01, -2.06333756e-01,\n",
       "         1.02270320e-01, -3.66577990e-02, -1.82513639e-01, -9.35135782e-02,\n",
       "         1.27584770e-01,  4.21351157e-02, -1.07464731e-01,  5.41244969e-02,\n",
       "         8.46846178e-02, -2.08562389e-01, -6.84498902e-03, -1.34224385e-01,\n",
       "        -1.11661024e-01,  1.62195951e-01,  1.78803414e-01, -9.11797881e-02,\n",
       "        -2.40024105e-02,  7.18694273e-03, -2.23927684e-02, -1.46851912e-01,\n",
       "         1.31061167e-01, -2.62087211e-02,  6.67621270e-02,  1.08093932e-01,\n",
       "         7.67426705e-03,  1.25806063e-01, -8.82745013e-02, -1.07221156e-02,\n",
       "        -5.93341254e-02, -6.90364391e-02, -3.62150073e-02, -3.83460484e-02,\n",
       "        -1.78215504e-02,  2.47782711e-02,  7.74192438e-02, -4.83777262e-02,\n",
       "         1.05061099e-01, -2.91593131e-02,  7.38324821e-02,  3.27630416e-02,\n",
       "         6.68832958e-02, -5.82276471e-02,  2.36322165e-01,  1.01221308e-01,\n",
       "         2.76206229e-02,  2.23418385e-01, -6.00677915e-02,  5.48706576e-02,\n",
       "        -2.40148325e-02,  1.06038675e-02, -1.63590647e-02, -4.29297090e-02,\n",
       "        -9.90713462e-02, -1.67163014e-01, -1.05196744e-01, -5.38122794e-03,\n",
       "        -5.31952232e-02,  5.01167029e-02, -1.76285282e-01,  7.13225156e-02,\n",
       "         4.26088423e-02,  1.24688894e-02, -1.78838409e-02, -3.21589001e-02,\n",
       "        -3.15202288e-02, -7.17782974e-02, -1.99088212e-02, -1.69424176e-01,\n",
       "         4.75964788e-03,  1.76208496e-01, -9.88473594e-02,  2.77631506e-02],\n",
       "       dtype=float32),\n",
       " array([-1.9028623 ,  2.3715947 ,  2.3707955 ,  1.854376  , -1.306096  ,\n",
       "         1.5584965 ,  2.6664352 , -0.40308794, -1.7174063 ,  1.6973611 ,\n",
       "         0.8792335 , -1.1276262 ,  1.615508  ,  2.1147022 ,  0.4691854 ,\n",
       "         2.0448914 ,  0.95405596,  0.9390038 , -0.5585613 ,  2.3959293 ,\n",
       "         0.19238588,  2.0679643 ,  0.27398714, -0.21473733, -0.1653855 ,\n",
       "         1.1226112 , -0.07451177,  2.5794818 ,  0.25050396,  2.1179683 ,\n",
       "         1.2900138 ,  0.78812844, -2.650142  ,  0.5789374 ,  1.5023911 ,\n",
       "         1.0221981 , -1.1581534 , -0.98892766,  1.5863152 ,  1.6823468 ,\n",
       "         0.9738449 , -2.7660353 ,  1.486106  , -0.41211805,  1.5845025 ,\n",
       "        -0.94785815,  2.1415486 , -0.802215  ,  0.06578715,  0.6474249 ,\n",
       "        -1.1741352 , -1.5028592 ,  1.2265115 , -2.7806025 ,  2.5299242 ,\n",
       "         1.0553743 ,  0.99960995,  1.312878  , -1.2166586 ,  1.0536035 ,\n",
       "         1.0143383 ,  0.5373334 ,  2.6379778 , -2.7543876 , -0.48993707,\n",
       "        -0.15961388,  1.1684058 , -1.1339494 ,  1.2084786 ,  1.4635762 ,\n",
       "         0.08369277, -1.2216249 ,  0.77827567,  1.0050238 ,  1.3143054 ,\n",
       "        -1.1962897 ,  0.9693801 ,  0.1823609 ,  0.9111634 ,  0.72316396,\n",
       "         1.6961284 ,  1.6428885 , -1.9595741 , -1.3479764 ,  1.9821913 ,\n",
       "        -1.3123271 ,  1.1531346 , -1.0183526 , -1.8747077 ,  1.558897  ,\n",
       "         0.8493299 ,  1.4344864 ,  1.9734516 ,  1.5771933 ,  1.569438  ,\n",
       "        -1.2829303 ,  2.2421207 ,  0.42421317,  1.4629985 ,  1.4055506 ],\n",
       "       dtype=float32),\n",
       " array([ 69.69819  ,  36.94235  ,   3.1346366,  48.367664 ,  13.55584  ,\n",
       "        112.3287   ,  49.04665  ,   8.759808 ,  52.323208 ,   4.8755293,\n",
       "         45.958893 ,  52.691093 ,  64.79926  ,  47.88272  ,   2.900659 ,\n",
       "         75.21198  ,  11.401909 ,  31.997883 ,  38.62164  ,  59.29504  ,\n",
       "         25.081331 ,  19.066772 ,  32.243282 ,  38.38337  ,  25.035276 ,\n",
       "         19.801292 ,  52.887253 ,  37.16585  ,   7.201381 ,  79.93135  ,\n",
       "         24.572807 ,  31.45996  ,  69.124146 ,  48.782116 ,   9.50803  ,\n",
       "         54.895004 ,   7.019129 ,  56.064507 ,  34.998615 ,  50.59826  ,\n",
       "          7.484807 ,  48.95117  ,  30.722282 ,  51.16436  ,  88.52262  ,\n",
       "         64.14106  ,  63.515102 ,  34.16861  ,  19.540201 ,  21.195498 ,\n",
       "         69.84515  ,  77.03892  ,  28.074837 ,   7.918397 ,  53.567894 ,\n",
       "         14.345289 ,  22.792189 ,  56.35673  ,  11.726701 ,  38.289368 ,\n",
       "         48.729996 ,  65.35917  ,  47.70094  ,  10.301486 ,  32.406834 ,\n",
       "         15.096269 ,  48.965214 ,  62.69986  ,  57.325184 ,  64.81121  ,\n",
       "         42.37646  ,  39.71003  ,  41.796783 ,  57.871983 ,  12.986976 ,\n",
       "         26.96759  ,  56.560013 ,  24.168344 ,   4.257792 ,  31.750568 ,\n",
       "         58.819393 ,  36.080822 ,  18.55644  ,  39.484066 ,  20.355839 ,\n",
       "          6.1630597,   3.3927062,  14.35371  , 121.87218  ,  75.10878  ,\n",
       "         23.443382 ,  44.759617 ,  69.31815  ,  52.507336 ,  33.26342  ,\n",
       "         22.653296 ,  83.069275 ,   1.2206782,  25.625319 ,   4.9945097],\n",
       "       dtype=float32),\n",
       " array([[-0.00777148, -0.046853  ,  0.0913678 , ..., -0.14130245,\n",
       "         -0.13572803, -0.07028691],\n",
       "        [ 0.25742257, -0.0601241 ,  0.28095388, ..., -0.00832517,\n",
       "         -0.02024036,  0.01460059],\n",
       "        [-0.01170303,  0.2039199 ,  0.13634129, ..., -0.2453219 ,\n",
       "          0.04740418,  0.01021318],\n",
       "        ...,\n",
       "        [ 0.11394929,  0.02443735, -0.11571538, ...,  0.03798302,\n",
       "         -0.08485965,  0.05071276],\n",
       "        [-0.04421547, -0.04247684,  0.12559995, ..., -0.02036702,\n",
       "          0.07502504,  0.23549885],\n",
       "        [-0.04630273,  0.02579767,  0.15141636, ...,  0.08377688,\n",
       "         -0.09105242,  0.065121  ]], dtype=float32),\n",
       " array([ 0.0168295 , -0.01361315,  0.04368065,  0.04996952,  0.01848302,\n",
       "         0.0027644 , -0.03378987,  0.00665724,  0.01503929,  0.0018509 ,\n",
       "         0.0358614 , -0.01903388, -0.03984672, -0.05595493, -0.00213966,\n",
       "         0.00893872,  0.00855347,  0.00943648, -0.01290894, -0.02609403],\n",
       "       dtype=float32),\n",
       " array([0.99528015, 0.96503556, 0.95015347, 0.9494676 , 0.8890885 ,\n",
       "        0.96320426, 0.99407995, 0.4494899 , 0.981666  , 0.9783582 ,\n",
       "        0.8352845 , 1.0354288 , 0.9746774 , 0.982795  , 0.7865775 ,\n",
       "        0.94116116, 0.85601586, 0.9009082 , 0.9735527 , 0.999988  ],\n",
       "       dtype=float32),\n",
       " array([-0.09482905, -0.07696225, -0.00105021,  0.10761371,  0.08926509,\n",
       "        -0.08366741,  0.09245507, -0.21496283, -0.06699046, -0.03605165,\n",
       "         0.21220818,  0.37872776,  0.02808755, -0.06815103,  0.10109694,\n",
       "        -0.07007822,  0.05674234,  0.07352594, -0.09230166, -0.0656971 ],\n",
       "       dtype=float32),\n",
       " array([ 1.3505471 ,  1.5135916 ,  0.7367118 ,  0.04172055, -1.7027458 ,\n",
       "        -1.3079947 ,  0.33349785, -0.29368514, -1.0068607 , -0.87797993,\n",
       "        -1.2475231 , -0.3860231 , -0.64978474,  1.1278808 , -1.2828511 ,\n",
       "        -0.57691807, -1.0485233 , -1.6249895 ,  1.1366273 ,  0.92718387],\n",
       "       dtype=float32),\n",
       " array([ 32.302864 ,  37.305405 ,  35.215115 ,  15.393678 ,  64.86043  ,\n",
       "        103.547485 ,  19.697538 ,   3.2747314,  42.745373 ,  17.270935 ,\n",
       "         56.336452 ,  15.051951 ,   6.0713186,  43.0249   ,  47.788822 ,\n",
       "         11.639762 ,  36.667686 ,  46.34651  ,  30.692219 ,  39.0015   ],\n",
       "       dtype=float32),\n",
       " array([[-0.21570563],\n",
       "        [ 0.37953392],\n",
       "        [ 0.42155054],\n",
       "        [ 0.24977572],\n",
       "        [ 0.39361343],\n",
       "        [-0.33308473],\n",
       "        [ 0.27321965],\n",
       "        [ 0.02539603],\n",
       "        [-0.34651375],\n",
       "        [-0.38515255],\n",
       "        [ 0.11144087],\n",
       "        [ 0.46289855],\n",
       "        [ 0.3220283 ],\n",
       "        [-0.45057705],\n",
       "        [ 0.04444534],\n",
       "        [-0.09684321],\n",
       "        [ 0.0868459 ],\n",
       "        [ 0.183538  ],\n",
       "        [-0.16904911],\n",
       "        [-0.45891953]], dtype=float32),\n",
       " array([0.10943688], dtype=float32)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fac39303670>\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "model = deep_model_algo(activation='elu', nodes = [300, 550, 500, 300, 200, 150, 100, 50], opti = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 1.1499 - accuracy: 0.8472 - val_loss: 0.3377 - val_accuracy: 0.9069\n",
      "Epoch 2/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.9261 - accuracy: 0.8756 - val_loss: 0.3566 - val_accuracy: 0.9069\n",
      "Epoch 3/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.8763 - accuracy: 0.8797 - val_loss: 0.3987 - val_accuracy: 0.9066\n",
      "Epoch 4/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.7965 - accuracy: 0.8758 - val_loss: 1.4403 - val_accuracy: 0.9066\n",
      "Epoch 5/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 1.8019 - accuracy: 0.8111 - val_loss: 1.4403 - val_accuracy: 0.9066\n",
      "Epoch 6/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.6257 - accuracy: 0.8609 - val_loss: 1.4352 - val_accuracy: 0.9069\n",
      "Epoch 7/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.5749 - accuracy: 0.8815 - val_loss: 1.4403 - val_accuracy: 0.9066\n",
      "Epoch 8/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.5714 - accuracy: 0.8870 - val_loss: 1.4403 - val_accuracy: 0.9066\n",
      "Epoch 9/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.6098 - accuracy: 0.8836 - val_loss: 0.5763 - val_accuracy: 0.9066\n",
      "Epoch 10/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.6008 - accuracy: 0.8660 - val_loss: 0.3473 - val_accuracy: 0.9066\n",
      "Epoch 11/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.7229 - accuracy: 0.8326 - val_loss: 1.4403 - val_accuracy: 0.9066\n",
      "Epoch 12/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3359 - accuracy: 0.9074 - val_loss: 0.4896 - val_accuracy: 0.9066\n",
      "Epoch 13/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3352 - accuracy: 0.9085 - val_loss: 0.3865 - val_accuracy: 0.9069\n",
      "Epoch 14/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3266 - accuracy: 0.9085 - val_loss: 1.4257 - val_accuracy: 0.9071\n",
      "Epoch 15/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3277 - accuracy: 0.9087 - val_loss: 0.5475 - val_accuracy: 0.9071\n",
      "Epoch 16/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3142 - accuracy: 0.9086 - val_loss: 0.3406 - val_accuracy: 0.9076\n",
      "Epoch 17/300\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.3319 - accuracy: 0.9077 - val_loss: 0.4046 - val_accuracy: 0.9076\n",
      "Epoch 18/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3324 - accuracy: 0.9076 - val_loss: 1.4251 - val_accuracy: 0.9076\n",
      "Epoch 19/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3189 - accuracy: 0.9085 - val_loss: 1.4251 - val_accuracy: 0.9076\n",
      "Epoch 20/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 1.2098 - accuracy: 0.8277 - val_loss: 1.4403 - val_accuracy: 0.9066\n",
      "Epoch 21/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.4046 - accuracy: 0.9058 - val_loss: 1.4354 - val_accuracy: 0.9066\n",
      "Epoch 22/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.5989 - accuracy: 0.8583 - val_loss: 1.4403 - val_accuracy: 0.9066\n",
      "Epoch 23/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3561 - accuracy: 0.9071 - val_loss: 1.4252 - val_accuracy: 0.9076\n",
      "Epoch 24/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3165 - accuracy: 0.9085 - val_loss: 1.4032 - val_accuracy: 0.9076\n",
      "Epoch 25/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3208 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 26/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3146 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 27/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3125 - accuracy: 0.9086 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 28/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3084 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 29/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3163 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 30/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3236 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 31/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3148 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 32/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3756 - accuracy: 0.8906 - val_loss: 0.8022 - val_accuracy: 0.0934\n",
      "Epoch 33/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.5597 - accuracy: 0.8831 - val_loss: 0.3304 - val_accuracy: 0.9088\n",
      "Epoch 34/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3217 - accuracy: 0.9086 - val_loss: 0.3295 - val_accuracy: 0.9088\n",
      "Epoch 35/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3176 - accuracy: 0.9087 - val_loss: 0.3218 - val_accuracy: 0.9088\n",
      "Epoch 36/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3205 - accuracy: 0.9087 - val_loss: 0.4285 - val_accuracy: 0.9088\n",
      "Epoch 37/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3192 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 38/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3165 - accuracy: 0.9086 - val_loss: 0.8107 - val_accuracy: 0.9088\n",
      "Epoch 39/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3112 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 40/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3092 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 41/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3744 - accuracy: 0.9005 - val_loss: 0.3282 - val_accuracy: 0.9088\n",
      "Epoch 42/300\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.3258 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 43/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3109 - accuracy: 0.9088 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 44/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3071 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 45/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3110 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 46/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3143 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 47/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3065 - accuracy: 0.9082 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 48/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3109 - accuracy: 0.9082 - val_loss: 1.4249 - val_accuracy: 0.9076\n",
      "Epoch 49/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3058 - accuracy: 0.9087 - val_loss: 1.4030 - val_accuracy: 0.9084\n",
      "Epoch 50/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3058 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 51/300\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.3052 - accuracy: 0.9082 - val_loss: 1.4026 - val_accuracy: 0.9088\n",
      "Epoch 52/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3610 - accuracy: 0.9056 - val_loss: 0.3661 - val_accuracy: 0.9088\n",
      "Epoch 53/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3249 - accuracy: 0.9087 - val_loss: 0.3386 - val_accuracy: 0.9088\n",
      "Epoch 54/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3097 - accuracy: 0.9087 - val_loss: 0.3758 - val_accuracy: 0.9088\n",
      "Epoch 55/300\n",
      "55/55 [==============================] - 3s 45ms/step - loss: 0.3128 - accuracy: 0.9087 - val_loss: 0.3291 - val_accuracy: 0.9088\n",
      "Epoch 56/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3209 - accuracy: 0.9087 - val_loss: 1.4025 - val_accuracy: 0.9088\n",
      "Epoch 57/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3163 - accuracy: 0.9080 - val_loss: 0.3126 - val_accuracy: 0.9088\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3075 - accuracy: 0.9086 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 59/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3038 - accuracy: 0.9086 - val_loss: 0.3936 - val_accuracy: 0.9088\n",
      "Epoch 60/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.4741 - accuracy: 0.8755 - val_loss: 0.3136 - val_accuracy: 0.9088\n",
      "Epoch 61/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.6051 - accuracy: 0.8935 - val_loss: 0.3184 - val_accuracy: 0.9088\n",
      "Epoch 62/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3378 - accuracy: 0.9080 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 63/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3126 - accuracy: 0.9086 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 64/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3113 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 65/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3106 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 66/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3084 - accuracy: 0.9082 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 67/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3041 - accuracy: 0.9090 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 68/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3962 - accuracy: 0.9064 - val_loss: 0.3151 - val_accuracy: 0.9088\n",
      "Epoch 69/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3082 - accuracy: 0.9083 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 70/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3049 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 71/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3057 - accuracy: 0.9089 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 72/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3041 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 73/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3024 - accuracy: 0.9086 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 74/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3088 - accuracy: 0.9088 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 75/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3060 - accuracy: 0.9086 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 76/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3115 - accuracy: 0.9081 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 77/300\n",
      "55/55 [==============================] - 3s 47ms/step - loss: 0.3080 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 78/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.3057 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 79/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3036 - accuracy: 0.9084 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 80/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.5782 - accuracy: 0.8340 - val_loss: 1.4056 - val_accuracy: 0.9088\n",
      "Epoch 81/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3297 - accuracy: 0.9081 - val_loss: 1.4071 - val_accuracy: 0.9088\n",
      "Epoch 82/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3762 - accuracy: 0.8816 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 83/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3293 - accuracy: 0.9059 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 84/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3031 - accuracy: 0.9084 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 85/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3002 - accuracy: 0.9090 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 86/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3142 - accuracy: 0.9082 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 87/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.8627 - accuracy: 0.8181 - val_loss: 0.3225 - val_accuracy: 0.9079\n",
      "Epoch 88/300\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.3442 - accuracy: 0.9062 - val_loss: 0.3104 - val_accuracy: 0.9088\n",
      "Epoch 89/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3474 - accuracy: 0.9023 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 90/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3275 - accuracy: 0.9072 - val_loss: 0.3116 - val_accuracy: 0.9088\n",
      "Epoch 91/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3271 - accuracy: 0.9072 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 92/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3292 - accuracy: 0.9072 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 93/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.3244 - accuracy: 0.9072 - val_loss: 0.3132 - val_accuracy: 0.9088\n",
      "Epoch 94/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3240 - accuracy: 0.9075 - val_loss: 0.3145 - val_accuracy: 0.9088\n",
      "Epoch 95/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3291 - accuracy: 0.9073 - val_loss: 0.3162 - val_accuracy: 0.9088\n",
      "Epoch 96/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3263 - accuracy: 0.9075 - val_loss: 0.3811 - val_accuracy: 0.9088\n",
      "Epoch 97/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3248 - accuracy: 0.9075 - val_loss: 1.4071 - val_accuracy: 0.9088\n",
      "Epoch 98/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3345 - accuracy: 0.9064 - val_loss: 0.3107 - val_accuracy: 0.9088\n",
      "Epoch 99/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3294 - accuracy: 0.9074 - val_loss: 0.3225 - val_accuracy: 0.9088\n",
      "Epoch 100/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3297 - accuracy: 0.9074 - val_loss: 0.3393 - val_accuracy: 0.9088\n",
      "Epoch 101/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3268 - accuracy: 0.9074 - val_loss: 0.3510 - val_accuracy: 0.9088\n",
      "Epoch 102/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3347 - accuracy: 0.9075 - val_loss: 0.3374 - val_accuracy: 0.9088\n",
      "Epoch 103/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3328 - accuracy: 0.9072 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 104/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3265 - accuracy: 0.9072 - val_loss: 1.4071 - val_accuracy: 0.9088\n",
      "Epoch 105/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.3215 - accuracy: 0.9069 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 106/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3295 - accuracy: 0.9070 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 107/300\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.3264 - accuracy: 0.9068 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 108/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3321 - accuracy: 0.9070 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 109/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3298 - accuracy: 0.9072 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 110/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3247 - accuracy: 0.9072 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 111/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3251 - accuracy: 0.9066 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 112/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3200 - accuracy: 0.9073 - val_loss: 1.4071 - val_accuracy: 0.9088\n",
      "Epoch 113/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3222 - accuracy: 0.9072 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 114/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3340 - accuracy: 0.9066 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3243 - accuracy: 0.9067 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 116/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.3351 - accuracy: 0.9071 - val_loss: 1.4045 - val_accuracy: 0.9083\n",
      "Epoch 117/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3242 - accuracy: 0.9072 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 118/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3197 - accuracy: 0.9069 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 119/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3233 - accuracy: 0.9073 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 120/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3279 - accuracy: 0.9072 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 121/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3318 - accuracy: 0.9069 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 122/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3573 - accuracy: 0.9072 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 123/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3261 - accuracy: 0.9072 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 124/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3722 - accuracy: 0.8927 - val_loss: 0.3356 - val_accuracy: 0.9088\n",
      "Epoch 125/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3158 - accuracy: 0.9087 - val_loss: 0.3136 - val_accuracy: 0.9088\n",
      "Epoch 126/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3124 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 127/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3071 - accuracy: 0.9087 - val_loss: 0.3135 - val_accuracy: 0.9088\n",
      "Epoch 128/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3106 - accuracy: 0.9082 - val_loss: 0.3108 - val_accuracy: 0.9088\n",
      "Epoch 129/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3044 - accuracy: 0.9087 - val_loss: 0.3828 - val_accuracy: 0.9088\n",
      "Epoch 130/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3552 - accuracy: 0.9059 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 131/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3126 - accuracy: 0.9084 - val_loss: 0.3227 - val_accuracy: 0.9088\n",
      "Epoch 132/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3065 - accuracy: 0.9086 - val_loss: 0.3118 - val_accuracy: 0.9088\n",
      "Epoch 133/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3067 - accuracy: 0.9087 - val_loss: 0.3301 - val_accuracy: 0.9088\n",
      "Epoch 134/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3033 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 135/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3002 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 136/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.4534 - accuracy: 0.8787 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 137/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3259 - accuracy: 0.9083 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 138/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3147 - accuracy: 0.9087 - val_loss: 1.4034 - val_accuracy: 0.9088\n",
      "Epoch 139/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3402 - accuracy: 0.9085 - val_loss: 0.3344 - val_accuracy: 0.9088\n",
      "Epoch 140/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3448 - accuracy: 0.9087 - val_loss: 0.3176 - val_accuracy: 0.9088\n",
      "Epoch 141/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3264 - accuracy: 0.9087 - val_loss: 0.3106 - val_accuracy: 0.9088\n",
      "Epoch 142/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3294 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 143/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3214 - accuracy: 0.9072 - val_loss: 0.3254 - val_accuracy: 0.9088\n",
      "Epoch 144/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3066 - accuracy: 0.9087 - val_loss: 0.3108 - val_accuracy: 0.9088\n",
      "Epoch 145/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3545 - accuracy: 0.9015 - val_loss: 0.7405 - val_accuracy: 0.0934\n",
      "Epoch 146/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.4718 - accuracy: 0.8786 - val_loss: 0.3125 - val_accuracy: 0.9088\n",
      "Epoch 147/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3081 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 148/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3116 - accuracy: 0.9087 - val_loss: 0.4229 - val_accuracy: 0.9088\n",
      "Epoch 149/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3112 - accuracy: 0.9087 - val_loss: 0.3571 - val_accuracy: 0.9088\n",
      "Epoch 150/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3034 - accuracy: 0.9087 - val_loss: 0.3467 - val_accuracy: 0.9088\n",
      "Epoch 151/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3011 - accuracy: 0.9087 - val_loss: 0.3739 - val_accuracy: 0.9088\n",
      "Epoch 152/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3018 - accuracy: 0.9087 - val_loss: 0.3288 - val_accuracy: 0.9088\n",
      "Epoch 153/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3066 - accuracy: 0.9087 - val_loss: 0.3415 - val_accuracy: 0.9088\n",
      "Epoch 154/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3055 - accuracy: 0.9087 - val_loss: 0.3147 - val_accuracy: 0.9088\n",
      "Epoch 155/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3008 - accuracy: 0.9087 - val_loss: 0.3711 - val_accuracy: 0.9088\n",
      "Epoch 156/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3041 - accuracy: 0.9087 - val_loss: 0.3223 - val_accuracy: 0.9088\n",
      "Epoch 157/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3757 - accuracy: 0.8997 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 158/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.6296 - accuracy: 0.7139 - val_loss: 0.7919 - val_accuracy: 0.0934\n",
      "Epoch 159/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.4651 - accuracy: 0.8303 - val_loss: 0.4298 - val_accuracy: 0.9088\n",
      "Epoch 160/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3464 - accuracy: 0.9087 - val_loss: 0.3156 - val_accuracy: 0.9088\n",
      "Epoch 161/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3264 - accuracy: 0.9087 - val_loss: 0.3208 - val_accuracy: 0.9088\n",
      "Epoch 162/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3194 - accuracy: 0.9087 - val_loss: 0.3415 - val_accuracy: 0.9088\n",
      "Epoch 163/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3180 - accuracy: 0.9087 - val_loss: 0.3654 - val_accuracy: 0.9088\n",
      "Epoch 164/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3107 - accuracy: 0.9087 - val_loss: 0.3458 - val_accuracy: 0.9088\n",
      "Epoch 165/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3155 - accuracy: 0.9087 - val_loss: 0.3405 - val_accuracy: 0.9088\n",
      "Epoch 166/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3085 - accuracy: 0.9087 - val_loss: 0.3446 - val_accuracy: 0.9088\n",
      "Epoch 167/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3114 - accuracy: 0.9087 - val_loss: 0.3596 - val_accuracy: 0.9088\n",
      "Epoch 168/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3085 - accuracy: 0.9087 - val_loss: 0.3412 - val_accuracy: 0.9088\n",
      "Epoch 169/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3095 - accuracy: 0.9087 - val_loss: 0.3173 - val_accuracy: 0.9088\n",
      "Epoch 170/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3248 - accuracy: 0.9087 - val_loss: 0.3129 - val_accuracy: 0.9088\n",
      "Epoch 171/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3116 - accuracy: 0.9087 - val_loss: 0.3237 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3305 - accuracy: 0.9079 - val_loss: 0.3469 - val_accuracy: 0.9088\n",
      "Epoch 173/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3117 - accuracy: 0.9082 - val_loss: 0.3938 - val_accuracy: 0.9088\n",
      "Epoch 174/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3102 - accuracy: 0.9087 - val_loss: 0.3758 - val_accuracy: 0.9088\n",
      "Epoch 175/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3112 - accuracy: 0.9087 - val_loss: 0.4726 - val_accuracy: 0.9088\n",
      "Epoch 176/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3076 - accuracy: 0.9087 - val_loss: 0.4392 - val_accuracy: 0.9088\n",
      "Epoch 177/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3045 - accuracy: 0.9087 - val_loss: 0.3281 - val_accuracy: 0.9088\n",
      "Epoch 178/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3062 - accuracy: 0.9087 - val_loss: 0.3467 - val_accuracy: 0.9088\n",
      "Epoch 179/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3071 - accuracy: 0.9087 - val_loss: 0.3288 - val_accuracy: 0.9088\n",
      "Epoch 180/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3071 - accuracy: 0.9086 - val_loss: 0.3126 - val_accuracy: 0.9088\n",
      "Epoch 181/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3320 - accuracy: 0.9082 - val_loss: 0.3154 - val_accuracy: 0.9088\n",
      "Epoch 182/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3061 - accuracy: 0.9087 - val_loss: 0.3518 - val_accuracy: 0.9088\n",
      "Epoch 183/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3242 - accuracy: 0.9087 - val_loss: 0.4019 - val_accuracy: 0.9088\n",
      "Epoch 184/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3100 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 185/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3074 - accuracy: 0.9087 - val_loss: 1.4063 - val_accuracy: 0.9088\n",
      "Epoch 186/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3213 - accuracy: 0.9087 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 187/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3082 - accuracy: 0.9087 - val_loss: 0.3157 - val_accuracy: 0.9088\n",
      "Epoch 188/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3111 - accuracy: 0.9087 - val_loss: 0.3233 - val_accuracy: 0.9088\n",
      "Epoch 189/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3421 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 190/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3168 - accuracy: 0.9086 - val_loss: 0.3282 - val_accuracy: 0.9088\n",
      "Epoch 191/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3083 - accuracy: 0.9087 - val_loss: 0.3374 - val_accuracy: 0.9088\n",
      "Epoch 192/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3049 - accuracy: 0.9087 - val_loss: 0.3590 - val_accuracy: 0.9088\n",
      "Epoch 193/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3094 - accuracy: 0.9087 - val_loss: 0.3576 - val_accuracy: 0.9088\n",
      "Epoch 194/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3090 - accuracy: 0.9087 - val_loss: 0.3524 - val_accuracy: 0.9088\n",
      "Epoch 195/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3062 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 196/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3037 - accuracy: 0.9086 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 197/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3696 - accuracy: 0.8995 - val_loss: 1.4186 - val_accuracy: 0.9066\n",
      "Epoch 198/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.4969 - accuracy: 0.8824 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 199/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3131 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 200/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3098 - accuracy: 0.9087 - val_loss: 0.4684 - val_accuracy: 0.9088\n",
      "Epoch 201/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3080 - accuracy: 0.9087 - val_loss: 0.3615 - val_accuracy: 0.9088\n",
      "Epoch 202/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3077 - accuracy: 0.9087 - val_loss: 0.3450 - val_accuracy: 0.9088\n",
      "Epoch 203/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3070 - accuracy: 0.9087 - val_loss: 0.3721 - val_accuracy: 0.9088\n",
      "Epoch 204/300\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.3044 - accuracy: 0.9087 - val_loss: 0.3460 - val_accuracy: 0.9088\n",
      "Epoch 205/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3020 - accuracy: 0.9086 - val_loss: 0.3230 - val_accuracy: 0.9088\n",
      "Epoch 206/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3023 - accuracy: 0.9087 - val_loss: 0.3356 - val_accuracy: 0.9088\n",
      "Epoch 207/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3095 - accuracy: 0.9085 - val_loss: 0.4527 - val_accuracy: 0.9088\n",
      "Epoch 208/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3100 - accuracy: 0.9085 - val_loss: 0.4410 - val_accuracy: 0.9088\n",
      "Epoch 209/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3107 - accuracy: 0.9087 - val_loss: 0.3640 - val_accuracy: 0.9088\n",
      "Epoch 210/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3181 - accuracy: 0.9071 - val_loss: 0.3173 - val_accuracy: 0.9088\n",
      "Epoch 211/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3116 - accuracy: 0.9087 - val_loss: 0.3686 - val_accuracy: 0.9088\n",
      "Epoch 212/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3071 - accuracy: 0.9087 - val_loss: 0.3644 - val_accuracy: 0.9088\n",
      "Epoch 213/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3063 - accuracy: 0.9086 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 214/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3048 - accuracy: 0.9085 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 215/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3004 - accuracy: 0.9086 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 216/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3060 - accuracy: 0.9084 - val_loss: 1.4030 - val_accuracy: 0.9088\n",
      "Epoch 217/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3129 - accuracy: 0.9085 - val_loss: 0.4628 - val_accuracy: 0.9088\n",
      "Epoch 218/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3066 - accuracy: 0.9087 - val_loss: 0.3999 - val_accuracy: 0.9088\n",
      "Epoch 219/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3038 - accuracy: 0.9087 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 220/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3004 - accuracy: 0.9085 - val_loss: 1.4032 - val_accuracy: 0.9088\n",
      "Epoch 221/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3186 - accuracy: 0.9088 - val_loss: 0.3450 - val_accuracy: 0.9088\n",
      "Epoch 222/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3130 - accuracy: 0.9077 - val_loss: 0.6089 - val_accuracy: 0.9088\n",
      "Epoch 223/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.5356 - accuracy: 0.8109 - val_loss: 0.5623 - val_accuracy: 0.9088\n",
      "Epoch 224/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.4418 - accuracy: 0.8982 - val_loss: 0.4022 - val_accuracy: 0.9088\n",
      "Epoch 225/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3406 - accuracy: 0.9087 - val_loss: 0.3307 - val_accuracy: 0.9088\n",
      "Epoch 226/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3079 - accuracy: 0.9087 - val_loss: 0.3125 - val_accuracy: 0.9088\n",
      "Epoch 227/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3092 - accuracy: 0.9087 - val_loss: 0.3115 - val_accuracy: 0.9088\n",
      "Epoch 228/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3107 - accuracy: 0.9087 - val_loss: 0.3122 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3079 - accuracy: 0.9087 - val_loss: 0.3136 - val_accuracy: 0.9088\n",
      "Epoch 230/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3084 - accuracy: 0.9087 - val_loss: 0.3127 - val_accuracy: 0.9088\n",
      "Epoch 231/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3106 - accuracy: 0.9087 - val_loss: 0.3135 - val_accuracy: 0.9088\n",
      "Epoch 232/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3069 - accuracy: 0.9087 - val_loss: 0.3134 - val_accuracy: 0.9088\n",
      "Epoch 233/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3074 - accuracy: 0.9087 - val_loss: 0.3138 - val_accuracy: 0.9088\n",
      "Epoch 234/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3105 - accuracy: 0.9087 - val_loss: 0.3123 - val_accuracy: 0.9088\n",
      "Epoch 235/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3067 - accuracy: 0.9087 - val_loss: 0.3119 - val_accuracy: 0.9088\n",
      "Epoch 236/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3065 - accuracy: 0.9087 - val_loss: 0.3120 - val_accuracy: 0.9088\n",
      "Epoch 237/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3106 - accuracy: 0.9087 - val_loss: 0.3128 - val_accuracy: 0.9088\n",
      "Epoch 238/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3056 - accuracy: 0.9087 - val_loss: 0.3134 - val_accuracy: 0.9088\n",
      "Epoch 239/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3077 - accuracy: 0.9087 - val_loss: 0.3123 - val_accuracy: 0.9088\n",
      "Epoch 240/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3084 - accuracy: 0.9087 - val_loss: 0.3120 - val_accuracy: 0.9088\n",
      "Epoch 241/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3075 - accuracy: 0.9087 - val_loss: 0.3112 - val_accuracy: 0.9088\n",
      "Epoch 242/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3081 - accuracy: 0.9087 - val_loss: 0.3124 - val_accuracy: 0.9088\n",
      "Epoch 243/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3082 - accuracy: 0.9087 - val_loss: 0.3128 - val_accuracy: 0.9088\n",
      "Epoch 244/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3052 - accuracy: 0.9087 - val_loss: 0.3151 - val_accuracy: 0.9088\n",
      "Epoch 245/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3085 - accuracy: 0.9087 - val_loss: 0.3127 - val_accuracy: 0.9088\n",
      "Epoch 246/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3074 - accuracy: 0.9087 - val_loss: 0.3131 - val_accuracy: 0.9088\n",
      "Epoch 247/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3056 - accuracy: 0.9087 - val_loss: 0.3111 - val_accuracy: 0.9088\n",
      "Epoch 248/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3112 - accuracy: 0.9087 - val_loss: 0.3107 - val_accuracy: 0.9088\n",
      "Epoch 249/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3054 - accuracy: 0.9087 - val_loss: 0.3128 - val_accuracy: 0.9088\n",
      "Epoch 250/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3090 - accuracy: 0.9087 - val_loss: 0.3137 - val_accuracy: 0.9088\n",
      "Epoch 251/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3066 - accuracy: 0.9087 - val_loss: 0.3145 - val_accuracy: 0.9088\n",
      "Epoch 252/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3022 - accuracy: 0.9087 - val_loss: 0.3129 - val_accuracy: 0.9088\n",
      "Epoch 253/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3106 - accuracy: 0.9075 - val_loss: 0.3352 - val_accuracy: 0.9088\n",
      "Epoch 254/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3061 - accuracy: 0.9087 - val_loss: 0.3102 - val_accuracy: 0.9088\n",
      "Epoch 255/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3340 - accuracy: 0.9086 - val_loss: 0.3204 - val_accuracy: 0.9088\n",
      "Epoch 256/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3174 - accuracy: 0.9087 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 257/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3060 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 258/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3094 - accuracy: 0.9087 - val_loss: 0.3104 - val_accuracy: 0.9088\n",
      "Epoch 259/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3075 - accuracy: 0.9087 - val_loss: 0.3104 - val_accuracy: 0.9088\n",
      "Epoch 260/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3089 - accuracy: 0.9087 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 261/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3065 - accuracy: 0.9087 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 262/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3063 - accuracy: 0.9087 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 263/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3056 - accuracy: 0.9087 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 264/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3096 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 265/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3059 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 266/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3085 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 267/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3062 - accuracy: 0.9087 - val_loss: 0.3100 - val_accuracy: 0.9088\n",
      "Epoch 268/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3090 - accuracy: 0.9087 - val_loss: 0.3815 - val_accuracy: 0.9088\n",
      "Epoch 269/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3516 - accuracy: 0.9087 - val_loss: 0.3199 - val_accuracy: 0.9088\n",
      "Epoch 270/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3119 - accuracy: 0.9087 - val_loss: 0.3108 - val_accuracy: 0.9088\n",
      "Epoch 271/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3107 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 272/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3069 - accuracy: 0.9087 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 273/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3064 - accuracy: 0.9087 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 274/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3081 - accuracy: 0.9087 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 275/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3053 - accuracy: 0.9087 - val_loss: 0.3106 - val_accuracy: 0.9088\n",
      "Epoch 276/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3101 - accuracy: 0.9087 - val_loss: 0.3100 - val_accuracy: 0.9088\n",
      "Epoch 277/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3094 - accuracy: 0.9087 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 278/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3104 - accuracy: 0.9087 - val_loss: 0.3121 - val_accuracy: 0.9088\n",
      "Epoch 279/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3063 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 280/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3040 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 281/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3037 - accuracy: 0.9087 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 282/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3063 - accuracy: 0.9087 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 283/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3033 - accuracy: 0.9087 - val_loss: 0.3102 - val_accuracy: 0.9088\n",
      "Epoch 284/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3020 - accuracy: 0.9087 - val_loss: 0.3110 - val_accuracy: 0.9088\n",
      "Epoch 285/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3077 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3045 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 287/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3042 - accuracy: 0.9087 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 288/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3052 - accuracy: 0.9087 - val_loss: 0.3107 - val_accuracy: 0.9088\n",
      "Epoch 289/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3038 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 290/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3058 - accuracy: 0.9087 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 291/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3028 - accuracy: 0.9087 - val_loss: 0.3106 - val_accuracy: 0.9088\n",
      "Epoch 292/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3027 - accuracy: 0.9087 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 293/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3274 - accuracy: 0.9084 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 294/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3060 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 295/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3046 - accuracy: 0.9087 - val_loss: 0.3100 - val_accuracy: 0.9088\n",
      "Epoch 296/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3062 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 297/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3036 - accuracy: 0.9087 - val_loss: 0.3102 - val_accuracy: 0.9088\n",
      "Epoch 298/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3024 - accuracy: 0.9087 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 299/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3042 - accuracy: 0.9087 - val_loss: 0.3102 - val_accuracy: 0.9088\n",
      "Epoch 300/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3048 - accuracy: 0.9087 - val_loss: 0.3097 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac21f4d1f0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 256, epochs = 300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss.head()\n",
    "loss[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict_classes(X_train)\n",
    "test_pred = model.predict_classes (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[12597     0]\n",
      " [ 1266     0]]\n",
      "Log Loss:\n",
      " 3.154157896267542\n",
      "Hinge Loss:\n",
      " 1.0\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9086777753732959\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     12597\n",
      "           1       0.00      0.00      0.00      1266\n",
      "\n",
      "    accuracy                           0.91     13863\n",
      "   macro avg       0.45      0.50      0.48     13863\n",
      "weighted avg       0.83      0.91      0.87     13863\n",
      "\n",
      "----------\n",
      "Confusion Matrix:\n",
      " [[5400    0]\n",
      " [ 542    0]]\n",
      "Log Loss:\n",
      " 3.150457220808077\n",
      "Hinge Loss:\n",
      " 1.0\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9087849209020532\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      5400\n",
      "           1       0.00      0.00      0.00       542\n",
      "\n",
      "    accuracy                           0.91      5942\n",
      "   macro avg       0.45      0.50      0.48      5942\n",
      "weighted avg       0.83      0.91      0.87      5942\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train, train_pred)\n",
    "print('-'*10)\n",
    "metrics(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3004 - accuracy: 0.9087 - val_loss: 0.3110 - val_accuracy: 0.9088\n",
      "Epoch 2/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3004 - accuracy: 0.9087 - val_loss: 0.3159 - val_accuracy: 0.9088\n",
      "Epoch 3/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3039 - accuracy: 0.9087 - val_loss: 0.3094 - val_accuracy: 0.9088\n",
      "Epoch 4/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3008 - accuracy: 0.9087 - val_loss: 0.3126 - val_accuracy: 0.9088\n",
      "Epoch 5/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2976 - accuracy: 0.9087 - val_loss: 0.3115 - val_accuracy: 0.9088\n",
      "Epoch 6/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2958 - accuracy: 0.9087 - val_loss: 0.3225 - val_accuracy: 0.9088\n",
      "Epoch 7/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2983 - accuracy: 0.9087 - val_loss: 0.3236 - val_accuracy: 0.9088\n",
      "Epoch 8/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3016 - accuracy: 0.9087 - val_loss: 0.3144 - val_accuracy: 0.9088\n",
      "Epoch 9/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2995 - accuracy: 0.9087 - val_loss: 0.3348 - val_accuracy: 0.9088\n",
      "Epoch 10/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2967 - accuracy: 0.9087 - val_loss: 0.3776 - val_accuracy: 0.9088\n",
      "Epoch 11/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.4008 - accuracy: 0.9069 - val_loss: 0.3627 - val_accuracy: 0.9088\n",
      "Epoch 12/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3289 - accuracy: 0.9082 - val_loss: 0.3109 - val_accuracy: 0.9088\n",
      "Epoch 13/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3080 - accuracy: 0.9087 - val_loss: 0.3116 - val_accuracy: 0.9088\n",
      "Epoch 14/300\n",
      "55/55 [==============================] - 3s 47ms/step - loss: 0.3087 - accuracy: 0.9087 - val_loss: 0.3128 - val_accuracy: 0.9088\n",
      "Epoch 15/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3082 - accuracy: 0.9087 - val_loss: 0.3102 - val_accuracy: 0.9088\n",
      "Epoch 16/300\n",
      "55/55 [==============================] - 3s 56ms/step - loss: 0.3042 - accuracy: 0.9087 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 17/300\n",
      "55/55 [==============================] - 3s 52ms/step - loss: 0.3066 - accuracy: 0.9087 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 18/300\n",
      "55/55 [==============================] - 3s 55ms/step - loss: 0.3051 - accuracy: 0.9087 - val_loss: 0.3119 - val_accuracy: 0.9088\n",
      "Epoch 19/300\n",
      "55/55 [==============================] - 3s 49ms/step - loss: 0.3093 - accuracy: 0.9087 - val_loss: 0.3103 - val_accuracy: 0.9088\n",
      "Epoch 20/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3020 - accuracy: 0.9087 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 21/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3100 - accuracy: 0.9087 - val_loss: 0.3114 - val_accuracy: 0.9088\n",
      "Epoch 22/300\n",
      "55/55 [==============================] - 3s 53ms/step - loss: 0.3086 - accuracy: 0.9087 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 23/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3077 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 24/300\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.3049 - accuracy: 0.9087 - val_loss: 0.3108 - val_accuracy: 0.9088\n",
      "Epoch 25/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3085 - accuracy: 0.9087 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 26/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3048 - accuracy: 0.9087 - val_loss: 0.3103 - val_accuracy: 0.9088\n",
      "Epoch 27/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3026 - accuracy: 0.9087 - val_loss: 0.3119 - val_accuracy: 0.9088\n",
      "Epoch 28/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3009 - accuracy: 0.9087 - val_loss: 0.3104 - val_accuracy: 0.9088\n",
      "Epoch 29/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.2996 - accuracy: 0.9087 - val_loss: 0.3104 - val_accuracy: 0.9088\n",
      "Epoch 30/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.2984 - accuracy: 0.9087 - val_loss: 0.3148 - val_accuracy: 0.9088\n",
      "Epoch 31/300\n",
      "55/55 [==============================] - 3s 54ms/step - loss: 0.2932 - accuracy: 0.9090 - val_loss: 0.3112 - val_accuracy: 0.9088\n",
      "Epoch 32/300\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.2982 - accuracy: 0.9087 - val_loss: 0.3165 - val_accuracy: 0.9088\n",
      "Epoch 33/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3047 - accuracy: 0.9087 - val_loss: 0.3152 - val_accuracy: 0.9088\n",
      "Epoch 34/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3019 - accuracy: 0.9082 - val_loss: 0.3267 - val_accuracy: 0.9088\n",
      "Epoch 35/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3010 - accuracy: 0.9085 - val_loss: 0.3169 - val_accuracy: 0.9088\n",
      "Epoch 36/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.2902 - accuracy: 0.9087 - val_loss: 0.3094 - val_accuracy: 0.9088\n",
      "Epoch 37/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2871 - accuracy: 0.9085 - val_loss: 0.3309 - val_accuracy: 0.9088\n",
      "Epoch 38/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3103 - accuracy: 0.9085 - val_loss: 0.3185 - val_accuracy: 0.9088\n",
      "Epoch 39/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.2886 - accuracy: 0.9087 - val_loss: 0.3802 - val_accuracy: 0.9088\n",
      "Epoch 40/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.2901 - accuracy: 0.9086 - val_loss: 0.4078 - val_accuracy: 0.9088\n",
      "Epoch 41/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2853 - accuracy: 0.9087 - val_loss: 0.6124 - val_accuracy: 0.9088\n",
      "Epoch 42/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3021 - accuracy: 0.9085 - val_loss: 0.3134 - val_accuracy: 0.9088\n",
      "Epoch 43/300\n",
      "55/55 [==============================] - 3s 58ms/step - loss: 0.2944 - accuracy: 0.9086 - val_loss: 0.3285 - val_accuracy: 0.9088\n",
      "Epoch 44/300\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.2867 - accuracy: 0.9090 - val_loss: 0.3457 - val_accuracy: 0.9088\n",
      "Epoch 45/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.2857 - accuracy: 0.9089 - val_loss: 0.3601 - val_accuracy: 0.9088\n",
      "Epoch 46/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.2853 - accuracy: 0.9087 - val_loss: 0.3206 - val_accuracy: 0.9088\n",
      "Epoch 47/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.2852 - accuracy: 0.9086 - val_loss: 0.3599 - val_accuracy: 0.9088\n",
      "Epoch 48/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2852 - accuracy: 0.9085 - val_loss: 0.3970 - val_accuracy: 0.9088\n",
      "Epoch 49/300\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.2807 - accuracy: 0.9087 - val_loss: 0.4114 - val_accuracy: 0.9088\n",
      "Epoch 50/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.2833 - accuracy: 0.9090 - val_loss: 0.3307 - val_accuracy: 0.9088\n",
      "Epoch 51/300\n",
      "55/55 [==============================] - 3s 62ms/step - loss: 0.2791 - accuracy: 0.9089 - val_loss: 0.4602 - val_accuracy: 0.9088\n",
      "Epoch 52/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.2778 - accuracy: 0.9089 - val_loss: 0.3779 - val_accuracy: 0.9088\n",
      "Epoch 53/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.2766 - accuracy: 0.9084 - val_loss: 0.3744 - val_accuracy: 0.9088\n",
      "Epoch 54/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2773 - accuracy: 0.9088 - val_loss: 0.4831 - val_accuracy: 0.9088\n",
      "Epoch 55/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2919 - accuracy: 0.9082 - val_loss: 0.3405 - val_accuracy: 0.9088\n",
      "Epoch 56/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2830 - accuracy: 0.9087 - val_loss: 0.3816 - val_accuracy: 0.9088\n",
      "Epoch 57/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3219 - accuracy: 0.8999 - val_loss: 0.3894 - val_accuracy: 0.9088\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3567 - accuracy: 0.9087 - val_loss: 0.3107 - val_accuracy: 0.9088\n",
      "Epoch 59/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3184 - accuracy: 0.9087 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 60/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3088 - accuracy: 0.9087 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 61/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3201 - accuracy: 0.9087 - val_loss: 0.3111 - val_accuracy: 0.9088\n",
      "Epoch 62/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.3110 - accuracy: 0.9087 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 63/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3156 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 64/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3054 - accuracy: 0.9087 - val_loss: 0.3100 - val_accuracy: 0.9088\n",
      "Epoch 65/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3026 - accuracy: 0.9087 - val_loss: 0.3100 - val_accuracy: 0.9088\n",
      "Epoch 66/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.3086 - accuracy: 0.9087 - val_loss: 0.3123 - val_accuracy: 0.9088\n",
      "Epoch 67/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3080 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 68/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3080 - accuracy: 0.9087 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 69/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3010 - accuracy: 0.9087 - val_loss: 0.3112 - val_accuracy: 0.9088\n",
      "Epoch 70/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2984 - accuracy: 0.9087 - val_loss: 0.3184 - val_accuracy: 0.9088\n",
      "Epoch 71/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.3044 - accuracy: 0.9087 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 72/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3192 - accuracy: 0.9087 - val_loss: 0.3218 - val_accuracy: 0.9088\n",
      "Epoch 73/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.2968 - accuracy: 0.9087 - val_loss: 0.3154 - val_accuracy: 0.9088\n",
      "Epoch 74/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3034 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 75/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3075 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 76/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.2928 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 77/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2922 - accuracy: 0.9087 - val_loss: 0.3230 - val_accuracy: 0.9088\n",
      "Epoch 78/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3175 - accuracy: 0.9087 - val_loss: 0.3127 - val_accuracy: 0.9088\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac2639beb0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 256, epochs = 300, validation_data = (X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict_classes(X_train)\n",
    "test_pred = model.predict_classes (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Initialiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fac29f8eac0>\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "model = deep_model_algo(activation='relu', nodes = [300, 550, 500, 300, 200, 150, 100, 50], opti = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "55/55 [==============================] - 8s 52ms/step - loss: 0.9784 - accuracy: 0.8556 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 2/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.6300 - accuracy: 0.8937 - val_loss: 0.3154 - val_accuracy: 0.9088\n",
      "Epoch 3/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.6332 - accuracy: 0.9093 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 4/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3721 - accuracy: 0.9058 - val_loss: 0.3109 - val_accuracy: 0.9088\n",
      "Epoch 5/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3379 - accuracy: 0.9103 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 6/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3348 - accuracy: 0.9078 - val_loss: 0.3109 - val_accuracy: 0.9088\n",
      "Epoch 7/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3295 - accuracy: 0.9099 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 8/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3249 - accuracy: 0.9112 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 9/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3254 - accuracy: 0.9108 - val_loss: 0.3100 - val_accuracy: 0.9088\n",
      "Epoch 10/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3424 - accuracy: 0.9067 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 11/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3383 - accuracy: 0.9074 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 12/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3402 - accuracy: 0.9064 - val_loss: 0.3118 - val_accuracy: 0.9088\n",
      "Epoch 13/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3167 - accuracy: 0.9107 - val_loss: 0.3110 - val_accuracy: 0.9088\n",
      "Epoch 14/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3325 - accuracy: 0.9062 - val_loss: 0.3116 - val_accuracy: 0.9088\n",
      "Epoch 15/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3418 - accuracy: 0.9056 - val_loss: 0.3131 - val_accuracy: 0.9088\n",
      "Epoch 16/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3218 - accuracy: 0.9090 - val_loss: 0.3168 - val_accuracy: 0.9088\n",
      "Epoch 17/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3276 - accuracy: 0.9114 - val_loss: 0.3203 - val_accuracy: 0.9088\n",
      "Epoch 18/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3402 - accuracy: 0.9092 - val_loss: 0.3143 - val_accuracy: 0.9088\n",
      "Epoch 19/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3249 - accuracy: 0.9100 - val_loss: 0.3135 - val_accuracy: 0.9088\n",
      "Epoch 20/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3212 - accuracy: 0.9090 - val_loss: 0.3100 - val_accuracy: 0.9088\n",
      "Epoch 21/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3437 - accuracy: 0.9047 - val_loss: 0.3109 - val_accuracy: 0.9088\n",
      "Epoch 22/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3198 - accuracy: 0.9105 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 23/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3232 - accuracy: 0.9081 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 24/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3336 - accuracy: 0.9062 - val_loss: 0.3209 - val_accuracy: 0.9088\n",
      "Epoch 25/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3297 - accuracy: 0.9095 - val_loss: 0.3210 - val_accuracy: 0.9088\n",
      "Epoch 26/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3611 - accuracy: 0.9076 - val_loss: 0.3108 - val_accuracy: 0.9088\n",
      "Epoch 27/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3328 - accuracy: 0.9064 - val_loss: 0.3148 - val_accuracy: 0.9088\n",
      "Epoch 28/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3343 - accuracy: 0.9070 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 29/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3168 - accuracy: 0.9103 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 30/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3186 - accuracy: 0.9054 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 31/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2906 - accuracy: 0.9149 - val_loss: 0.3103 - val_accuracy: 0.9088\n",
      "Epoch 32/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.2960 - accuracy: 0.9133 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 33/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3143 - accuracy: 0.9080 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 34/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3073 - accuracy: 0.9074 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 35/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3108 - accuracy: 0.9065 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 36/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3015 - accuracy: 0.9099 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 37/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3043 - accuracy: 0.9099 - val_loss: 0.3127 - val_accuracy: 0.9088\n",
      "Epoch 38/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.2956 - accuracy: 0.9104 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 39/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.2992 - accuracy: 0.9107 - val_loss: 0.3130 - val_accuracy: 0.9088\n",
      "Epoch 40/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3036 - accuracy: 0.9104 - val_loss: 0.3142 - val_accuracy: 0.9088\n",
      "Epoch 41/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.2907 - accuracy: 0.9133 - val_loss: 0.3106 - val_accuracy: 0.9088\n",
      "Epoch 42/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3055 - accuracy: 0.9066 - val_loss: 0.3106 - val_accuracy: 0.9088\n",
      "Epoch 43/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3128 - accuracy: 0.9066 - val_loss: 0.3109 - val_accuracy: 0.9088\n",
      "Epoch 44/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3033 - accuracy: 0.9095 - val_loss: 0.3116 - val_accuracy: 0.9088\n",
      "Epoch 45/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.2959 - accuracy: 0.9129 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 46/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.2936 - accuracy: 0.9110 - val_loss: 0.3111 - val_accuracy: 0.9088\n",
      "Epoch 47/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3127 - accuracy: 0.9029 - val_loss: 0.3155 - val_accuracy: 0.9088\n",
      "Epoch 48/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3104 - accuracy: 0.9058 - val_loss: 0.3190 - val_accuracy: 0.9088\n",
      "Epoch 49/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3084 - accuracy: 0.9063 - val_loss: 0.3153 - val_accuracy: 0.9088\n",
      "Epoch 50/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3022 - accuracy: 0.9105 - val_loss: 0.3110 - val_accuracy: 0.9088\n",
      "Epoch 51/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.2963 - accuracy: 0.9100 - val_loss: 0.3239 - val_accuracy: 0.9088\n",
      "Epoch 52/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.2969 - accuracy: 0.9124 - val_loss: 0.3207 - val_accuracy: 0.9088\n",
      "Epoch 53/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3158 - accuracy: 0.9083 - val_loss: 0.3314 - val_accuracy: 0.9088\n",
      "Epoch 54/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3125 - accuracy: 0.9019 - val_loss: 0.3432 - val_accuracy: 0.9088\n",
      "Epoch 55/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3058 - accuracy: 0.9064 - val_loss: 0.3348 - val_accuracy: 0.9088\n",
      "Epoch 56/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3024 - accuracy: 0.9085 - val_loss: 0.3157 - val_accuracy: 0.9088\n",
      "Epoch 57/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3006 - accuracy: 0.9080 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3009 - accuracy: 0.9079 - val_loss: 0.3102 - val_accuracy: 0.9088\n",
      "Epoch 59/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2915 - accuracy: 0.9099 - val_loss: 0.3113 - val_accuracy: 0.9088\n",
      "Epoch 60/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2893 - accuracy: 0.9097 - val_loss: 0.3233 - val_accuracy: 0.9088\n",
      "Epoch 61/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3131 - accuracy: 0.9040 - val_loss: 0.3242 - val_accuracy: 0.9088\n",
      "Epoch 62/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3029 - accuracy: 0.9072 - val_loss: 0.3197 - val_accuracy: 0.9088\n",
      "Epoch 63/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.2931 - accuracy: 0.9080 - val_loss: 0.3182 - val_accuracy: 0.9088\n",
      "Epoch 64/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2996 - accuracy: 0.9099 - val_loss: 0.3235 - val_accuracy: 0.9088\n",
      "Epoch 65/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3094 - accuracy: 0.9079 - val_loss: 0.3108 - val_accuracy: 0.9088\n",
      "Epoch 66/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3119 - accuracy: 0.9071 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 67/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3188 - accuracy: 0.9033 - val_loss: 0.3104 - val_accuracy: 0.9088\n",
      "Epoch 68/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3006 - accuracy: 0.9068 - val_loss: 0.3115 - val_accuracy: 0.9088\n",
      "Epoch 69/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2915 - accuracy: 0.9146 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 70/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2973 - accuracy: 0.9097 - val_loss: 0.3176 - val_accuracy: 0.9088\n",
      "Epoch 71/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2940 - accuracy: 0.9059 - val_loss: 0.3298 - val_accuracy: 0.9088\n",
      "Epoch 72/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2872 - accuracy: 0.9107 - val_loss: 0.3193 - val_accuracy: 0.9088\n",
      "Epoch 73/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2941 - accuracy: 0.9073 - val_loss: 0.3182 - val_accuracy: 0.9088\n",
      "Epoch 74/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2889 - accuracy: 0.9083 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 75/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.2890 - accuracy: 0.9114 - val_loss: 0.3212 - val_accuracy: 0.9088\n",
      "Epoch 76/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2912 - accuracy: 0.9075 - val_loss: 0.3148 - val_accuracy: 0.9088\n",
      "Epoch 77/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2918 - accuracy: 0.9074 - val_loss: 0.3362 - val_accuracy: 0.9088\n",
      "Epoch 78/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.3036 - accuracy: 0.9046 - val_loss: 0.3240 - val_accuracy: 0.9088\n",
      "Epoch 79/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2811 - accuracy: 0.9076 - val_loss: 0.3217 - val_accuracy: 0.9088\n",
      "Epoch 80/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2925 - accuracy: 0.9059 - val_loss: 0.3237 - val_accuracy: 0.9088\n",
      "Epoch 81/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2864 - accuracy: 0.9104 - val_loss: 0.3112 - val_accuracy: 0.9088\n",
      "Epoch 82/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2824 - accuracy: 0.9090 - val_loss: 0.3455 - val_accuracy: 0.9088\n",
      "Epoch 83/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.2922 - accuracy: 0.9105 - val_loss: 0.3307 - val_accuracy: 0.9088\n",
      "Epoch 84/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2873 - accuracy: 0.9079 - val_loss: 0.3166 - val_accuracy: 0.9088\n",
      "Epoch 85/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2825 - accuracy: 0.9081 - val_loss: 0.3203 - val_accuracy: 0.9088\n",
      "Epoch 86/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2881 - accuracy: 0.9110 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 87/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2838 - accuracy: 0.9138 - val_loss: 0.3615 - val_accuracy: 0.9088\n",
      "Epoch 88/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2939 - accuracy: 0.9080 - val_loss: 0.3454 - val_accuracy: 0.9088\n",
      "Epoch 89/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.3021 - accuracy: 0.9067 - val_loss: 0.3313 - val_accuracy: 0.9088\n",
      "Epoch 90/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2853 - accuracy: 0.9081 - val_loss: 0.3188 - val_accuracy: 0.9088\n",
      "Epoch 91/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2870 - accuracy: 0.9083 - val_loss: 0.3158 - val_accuracy: 0.9088\n",
      "Epoch 92/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2848 - accuracy: 0.9090 - val_loss: 0.3187 - val_accuracy: 0.9088\n",
      "Epoch 93/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2822 - accuracy: 0.9105 - val_loss: 0.3133 - val_accuracy: 0.9088\n",
      "Epoch 94/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2770 - accuracy: 0.9102 - val_loss: 0.3210 - val_accuracy: 0.9088\n",
      "Epoch 95/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2924 - accuracy: 0.9076 - val_loss: 0.3206 - val_accuracy: 0.9088\n",
      "Epoch 96/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.2883 - accuracy: 0.9095 - val_loss: 0.3126 - val_accuracy: 0.9088\n",
      "Epoch 97/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2781 - accuracy: 0.9066 - val_loss: 0.3167 - val_accuracy: 0.9088\n",
      "Epoch 98/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2921 - accuracy: 0.9050 - val_loss: 0.3238 - val_accuracy: 0.9088\n",
      "Epoch 99/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2869 - accuracy: 0.9061 - val_loss: 0.3169 - val_accuracy: 0.9088\n",
      "Epoch 100/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.3041 - accuracy: 0.9087 - val_loss: 0.3103 - val_accuracy: 0.9088\n",
      "Epoch 101/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2834 - accuracy: 0.9073 - val_loss: 0.3171 - val_accuracy: 0.9088\n",
      "Epoch 102/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2955 - accuracy: 0.9033 - val_loss: 0.3274 - val_accuracy: 0.9088\n",
      "Epoch 103/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2885 - accuracy: 0.9076 - val_loss: 0.3119 - val_accuracy: 0.9088\n",
      "Epoch 104/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2855 - accuracy: 0.9051 - val_loss: 0.3244 - val_accuracy: 0.9088\n",
      "Epoch 105/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2703 - accuracy: 0.9115 - val_loss: 0.3174 - val_accuracy: 0.9088\n",
      "Epoch 106/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2728 - accuracy: 0.9107 - val_loss: 0.3265 - val_accuracy: 0.9088\n",
      "Epoch 107/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2869 - accuracy: 0.9075 - val_loss: 0.3116 - val_accuracy: 0.9088\n",
      "Epoch 108/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2928 - accuracy: 0.9064 - val_loss: 0.3305 - val_accuracy: 0.9088\n",
      "Epoch 109/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2905 - accuracy: 0.9082 - val_loss: 0.3277 - val_accuracy: 0.9088\n",
      "Epoch 110/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2711 - accuracy: 0.9125 - val_loss: 0.3182 - val_accuracy: 0.9088\n",
      "Epoch 111/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2833 - accuracy: 0.9091 - val_loss: 0.3211 - val_accuracy: 0.9088\n",
      "Epoch 112/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2793 - accuracy: 0.9080 - val_loss: 0.3256 - val_accuracy: 0.9088\n",
      "Epoch 113/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2805 - accuracy: 0.9079 - val_loss: 0.3459 - val_accuracy: 0.9088\n",
      "Epoch 114/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2919 - accuracy: 0.9055 - val_loss: 0.3354 - val_accuracy: 0.9088\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2795 - accuracy: 0.9087 - val_loss: 0.3177 - val_accuracy: 0.9088\n",
      "Epoch 116/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2768 - accuracy: 0.9090 - val_loss: 0.3261 - val_accuracy: 0.9088\n",
      "Epoch 117/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2784 - accuracy: 0.9083 - val_loss: 0.3144 - val_accuracy: 0.9088\n",
      "Epoch 118/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2895 - accuracy: 0.9072 - val_loss: 0.3205 - val_accuracy: 0.9088\n",
      "Epoch 119/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2792 - accuracy: 0.9101 - val_loss: 0.3204 - val_accuracy: 0.9088\n",
      "Epoch 120/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2812 - accuracy: 0.9069 - val_loss: 0.3375 - val_accuracy: 0.9088\n",
      "Epoch 121/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2684 - accuracy: 0.9116 - val_loss: 0.3271 - val_accuracy: 0.9088\n",
      "Epoch 122/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2814 - accuracy: 0.9076 - val_loss: 0.3234 - val_accuracy: 0.9088\n",
      "Epoch 123/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2721 - accuracy: 0.9086 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 124/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2824 - accuracy: 0.9106 - val_loss: 0.3346 - val_accuracy: 0.9088\n",
      "Epoch 125/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.2804 - accuracy: 0.9082 - val_loss: 0.3146 - val_accuracy: 0.9088\n",
      "Epoch 126/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2861 - accuracy: 0.9096 - val_loss: 0.3110 - val_accuracy: 0.9088\n",
      "Epoch 127/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2772 - accuracy: 0.9123 - val_loss: 0.3238 - val_accuracy: 0.9088\n",
      "Epoch 128/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2793 - accuracy: 0.9059 - val_loss: 0.3406 - val_accuracy: 0.9088\n",
      "Epoch 129/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2871 - accuracy: 0.9072 - val_loss: 0.4601 - val_accuracy: 0.9088\n",
      "Epoch 130/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2599 - accuracy: 0.9160 - val_loss: 0.3681 - val_accuracy: 0.9088\n",
      "Epoch 131/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2861 - accuracy: 0.9088 - val_loss: 0.3464 - val_accuracy: 0.9088\n",
      "Epoch 132/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3696 - accuracy: 0.9094 - val_loss: 0.3547 - val_accuracy: 0.9088\n",
      "Epoch 133/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.3137 - accuracy: 0.9113 - val_loss: 0.3141 - val_accuracy: 0.9088\n",
      "Epoch 134/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.3158 - accuracy: 0.9078 - val_loss: 0.3122 - val_accuracy: 0.9088\n",
      "Epoch 135/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.3114 - accuracy: 0.9089 - val_loss: 0.3129 - val_accuracy: 0.9088\n",
      "Epoch 136/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3219 - accuracy: 0.9049 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 137/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.3198 - accuracy: 0.9054 - val_loss: 0.3143 - val_accuracy: 0.9088\n",
      "Epoch 138/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3040 - accuracy: 0.9123 - val_loss: 0.3149 - val_accuracy: 0.9088\n",
      "Epoch 139/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.3113 - accuracy: 0.9077 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 140/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.3029 - accuracy: 0.9101 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 141/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.3113 - accuracy: 0.9067 - val_loss: 0.3138 - val_accuracy: 0.9088\n",
      "Epoch 142/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.3140 - accuracy: 0.9060 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 143/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.3009 - accuracy: 0.9110 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 144/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.3067 - accuracy: 0.9070 - val_loss: 0.3109 - val_accuracy: 0.9088\n",
      "Epoch 145/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2892 - accuracy: 0.9135 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 146/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2888 - accuracy: 0.9095 - val_loss: 0.3102 - val_accuracy: 0.9088\n",
      "Epoch 147/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.2902 - accuracy: 0.9089 - val_loss: 0.3154 - val_accuracy: 0.9088\n",
      "Epoch 148/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2908 - accuracy: 0.9073 - val_loss: 0.3132 - val_accuracy: 0.9088\n",
      "Epoch 149/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2838 - accuracy: 0.9095 - val_loss: 0.3227 - val_accuracy: 0.9088\n",
      "Epoch 150/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2897 - accuracy: 0.9079 - val_loss: 0.3149 - val_accuracy: 0.9088\n",
      "Epoch 151/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2851 - accuracy: 0.9115 - val_loss: 0.3178 - val_accuracy: 0.9088\n",
      "Epoch 152/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2828 - accuracy: 0.9110 - val_loss: 0.3129 - val_accuracy: 0.9088\n",
      "Epoch 153/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2736 - accuracy: 0.9125 - val_loss: 0.3236 - val_accuracy: 0.9088\n",
      "Epoch 154/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2905 - accuracy: 0.9033 - val_loss: 0.3284 - val_accuracy: 0.9088\n",
      "Epoch 155/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2994 - accuracy: 0.9078 - val_loss: 0.3185 - val_accuracy: 0.9088\n",
      "Epoch 156/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2810 - accuracy: 0.9106 - val_loss: 0.3180 - val_accuracy: 0.9088\n",
      "Epoch 157/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2819 - accuracy: 0.9085 - val_loss: 0.3189 - val_accuracy: 0.9088\n",
      "Epoch 158/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.2791 - accuracy: 0.9097 - val_loss: 0.3232 - val_accuracy: 0.9088\n",
      "Epoch 159/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2870 - accuracy: 0.9086 - val_loss: 0.3270 - val_accuracy: 0.9088\n",
      "Epoch 160/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2817 - accuracy: 0.9084 - val_loss: 0.3214 - val_accuracy: 0.9088\n",
      "Epoch 161/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2769 - accuracy: 0.9109 - val_loss: 0.3273 - val_accuracy: 0.9088\n",
      "Epoch 162/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2764 - accuracy: 0.9103 - val_loss: 0.3222 - val_accuracy: 0.9088\n",
      "Epoch 163/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2856 - accuracy: 0.9061 - val_loss: 0.3285 - val_accuracy: 0.9088\n",
      "Epoch 164/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2844 - accuracy: 0.9075 - val_loss: 0.3299 - val_accuracy: 0.9088\n",
      "Epoch 165/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2851 - accuracy: 0.9120 - val_loss: 0.3190 - val_accuracy: 0.9088\n",
      "Epoch 166/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2793 - accuracy: 0.9105 - val_loss: 0.3271 - val_accuracy: 0.9088\n",
      "Epoch 167/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2889 - accuracy: 0.9082 - val_loss: 0.3344 - val_accuracy: 0.9088\n",
      "Epoch 168/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2800 - accuracy: 0.9096 - val_loss: 0.3312 - val_accuracy: 0.9088\n",
      "Epoch 169/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.2781 - accuracy: 0.9064 - val_loss: 0.4085 - val_accuracy: 0.9088\n",
      "Epoch 170/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2979 - accuracy: 0.9056 - val_loss: 0.3333 - val_accuracy: 0.9088\n",
      "Epoch 171/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2837 - accuracy: 0.9095 - val_loss: 0.3245 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2767 - accuracy: 0.9103 - val_loss: 0.3176 - val_accuracy: 0.9088\n",
      "Epoch 173/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2992 - accuracy: 0.9089 - val_loss: 0.3144 - val_accuracy: 0.9088\n",
      "Epoch 174/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.3090 - accuracy: 0.9035 - val_loss: 0.3266 - val_accuracy: 0.9088\n",
      "Epoch 175/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2773 - accuracy: 0.9082 - val_loss: 0.3291 - val_accuracy: 0.9088\n",
      "Epoch 176/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2798 - accuracy: 0.9111 - val_loss: 0.3254 - val_accuracy: 0.9088\n",
      "Epoch 177/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2777 - accuracy: 0.9105 - val_loss: 0.3425 - val_accuracy: 0.9088\n",
      "Epoch 178/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2755 - accuracy: 0.9105 - val_loss: 0.3296 - val_accuracy: 0.9088\n",
      "Epoch 179/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2737 - accuracy: 0.9091 - val_loss: 0.3313 - val_accuracy: 0.9088\n",
      "Epoch 180/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2848 - accuracy: 0.9095 - val_loss: 0.3189 - val_accuracy: 0.9088\n",
      "Epoch 181/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.2779 - accuracy: 0.9121 - val_loss: 0.3176 - val_accuracy: 0.9088\n",
      "Epoch 182/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2892 - accuracy: 0.9061 - val_loss: 0.3325 - val_accuracy: 0.9088\n",
      "Epoch 183/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2865 - accuracy: 0.9042 - val_loss: 0.4277 - val_accuracy: 0.9088\n",
      "Epoch 184/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2726 - accuracy: 0.9086 - val_loss: 0.3434 - val_accuracy: 0.9088\n",
      "Epoch 185/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2678 - accuracy: 0.9110 - val_loss: 0.3289 - val_accuracy: 0.9088\n",
      "Epoch 186/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2785 - accuracy: 0.9064 - val_loss: 0.3175 - val_accuracy: 0.9088\n",
      "Epoch 187/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2813 - accuracy: 0.9093 - val_loss: 0.3257 - val_accuracy: 0.9088\n",
      "Epoch 188/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2702 - accuracy: 0.9084 - val_loss: 0.3414 - val_accuracy: 0.9088\n",
      "Epoch 189/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2740 - accuracy: 0.9094 - val_loss: 0.3259 - val_accuracy: 0.9088\n",
      "Epoch 190/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2660 - accuracy: 0.9093 - val_loss: 0.3395 - val_accuracy: 0.9088\n",
      "Epoch 191/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2810 - accuracy: 0.9084 - val_loss: 0.3277 - val_accuracy: 0.9088\n",
      "Epoch 192/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2768 - accuracy: 0.9093 - val_loss: 0.3345 - val_accuracy: 0.9088\n",
      "Epoch 193/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2930 - accuracy: 0.9066 - val_loss: 0.3346 - val_accuracy: 0.9088\n",
      "Epoch 194/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2782 - accuracy: 0.9092 - val_loss: 0.3828 - val_accuracy: 0.9088\n",
      "Epoch 195/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2825 - accuracy: 0.9051 - val_loss: 0.3603 - val_accuracy: 0.9088\n",
      "Epoch 196/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2888 - accuracy: 0.9072 - val_loss: 0.3342 - val_accuracy: 0.9088\n",
      "Epoch 197/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2805 - accuracy: 0.9100 - val_loss: 0.3304 - val_accuracy: 0.9088\n",
      "Epoch 198/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2686 - accuracy: 0.9133 - val_loss: 0.3285 - val_accuracy: 0.9088\n",
      "Epoch 199/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2778 - accuracy: 0.9115 - val_loss: 0.3297 - val_accuracy: 0.9088\n",
      "Epoch 200/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2821 - accuracy: 0.9083 - val_loss: 0.3308 - val_accuracy: 0.9088\n",
      "Epoch 201/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2712 - accuracy: 0.9107 - val_loss: 0.3358 - val_accuracy: 0.9088\n",
      "Epoch 202/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2791 - accuracy: 0.9077 - val_loss: 0.3346 - val_accuracy: 0.9088\n",
      "Epoch 203/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2704 - accuracy: 0.9106 - val_loss: 0.3258 - val_accuracy: 0.9088\n",
      "Epoch 204/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.2866 - accuracy: 0.9039 - val_loss: 0.3368 - val_accuracy: 0.9088\n",
      "Epoch 205/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2601 - accuracy: 0.9130 - val_loss: 0.3243 - val_accuracy: 0.9088\n",
      "Epoch 206/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2772 - accuracy: 0.9088 - val_loss: 0.3489 - val_accuracy: 0.9088\n",
      "Epoch 207/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2755 - accuracy: 0.9075 - val_loss: 0.3363 - val_accuracy: 0.9088\n",
      "Epoch 208/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2685 - accuracy: 0.9110 - val_loss: 0.3642 - val_accuracy: 0.9088\n",
      "Epoch 209/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2651 - accuracy: 0.9109 - val_loss: 0.3360 - val_accuracy: 0.9088\n",
      "Epoch 210/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2713 - accuracy: 0.9075 - val_loss: 0.3554 - val_accuracy: 0.9088\n",
      "Epoch 211/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2828 - accuracy: 0.9064 - val_loss: 1.4070 - val_accuracy: 0.9088\n",
      "Epoch 212/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2684 - accuracy: 0.9068 - val_loss: 0.4069 - val_accuracy: 0.9088\n",
      "Epoch 213/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2649 - accuracy: 0.9092 - val_loss: 0.3795 - val_accuracy: 0.9088\n",
      "Epoch 214/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2738 - accuracy: 0.9110 - val_loss: 0.3423 - val_accuracy: 0.9088\n",
      "Epoch 215/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2793 - accuracy: 0.9087 - val_loss: 0.3417 - val_accuracy: 0.9088\n",
      "Epoch 216/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2698 - accuracy: 0.9110 - val_loss: 0.3590 - val_accuracy: 0.9088\n",
      "Epoch 217/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2668 - accuracy: 0.9101 - val_loss: 0.3467 - val_accuracy: 0.9088\n",
      "Epoch 218/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2818 - accuracy: 0.9093 - val_loss: 0.3283 - val_accuracy: 0.9088\n",
      "Epoch 219/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2721 - accuracy: 0.9069 - val_loss: 0.3335 - val_accuracy: 0.9088\n",
      "Epoch 220/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2722 - accuracy: 0.9128 - val_loss: 0.3217 - val_accuracy: 0.9088\n",
      "Epoch 221/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2791 - accuracy: 0.9066 - val_loss: 0.3200 - val_accuracy: 0.9088\n",
      "Epoch 222/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2717 - accuracy: 0.9091 - val_loss: 0.3307 - val_accuracy: 0.9088\n",
      "Epoch 223/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2665 - accuracy: 0.9124 - val_loss: 0.3445 - val_accuracy: 0.9088\n",
      "Epoch 224/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2621 - accuracy: 0.9132 - val_loss: 0.3386 - val_accuracy: 0.9088\n",
      "Epoch 225/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2840 - accuracy: 0.9054 - val_loss: 0.3624 - val_accuracy: 0.9088\n",
      "Epoch 226/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2682 - accuracy: 0.9101 - val_loss: 0.3401 - val_accuracy: 0.9088\n",
      "Epoch 227/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2705 - accuracy: 0.9121 - val_loss: 0.3451 - val_accuracy: 0.9088\n",
      "Epoch 228/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2727 - accuracy: 0.9080 - val_loss: 0.3344 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2661 - accuracy: 0.9103 - val_loss: 0.3663 - val_accuracy: 0.9088\n",
      "Epoch 230/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2725 - accuracy: 0.9040 - val_loss: 0.3539 - val_accuracy: 0.9088\n",
      "Epoch 231/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2625 - accuracy: 0.9109 - val_loss: 0.3556 - val_accuracy: 0.9088\n",
      "Epoch 232/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2671 - accuracy: 0.9097 - val_loss: 0.3594 - val_accuracy: 0.9088\n",
      "Epoch 233/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2697 - accuracy: 0.9082 - val_loss: 0.3368 - val_accuracy: 0.9088\n",
      "Epoch 234/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2750 - accuracy: 0.9092 - val_loss: 0.3434 - val_accuracy: 0.9088\n",
      "Epoch 235/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2659 - accuracy: 0.9112 - val_loss: 0.3336 - val_accuracy: 0.9088\n",
      "Epoch 236/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2785 - accuracy: 0.9073 - val_loss: 0.3578 - val_accuracy: 0.9088\n",
      "Epoch 237/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2708 - accuracy: 0.9138 - val_loss: 0.3181 - val_accuracy: 0.9088\n",
      "Epoch 238/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2679 - accuracy: 0.9106 - val_loss: 0.3289 - val_accuracy: 0.9088\n",
      "Epoch 239/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2708 - accuracy: 0.9100 - val_loss: 0.3266 - val_accuracy: 0.9088\n",
      "Epoch 240/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2855 - accuracy: 0.9048 - val_loss: 0.3459 - val_accuracy: 0.9088\n",
      "Epoch 241/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2838 - accuracy: 0.9062 - val_loss: 0.3376 - val_accuracy: 0.9088\n",
      "Epoch 242/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2710 - accuracy: 0.9074 - val_loss: 0.3335 - val_accuracy: 0.9088\n",
      "Epoch 243/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2781 - accuracy: 0.9071 - val_loss: 0.3424 - val_accuracy: 0.9088\n",
      "Epoch 244/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2813 - accuracy: 0.9045 - val_loss: 0.3314 - val_accuracy: 0.9088\n",
      "Epoch 245/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2784 - accuracy: 0.9105 - val_loss: 0.3407 - val_accuracy: 0.9088\n",
      "Epoch 246/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2639 - accuracy: 0.9129 - val_loss: 0.3427 - val_accuracy: 0.9088\n",
      "Epoch 247/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2646 - accuracy: 0.9082 - val_loss: 0.3506 - val_accuracy: 0.9088\n",
      "Epoch 248/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2654 - accuracy: 0.9112 - val_loss: 0.3505 - val_accuracy: 0.9088\n",
      "Epoch 249/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2749 - accuracy: 0.9098 - val_loss: 0.3519 - val_accuracy: 0.9088\n",
      "Epoch 250/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2798 - accuracy: 0.9094 - val_loss: 0.3530 - val_accuracy: 0.9088\n",
      "Epoch 251/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2653 - accuracy: 0.9143 - val_loss: 0.3568 - val_accuracy: 0.9088\n",
      "Epoch 252/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2775 - accuracy: 0.9100 - val_loss: 0.3496 - val_accuracy: 0.9088\n",
      "Epoch 253/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2819 - accuracy: 0.9092 - val_loss: 0.3536 - val_accuracy: 0.9088\n",
      "Epoch 254/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2762 - accuracy: 0.9047 - val_loss: 0.3551 - val_accuracy: 0.9088\n",
      "Epoch 255/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2706 - accuracy: 0.9106 - val_loss: 0.3649 - val_accuracy: 0.9088\n",
      "Epoch 256/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2697 - accuracy: 0.9095 - val_loss: 0.3943 - val_accuracy: 0.9088\n",
      "Epoch 257/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2724 - accuracy: 0.9094 - val_loss: 0.3504 - val_accuracy: 0.9088\n",
      "Epoch 258/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2712 - accuracy: 0.9074 - val_loss: 0.3726 - val_accuracy: 0.9088\n",
      "Epoch 259/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2748 - accuracy: 0.9109 - val_loss: 0.3522 - val_accuracy: 0.9088\n",
      "Epoch 260/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2814 - accuracy: 0.9032 - val_loss: 0.3105 - val_accuracy: 0.9088\n",
      "Epoch 261/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.2844 - accuracy: 0.9070 - val_loss: 0.3455 - val_accuracy: 0.9088\n",
      "Epoch 262/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2649 - accuracy: 0.9087 - val_loss: 0.3634 - val_accuracy: 0.9088\n",
      "Epoch 263/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2664 - accuracy: 0.9087 - val_loss: 0.3414 - val_accuracy: 0.9088\n",
      "Epoch 264/300\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.2738 - accuracy: 0.9074 - val_loss: 0.3295 - val_accuracy: 0.9088\n",
      "Epoch 265/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2733 - accuracy: 0.9098 - val_loss: 0.3429 - val_accuracy: 0.9088\n",
      "Epoch 266/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2693 - accuracy: 0.9109 - val_loss: 0.3508 - val_accuracy: 0.9088\n",
      "Epoch 267/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2747 - accuracy: 0.9090 - val_loss: 0.3410 - val_accuracy: 0.9088\n",
      "Epoch 268/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2704 - accuracy: 0.9096 - val_loss: 0.3461 - val_accuracy: 0.9088\n",
      "Epoch 269/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2860 - accuracy: 0.9047 - val_loss: 0.4146 - val_accuracy: 0.9088\n",
      "Epoch 270/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2765 - accuracy: 0.9062 - val_loss: 0.3626 - val_accuracy: 0.9088\n",
      "Epoch 271/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2750 - accuracy: 0.9084 - val_loss: 0.3777 - val_accuracy: 0.9088\n",
      "Epoch 272/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2664 - accuracy: 0.9119 - val_loss: 0.3680 - val_accuracy: 0.9088\n",
      "Epoch 273/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2790 - accuracy: 0.9047 - val_loss: 0.4201 - val_accuracy: 0.9088\n",
      "Epoch 274/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2729 - accuracy: 0.9097 - val_loss: 0.3684 - val_accuracy: 0.9088\n",
      "Epoch 275/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2690 - accuracy: 0.9076 - val_loss: 0.3481 - val_accuracy: 0.9088\n",
      "Epoch 276/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2675 - accuracy: 0.9097 - val_loss: 0.3848 - val_accuracy: 0.9088\n",
      "Epoch 277/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2750 - accuracy: 0.9069 - val_loss: 0.3629 - val_accuracy: 0.9088\n",
      "Epoch 278/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2800 - accuracy: 0.9041 - val_loss: 0.3445 - val_accuracy: 0.9088\n",
      "Epoch 279/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2728 - accuracy: 0.9080 - val_loss: 0.3157 - val_accuracy: 0.9088\n",
      "Epoch 280/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2819 - accuracy: 0.9038 - val_loss: 0.3621 - val_accuracy: 0.9088\n",
      "Epoch 281/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2640 - accuracy: 0.9080 - val_loss: 0.3594 - val_accuracy: 0.9088\n",
      "Epoch 282/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2752 - accuracy: 0.9063 - val_loss: 0.3690 - val_accuracy: 0.9088\n",
      "Epoch 283/300\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.2743 - accuracy: 0.9097 - val_loss: 0.3815 - val_accuracy: 0.9088\n",
      "Epoch 284/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2765 - accuracy: 0.9069 - val_loss: 0.4077 - val_accuracy: 0.9088\n",
      "Epoch 285/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2870 - accuracy: 0.9049 - val_loss: 0.3532 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2746 - accuracy: 0.9099 - val_loss: 0.3639 - val_accuracy: 0.9088\n",
      "Epoch 287/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2704 - accuracy: 0.9122 - val_loss: 0.3542 - val_accuracy: 0.9088\n",
      "Epoch 288/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2687 - accuracy: 0.9106 - val_loss: 0.3540 - val_accuracy: 0.9088\n",
      "Epoch 289/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2765 - accuracy: 0.9071 - val_loss: 0.3697 - val_accuracy: 0.9088\n",
      "Epoch 290/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2678 - accuracy: 0.9083 - val_loss: 0.3839 - val_accuracy: 0.9088\n",
      "Epoch 291/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2724 - accuracy: 0.9094 - val_loss: 0.3603 - val_accuracy: 0.9088\n",
      "Epoch 292/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2687 - accuracy: 0.9058 - val_loss: 0.4721 - val_accuracy: 0.9088\n",
      "Epoch 293/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2597 - accuracy: 0.9127 - val_loss: 0.3165 - val_accuracy: 0.9088\n",
      "Epoch 294/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2772 - accuracy: 0.9113 - val_loss: 0.4156 - val_accuracy: 0.9088\n",
      "Epoch 295/300\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.2873 - accuracy: 0.9083 - val_loss: 0.3658 - val_accuracy: 0.9088\n",
      "Epoch 296/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2825 - accuracy: 0.9078 - val_loss: 0.3577 - val_accuracy: 0.9088\n",
      "Epoch 297/300\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.2826 - accuracy: 0.9080 - val_loss: 0.3214 - val_accuracy: 0.9088\n",
      "Epoch 298/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2640 - accuracy: 0.9088 - val_loss: 0.3601 - val_accuracy: 0.9088\n",
      "Epoch 299/300\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.2752 - accuracy: 0.9058 - val_loss: 0.3752 - val_accuracy: 0.9088\n",
      "Epoch 300/300\n",
      "55/55 [==============================] - 2s 32ms/step - loss: 0.2585 - accuracy: 0.9109 - val_loss: 0.3548 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac29fe4190>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 256, epochs = 300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fac2ea51fd0>\n"
     ]
    }
   ],
   "source": [
    "#Model 2 (Drop Out)\n",
    "model = deep_model_algo(activation='relu', nodes = [300, 550, 500, 300, 200, 150, 100, 50], opti = 'Adam', dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 300)               63900     \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 550)               165550    \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 550)               2200      \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 500)               275500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 774,401\n",
      "Trainable params: 770,101\n",
      "Non-trainable params: 4,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "55/55 [==============================] - 6s 62ms/step - loss: 2.3427 - accuracy: 0.7789 - val_loss: 1.4403 - val_accuracy: 0.9066\n",
      "Epoch 2/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 1.4301 - accuracy: 0.8571 - val_loss: 0.3466 - val_accuracy: 0.9066\n",
      "Epoch 3/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.9540 - accuracy: 0.8568 - val_loss: 0.3184 - val_accuracy: 0.9088\n",
      "Epoch 4/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.7751 - accuracy: 0.8857 - val_loss: 0.3215 - val_accuracy: 0.9088\n",
      "Epoch 5/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.6534 - accuracy: 0.8914 - val_loss: 0.3252 - val_accuracy: 0.9088\n",
      "Epoch 6/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.6041 - accuracy: 0.8896 - val_loss: 0.3332 - val_accuracy: 0.9088\n",
      "Epoch 7/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.5525 - accuracy: 0.9008 - val_loss: 0.3290 - val_accuracy: 0.9088\n",
      "Epoch 8/300\n",
      "55/55 [==============================] - 3s 45ms/step - loss: 0.5700 - accuracy: 0.8873 - val_loss: 0.3415 - val_accuracy: 0.9088\n",
      "Epoch 9/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.5592 - accuracy: 0.8923 - val_loss: 0.3324 - val_accuracy: 0.9088\n",
      "Epoch 10/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.5044 - accuracy: 0.8985 - val_loss: 0.3282 - val_accuracy: 0.9088\n",
      "Epoch 11/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.5481 - accuracy: 0.8997 - val_loss: 0.3299 - val_accuracy: 0.9088\n",
      "Epoch 12/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.4865 - accuracy: 0.9041 - val_loss: 0.3282 - val_accuracy: 0.9088\n",
      "Epoch 13/300\n",
      "55/55 [==============================] - 3s 45ms/step - loss: 0.4426 - accuracy: 0.9023 - val_loss: 0.3265 - val_accuracy: 0.9088\n",
      "Epoch 14/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.4804 - accuracy: 0.9003 - val_loss: 0.3240 - val_accuracy: 0.9088\n",
      "Epoch 15/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.4747 - accuracy: 0.9025 - val_loss: 0.3187 - val_accuracy: 0.9088\n",
      "Epoch 16/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.4540 - accuracy: 0.8968 - val_loss: 0.3181 - val_accuracy: 0.9088\n",
      "Epoch 17/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.4222 - accuracy: 0.9031 - val_loss: 0.3155 - val_accuracy: 0.9088\n",
      "Epoch 18/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.4284 - accuracy: 0.9010 - val_loss: 0.3137 - val_accuracy: 0.9088\n",
      "Epoch 19/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.3971 - accuracy: 0.9049 - val_loss: 0.3118 - val_accuracy: 0.9088\n",
      "Epoch 20/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3946 - accuracy: 0.9034 - val_loss: 0.3110 - val_accuracy: 0.9088\n",
      "Epoch 21/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3770 - accuracy: 0.9036 - val_loss: 0.3107 - val_accuracy: 0.9088\n",
      "Epoch 22/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.3866 - accuracy: 0.9059 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 23/300\n",
      "55/55 [==============================] - 3s 55ms/step - loss: 0.3772 - accuracy: 0.9059 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 24/300\n",
      "55/55 [==============================] - 3s 52ms/step - loss: 0.3679 - accuracy: 0.9064 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 25/300\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.3708 - accuracy: 0.9058 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 26/300\n",
      "55/55 [==============================] - 3s 49ms/step - loss: 0.3604 - accuracy: 0.9071 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 27/300\n",
      "55/55 [==============================] - 3s 51ms/step - loss: 0.3431 - accuracy: 0.9075 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 28/300\n",
      "55/55 [==============================] - 3s 52ms/step - loss: 0.3491 - accuracy: 0.9074 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 29/300\n",
      "55/55 [==============================] - 3s 59ms/step - loss: 0.3524 - accuracy: 0.9076 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 30/300\n",
      "55/55 [==============================] - 3s 61ms/step - loss: 0.3474 - accuracy: 0.9068 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 31/300\n",
      "55/55 [==============================] - 3s 52ms/step - loss: 0.3381 - accuracy: 0.9085 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 32/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3469 - accuracy: 0.9072 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 33/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3381 - accuracy: 0.9077 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 34/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3386 - accuracy: 0.9076 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 35/300\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.3365 - accuracy: 0.9082 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 36/300\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.3348 - accuracy: 0.9086 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 37/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3366 - accuracy: 0.9083 - val_loss: 0.3101 - val_accuracy: 0.9088\n",
      "Epoch 38/300\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.3305 - accuracy: 0.9082 - val_loss: 0.3102 - val_accuracy: 0.9088\n",
      "Epoch 39/300\n",
      "55/55 [==============================] - 2s 45ms/step - loss: 0.3324 - accuracy: 0.9082 - val_loss: 0.3099 - val_accuracy: 0.9088\n",
      "Epoch 40/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.3407 - accuracy: 0.9082 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 41/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3374 - accuracy: 0.9085 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 42/300\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.3340 - accuracy: 0.9082 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 43/300\n",
      "55/55 [==============================] - 2s 41ms/step - loss: 0.3284 - accuracy: 0.9084 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 44/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3264 - accuracy: 0.9084 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 45/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3233 - accuracy: 0.9083 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 46/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3334 - accuracy: 0.9085 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 47/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3293 - accuracy: 0.9084 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 48/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3283 - accuracy: 0.9078 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 49/300\n",
      "55/55 [==============================] - 3s 46ms/step - loss: 0.3290 - accuracy: 0.9075 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 50/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3388 - accuracy: 0.9085 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 51/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3307 - accuracy: 0.9087 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 52/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3319 - accuracy: 0.9087 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 53/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3285 - accuracy: 0.9085 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 54/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3316 - accuracy: 0.9079 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 55/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3289 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 56/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3255 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 57/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3257 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3212 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 59/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3223 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 60/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3344 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 61/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3230 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 62/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3250 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 63/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3224 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 64/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3234 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 65/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3251 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 66/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3196 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 67/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3260 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 68/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3215 - accuracy: 0.9081 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 69/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3159 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 70/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3172 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 71/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3149 - accuracy: 0.9084 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 72/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3121 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 73/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3192 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 74/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3141 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 75/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3153 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 76/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.3137 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 77/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3137 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 78/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3172 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 79/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3132 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 80/300\n",
      "55/55 [==============================] - 2s 37ms/step - loss: 0.3141 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 81/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.3105 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 82/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.3190 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 83/300\n",
      "55/55 [==============================] - 4s 71ms/step - loss: 0.3103 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 84/300\n",
      "55/55 [==============================] - 5s 86ms/step - loss: 0.3158 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 85/300\n",
      "55/55 [==============================] - 4s 67ms/step - loss: 0.3112 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 86/300\n",
      "55/55 [==============================] - 4s 73ms/step - loss: 0.3116 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 87/300\n",
      "55/55 [==============================] - 4s 77ms/step - loss: 0.3112 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 88/300\n",
      "55/55 [==============================] - 5s 83ms/step - loss: 0.3203 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 89/300\n",
      "55/55 [==============================] - 4s 76ms/step - loss: 0.3078 - accuracy: 0.9087 - val_loss: 0.3097 - val_accuracy: 0.9088\n",
      "Epoch 90/300\n",
      "55/55 [==============================] - 4s 73ms/step - loss: 0.3146 - accuracy: 0.9085 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 91/300\n",
      "55/55 [==============================] - 4s 73ms/step - loss: 0.3135 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 92/300\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.3115 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 93/300\n",
      "55/55 [==============================] - 4s 71ms/step - loss: 0.3147 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 94/300\n",
      "55/55 [==============================] - 3s 61ms/step - loss: 0.3141 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 95/300\n",
      "55/55 [==============================] - 3s 61ms/step - loss: 0.3097 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 96/300\n",
      "55/55 [==============================] - 3s 60ms/step - loss: 0.3114 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 97/300\n",
      "55/55 [==============================] - 4s 67ms/step - loss: 0.3117 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 98/300\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 0.3115 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 99/300\n",
      "55/55 [==============================] - 3s 50ms/step - loss: 0.3137 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 100/300\n",
      "55/55 [==============================] - 2s 44ms/step - loss: 0.3122 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 101/300\n",
      "55/55 [==============================] - 2s 43ms/step - loss: 0.3109 - accuracy: 0.9086 - val_loss: 0.3096 - val_accuracy: 0.9088\n",
      "Epoch 102/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3129 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 103/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.3099 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 104/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3087 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 105/300\n",
      "55/55 [==============================] - 3s 48ms/step - loss: 0.3114 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 106/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3103 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 107/300\n",
      "55/55 [==============================] - 3s 53ms/step - loss: 0.3094 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 108/300\n",
      "55/55 [==============================] - 3s 59ms/step - loss: 0.3106 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 109/300\n",
      "55/55 [==============================] - 2s 42ms/step - loss: 0.3114 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 110/300\n",
      "55/55 [==============================] - 2s 40ms/step - loss: 0.3095 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 111/300\n",
      "55/55 [==============================] - 3s 47ms/step - loss: 0.3095 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 112/300\n",
      "55/55 [==============================] - 2s 39ms/step - loss: 0.3084 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 113/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3125 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 114/300\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.3142 - accuracy: 0.9087 - val_loss: 0.3095 - val_accuracy: 0.9088\n",
      "Epoch 00114: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac263a11c0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 256, epochs = 300, validation_data = (X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
